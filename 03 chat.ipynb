{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f5c7f0-ee72-4d29-bdc1-cd1004365ea7",
   "metadata": {},
   "source": [
    "# Chat With LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94867c9-7e2f-4fd7-aaea-4e7915d180c7",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7714b760-e63b-4126-8dda-7e829a74c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.llms import Tongyi\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d11c428a-75f2-4f5e-9b46-939d512ea7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载 .env 到环境变量\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07e2ddd0-2ca4-4563-a209-49e54fcbe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "handler = CallbackHandler(trace_name=\"chat_with_llm\", user_id=\"langchain_book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8baa67-0c6d-48d8-bdf7-89a862a2768d",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8af1b73f-bfbc-4d9f-bc40-ad383c6dd744",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542f927a-4a0c-4074-afff-0337fae22f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7831895-ec1d-497d-8af1-4c5cbb99867a",
   "metadata": {},
   "source": [
    "### GPT35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "11eca587-7212-412a-86aa-46d8ac3f5ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gpt35(input: str, temp = 0.3):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"{question}\"\"\")\n",
    "    llm = ChatOpenAI(model = \"gpt-3.5-turbo-1106\", streaming = True, temperature = temp)\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.stream({\"question\": input}, config = {\"callbacks\": [handler]})\n",
    "    for r in result:\n",
    "        print(r, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db341754-7586-4ada-af70-630f09bd40f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个基于人工智能的语言模型，可以进行对话交流并回答问题。我并不是一个具体的物理模型或数学模型。"
     ]
    }
   ],
   "source": [
    "await gpt35(\"你是什么模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da2ffb69-3a85-4f61-892b-447d55b297aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gpt4(input: str, temp = 0.3):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"{question}\"\"\")\n",
    "    llm = ChatOpenAI(model = \"gpt-4-1106-preview\", streaming = True, temperature = temp)\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.stream({\"question\": input}, config={\"callbacks\": [handler]})\n",
    "    for r in result:\n",
    "        print(r, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a99650a5-f694-4b47-8ac1-7159db6de77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是由 OpenAI 开发的大型语言模型，名为 ChatGPT。我的架构基于 GPT（生成预训练变换器）系列模型，这是一种深度学习模型，专门设计用于理解和生成自然语言文本。我的训练涉及大量的文本数据，使我能够回答问题、撰写文章、翻译语言、进行对话等。不过，请注意，我的知识是有截止日期的，我不会了解在我训练数据截止日期之后发生的事件或发展。"
     ]
    }
   ],
   "source": [
    "await gpt4(\"你是什么模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52dd9c22-bc85-4156-a929-916b1486af65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Runnable.stream at 0x119482dc0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = Tongyi()\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"你是什么模型\"\n",
    "llm_chain.stream(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a03d5634-6cdf-4789-b96f-e48169a58d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Tongyi\n",
    "\n",
    "async def tongyi(input: str, temp = 0.3):\n",
    "    prompt = PromptTemplate(template=\"\"\"{question}\"\"\", input_variables=[\"question\"])\n",
    "    llm = Tongyi(temperature = temp)\n",
    "    chain = LLMChain(prompt = prompt, llm = llm)\n",
    "    result = chain.stream(input)\n",
    "    for r in result:\n",
    "        print(r, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bdc0286d-2516-47b7-a984-10b9caa5de33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你是什么模型', 'text': '我是阿里云开发的大规模语言模型，我叫通义千问。'}"
     ]
    }
   ],
   "source": [
    "await tongyi(\"你是什么模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f8b969a9-2592-442a-bc24-0e8327091b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chatglm(input: str, temp = 0.3):\n",
    "    prompt = PromptTemplate(template=\"\"\"{question}\"\"\", input_variables=[\"question\"])\n",
    "    llm = Tongyi(model_name = \"chatglm3-6b\")\n",
    "    chain = LLMChain(prompt = prompt, llm = llm)\n",
    "    result = chain.stream({\"question\": input})\n",
    "    for r in result:\n",
    "        print(r, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f03b6cea-513d-4772-b737-efcec7eed6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '你是什么模型', 'text': '\\n 我是一个名为 ChatGLM3-6B 的人工智能助手，是基于清华大学 KEG 实验室和智谱 AI 公司于 2023 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。'}"
     ]
    }
   ],
   "source": [
    "await chatglm(\"你是什么模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e1c6c-e1eb-4063-a5c6-9f9336302dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
