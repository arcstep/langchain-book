{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ed013-dc0f-4a14-8a41-883c4e0f8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778f1e3-d164-410e-9fd5-8153c3fc8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38182e07-def7-4b0c-8226-97567eac6c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be4934-3dff-434e-8873-141d139f9d92",
   "metadata": {},
   "source": [
    "# 提取单个网页"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f3901-15f8-4997-b260-88ba58559110",
   "metadata": {},
   "source": [
    "## 纯静态页面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1204c-a03d-4b84-8198-418ec9b30f80",
   "metadata": {},
   "source": [
    "## 有延迟加载的页面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d54e320-dac8-4118-ba5f-cf415743e37f",
   "metadata": {},
   "source": [
    "## JS补充加载的页面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba955065-be34-4ea3-94dd-3134b59876a8",
   "metadata": {},
   "source": [
    "# 提取单个异步加载网页"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f69e0-902f-4ab6-b4a1-546dea2bdc75",
   "metadata": {},
   "source": [
    "# 根据网页内的链接循环获取批量网页"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ce6fd-6d5e-4100-b265-ced22e3761a4",
   "metadata": {},
   "source": [
    "# 根据 SiteMap 获取批量网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7334525f-95a4-417c-bf13-7d7b5760e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import re\n",
    "\n",
    "def simple_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd100b60-2c5c-435a-b7d5-83c0c94c7db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a06964-de24-486d-b232-71c6be8fe6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"智谱AI开放平台We're sorry but 智谱AI开放平台 doesn't work properly without JavaScript enabled. Please enable it to continue.\", metadata={'source': 'https://maas.aminer.cn/dev/howuse/model', 'title': '智谱AI开放平台', 'description': '大模型开放平台-新一代国产自主通用AI开放平台，致力于将产品技术与行业场景双轮驱动的中国先进的认知智能技术和千行百业应用相结合，构建更高精度、高效率、通用化的AI开发新模式，实现智谱大模型的产业化，将AI的好处带给每个人。', 'language': 'zh-cn'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from langchain_core.utils.html import PREFIXES_TO_IGNORE_REGEX, SUFFIXES_TO_IGNORE_REGEX\n",
    "\n",
    "loader = RecursiveUrlLoader(\n",
    "        url = \"https://maas.aminer.cn/dev/howuse/model\",\n",
    "        max_depth = 8,\n",
    "        extractor = simple_extractor,\n",
    "        prevent_outside = True,\n",
    "        use_async = True,\n",
    "        timeout = 600,\n",
    "        # Drop trailing / to avoid duplicate pages.\n",
    "        link_regex = (\n",
    "            f\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)\"\n",
    "            r\"(?:[\\#'\\\"]|\\/[\\#'\\\"])\"\n",
    "        ),\n",
    "        check_response_status = True,\n",
    "    )\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7feb23f-a006-4599-a6af-c78d2c6c48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import re\n",
    "\n",
    "def simple_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4b7060-2e36-415e-9e8e-c744279fe1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3de4fc95-651d-4ee8-9ee1-e9777c2b19da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"智谱AI开放平台We're sorry but 智谱AI开放平台 doesn't work properly without JavaScript enabled. Please enable it to continue.\", metadata={'source': 'https://maas.aminer.cn/dev/howuse/model', 'title': '智谱AI开放平台', 'description': '大模型开放平台-新一代国产自主通用AI开放平台，致力于将产品技术与行业场景双轮驱动的中国先进的认知智能技术和千行百业应用相结合，构建更高精度、高效率、通用化的AI开发新模式，实现智谱大模型的产业化，将AI的好处带给每个人。', 'language': 'zh-cn'})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from langchain_core.utils.html import PREFIXES_TO_IGNORE_REGEX, SUFFIXES_TO_IGNORE_REGEX\n",
    "\n",
    "loader = RecursiveUrlLoader(\n",
    "        url = \"https://maas.aminer.cn/dev/howuse/model\",\n",
    "        max_depth = 8,\n",
    "        extractor = simple_extractor,\n",
    "        prevent_outside = True,\n",
    "        use_async = True,\n",
    "        timeout = 600,\n",
    "        # Drop trailing / to avoid duplicate pages.\n",
    "        link_regex = (\n",
    "            f\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)\"\n",
    "            r\"(?:[\\#'\\\"]|\\/[\\#'\\\"])\"\n",
    "        ),\n",
    "        check_response_status = True,\n",
    "    )\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d280f24-f6db-4c38-8be2-6075381e8e36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
    "from langchain_core.utils.html import PREFIXES_TO_IGNORE_REGEX, SUFFIXES_TO_IGNORE_REGEX\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22438a36-7eba-4ce5-9ad5-8bef27449451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅在jupyter中需要\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2509a056-0c15-4129-af54-c215508b03cf",
   "metadata": {},
   "source": [
    "### 提取langchain文档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88e9a5-0b86-4ded-822b-87f63ff16374",
   "metadata": {},
   "source": [
    "#### 提取langchain的Docs文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d9dfea-aabe-4b39-8c37-38a766dc99fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metadata_extractor(meta: dict, soup: BeautifulSoup) -> dict:\n",
    "    title = soup.find(\"title\")\n",
    "    description = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    html = soup.find(\"html\")\n",
    "    return {\n",
    "        \"source\": meta[\"loc\"],\n",
    "        \"title\": title.get_text() if title else \"\",\n",
    "        \"description\": description.get(\"content\", \"\") if description else \"\",\n",
    "        \"language\": html.get(\"lang\", \"\") if html else \"\",\n",
    "        **meta,\n",
    "    }\n",
    "\n",
    "def load_langchain_docs():\n",
    "    return SitemapLoader(\n",
    "        \"https://python.langchain.com/sitemap.xml\",\n",
    "        filter_urls = [\"https://python.langchain.com/\"],\n",
    "        parsing_function = web_page_extractor,\n",
    "        default_parser = \"lxml\",\n",
    "        bs_kwargs = {\n",
    "            \"parse_only\": SoupStrainer(\n",
    "                name = (\"article\", \"title\", \"html\", \"lang\", \"content\")\n",
    "            ),\n",
    "        },\n",
    "        meta_function = metadata_extractor,\n",
    "    ).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc573a3-8b57-4087-9aba-8ed4e0fb6031",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1180/1180 [07:51<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "langchain_docs = load_langchain_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34109e8d-1684-4b87-b570-ddb632173f4c",
   "metadata": {},
   "source": [
    "#### 提取langchain的API文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd4bbe5-ca23-4f25-8c21-0eb66db60bb0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "def load_api_docs():\n",
    "    return RecursiveUrlLoader(\n",
    "        url = \"https://api.python.langchain.com/en/stable/langchain_api_reference.html\",\n",
    "        max_depth = 8,\n",
    "        extractor = simple_extractor,\n",
    "        prevent_outside = True,\n",
    "        use_async = True,\n",
    "        timeout = 600,\n",
    "        # Drop trailing / to avoid duplicate pages.\n",
    "        link_regex = (\n",
    "            f\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)\"\n",
    "            r\"(?:[\\#'\\\"]|\\/[\\#'\\\"])\"\n",
    "        ),\n",
    "        check_response_status = True,\n",
    "        exclude_dirs = (\n",
    "            \"https://api.python.langchain.com/en/latest/_sources\",\n",
    "            \"https://api.python.langchain.com/en/latest/_modules\",\n",
    "        ),\n",
    "    ).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "352ef841-63c7-435f-9079-a83ea4bf600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_docs = load_api_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cca9fc-9a4c-4220-87ec-dda17759bc9f",
   "metadata": {},
   "source": [
    "#### 提取langsmith的docs文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3643995-cb11-4348-ab8a-9890eba2e625",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_langsmith_docs():\n",
    "    return RecursiveUrlLoader(\n",
    "        url = \"https://docs.smith.langchain.com/\",\n",
    "        max_depth = 8,\n",
    "        extractor = simple_extractor,\n",
    "        prevent_outside = True,\n",
    "        use_async = True,\n",
    "        timeout = 600,\n",
    "        # Drop trailing / to avoid duplicate pages.\n",
    "        link_regex = (\n",
    "            f\"href=[\\\"']{PREFIXES_TO_IGNORE_REGEX}((?:{SUFFIXES_TO_IGNORE_REGEX}.)*?)\"\n",
    "            r\"(?:[\\#'\\\"]|\\/[\\#'\\\"])\"\n",
    "        ),\n",
    "        check_response_status = True,\n",
    "    ).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a353d1-1354-451b-81d8-33be994900fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f5/rlf27f4n6wzc_k4x7y4vzm5h0000gn/T/ipykernel_31512/320920142.py:2: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(html, \"lxml\")\n",
      "/Users/xuehongwei/.pyenv/versions/3.10.0/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    }
   ],
   "source": [
    "langsmith_docs = load_langsmith_docs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
