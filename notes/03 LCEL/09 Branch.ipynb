{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bda7cf-9094-4d3c-be54-4e75fa56edfd",
   "metadata": {},
   "source": [
    "# 流程控制概述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f2f08f-d763-4033-ad01-f507fd4d8bdd",
   "metadata": {},
   "source": [
    "Runnable 可以支持包括顺序、分支、条件、迭代等多种控制方式，构建较复杂的有向无环图。\n",
    "\n",
    "与直接使用python代码控制流程不同的是，下面这些流程控制手段仍然保持以Runnable返回，以便获得LCEL的诸多额外好处，如：Runnable的统一方法、序列化能力、重试能力、回滚能力、Langsmith追踪和Langserve的API集成等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46635a-88d6-4677-8ea9-bd1942bbe850",
   "metadata": {},
   "source": [
    "# 流程控制相关类结构"
   ]
  },
  {
   "cell_type": "raw",
   "id": "280d37af-5cf5-4e3b-887d-9ea2c3cc18dd",
   "metadata": {},
   "source": [
    "可接受参数：\n",
    "\n",
    "Union[\n",
    "    Runnable[Input, Output],\n",
    "    Callable[[Input], Output],\n",
    "    Callable[[Input], Awaitable[Output]],\n",
    "    Callable[[Iterator[Input]], Iterator[Output]],\n",
    "    Callable[[AsyncIterator[Input]], AsyncIterator[Output]],\n",
    "    Mapping[str, Any],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47ad8d-e8c3-4c71-a56c-6d47254decc6",
   "metadata": {},
   "source": [
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - RunnableSequence（实现顺序执行，可以用|符号或RunnableSequence来构造）\n",
    "        - RunnableParallel（实现并行执行，可以用Dict或RunnableParallel类来构造，别名RunnableMap）\n",
    "        - RunnableEach（实现相同的链迭代多次）\n",
    "        - RunnableBranch（实现流程分支，根据条件选择不同的链执行）\n",
    "        - RouterRunnable（实现流程分支，根据枚举值选择不同的链执行）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350af9c-984e-4dd6-878f-d2aa61776c3c",
   "metadata": {},
   "source": [
    "# RunnableSerializable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc23244-436d-4e2e-ab71-efb7a86af31e",
   "metadata": {},
   "source": [
    "主要增加了序列化的方法，可以将Runnable以JSON字符串的方式保存或加载：\n",
    "\n",
    "- loads / dumps （按JSON字符串）\n",
    "- load / dumpd （按Dict类型）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17e233-9ccb-4eb5-8382-09f82f066601",
   "metadata": {},
   "source": [
    "## 将Runnable保存为JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68a989d8-fcbe-4210-9bb0-0d0255c02757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from typing import Iterator\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chant = (\n",
    "    ChatPromptTemplate.from_template(\"Give me a 3 word chant about {topic}\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a9dfe2f-9dc1-4e52-b8b8-66b2addcaf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"runnable\", \"RunnableSequence\"], \"kwargs\": {\"first\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"chat\", \"ChatPromptTemplate\"], \"kwargs\": {\"input_variables\": [\"topic\"], \"messages\": [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"chat\", \"HumanMessagePromptTemplate\"], \"kwargs\": {\"prompt\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"prompt\", \"PromptTemplate\"], \"kwargs\": {\"input_variables\": [\"topic\"], \"template\": \"Give me a 3 word chant about {topic}\", \"template_format\": \"f-string\", \"partial_variables\": {}}}}}]}}, \"middle\": [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"openai_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"OPENAI_API_KEY\"]}}}], \"last\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output_parser\", \"StrOutputParser\"], \"kwargs\": {}}, \"name\": null}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.load import loads, dumps\n",
    "json = dumps(chant)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a9d6b-3474-46c2-a950-327b681a742c",
   "metadata": {},
   "source": [
    "## 从JSON中恢复Runnable并调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "20b369e6-dc8c-462d-b916-60f2d93c39b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Apple, sweet success!\"'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loads(json).invoke({\"topic\":\"苹果\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6911350-c506-4555-8101-a1561285e71b",
   "metadata": {},
   "source": [
    "## 根据配置动态选择Runnable对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2c13b4df-ba7c-4bf5-8cb1-3163f13bcbd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.runnables import ConfigurableField, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Give me a 3 word chant about {topic}\")\n",
    "openai = ChatOpenAI()\n",
    "llm = OpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "configurable_model = llm.configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"), \n",
    "    default_key=\"llm_openai\", \n",
    "    chat_openai=openai\n",
    ")\n",
    "\n",
    "configurable_chain = (\n",
    "    {\"topic\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | configurable_model \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "95e1062b-32b4-4390-afe3-4b273437d9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Sweet, cold, yum!\"'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurable_chain.invoke(\n",
    "    \"ice cream\", \n",
    "    config={\"model\": \"llm_openai\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "757cc7f7-3569-4405-a40e-04e36c083213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Scoop, swirl, savor!\"'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurable_chain.invoke(\n",
    "    \"ice cream\", \n",
    "    config={\"model\": \"chat_openai\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a1e74-a086-44a0-9738-68e84bb0ac67",
   "metadata": {},
   "source": [
    "## 查看有哪些动态选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356063f-bdd7-46c3-b018-b6e776c29c0c",
   "metadata": {},
   "source": [
    "# RunnableSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4fc2a9-5d33-4f03-8d42-66c97fa7e90d",
   "metadata": {},
   "source": [
    "RunnableSequence 是最最重要的流程控制组件。\n",
    "\n",
    "另外，RunnableSequence 也增加了几个属性：\n",
    "- first: 第一个Runnable组件\n",
    "- middle: 中间的Runnable组件列表\n",
    "- last: 最后一个Runnable组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ecb89267-4e5b-4916-8c39-7dd50db67912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +---------------+    \n",
      "    | add_one_input |    \n",
      "    +---------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "  +-----------------+    \n",
      "  | Lambda(add_one) |    \n",
      "  +-----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| Lambda(buggy_double) | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+---------------------+  \n",
      "| buggy_double_output |  \n",
      "+---------------------+  \n",
      "---RunnableSequence\n",
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n",
      "<class 'list'>\n",
      "<class 'langchain_core.runnables.retry.RunnableRetry'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import random\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "def buggy_double(y: int) -> int:\n",
    "    '''Buggy code that will fail 70% of the time'''\n",
    "    if random.random() > 0.3:\n",
    "        print('This code failed, and will probably be retried!')\n",
    "        raise ValueError('Triggered buggy code')\n",
    "    return y * 2\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(add_one) |\n",
    "    RunnableLambda(buggy_double).with_retry( # Retry on failure\n",
    "        stop_after_attempt = 10,\n",
    "        wait_exponential_jitter = False\n",
    "    )\n",
    ")\n",
    "chain.get_graph().print_ascii()\n",
    "\n",
    "print(\"---RunnableSequence\")\n",
    "print(type(chain.first))\n",
    "print(type(chain.middle))\n",
    "print(type(chain.last))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc22ee40-4d58-4f17-8be9-ff8d874d3bdf",
   "metadata": {},
   "source": [
    "# RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c7998b-d133-4d43-8ee5-b9f7715295f7",
   "metadata": {},
   "source": [
    "一种情况是从同一个输入生成多个分支链："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "eaa9f7fa-ba19-4093-9efd-7c982f1077b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    +---------------+                     \n",
      "                    | add_one_input |                     \n",
      "                    +---------------+                     \n",
      "                            *                             \n",
      "                            *                             \n",
      "                            *                             \n",
      "                  +-----------------+                     \n",
      "                  | Lambda(add_one) |                     \n",
      "                  +-----------------+                     \n",
      "                            *                             \n",
      "                            *                             \n",
      "                            *                             \n",
      "          +----------------------------------+            \n",
      "          | Parallel<mul_two,mul_three>Input |            \n",
      "          +----------------------------------+            \n",
      "                  ***               ***                   \n",
      "               ***                     ***                \n",
      "             **                           **              \n",
      "+-----------------+                 +-------------------+ \n",
      "| Lambda(mul_two) |                 | Lambda(mul_three) | \n",
      "+-----------------+                 +-------------------+ \n",
      "                  ***               ***                   \n",
      "                     ***         ***                      \n",
      "                        **     **                         \n",
      "          +-----------------------------------+           \n",
      "          | Parallel<mul_two,mul_three>Output |           \n",
      "          +-----------------------------------+           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'mul_two': 4, 'mul_three': 6},\n",
       " {'mul_two': 6, 'mul_three': 9},\n",
       " {'mul_two': 8, 'mul_three': 12}]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "def mul_three(x: int) -> int:\n",
    "    return x * 3\n",
    "\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(mul_two)\n",
    "runnable_3 = RunnableLambda(mul_three)\n",
    "\n",
    "sequence = runnable_1 | {  # this dict is coerced to a RunnableParallel\n",
    "    \"mul_two\": runnable_2,\n",
    "    \"mul_three\": runnable_3,\n",
    "}\n",
    "# Or equivalently:\n",
    "# sequence = runnable_1 | RunnableParallel(\n",
    "#     {\"mul_two\": runnable_2, \"mul_three\": runnable_3}\n",
    "# )\n",
    "# Also equivalently:\n",
    "# sequence = runnable_1 | RunnableParallel(\n",
    "#     mul_two=runnable_2,\n",
    "#     mul_three=runnable_3,\n",
    "# )\n",
    "\n",
    "sequence.invoke(1)\n",
    "sequence.get_graph().print_ascii()\n",
    "\n",
    "await sequence.ainvoke(1)\n",
    "\n",
    "sequence.batch([1, 2, 3])\n",
    "await sequence.abatch([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f51bf64-242d-490f-9d23-bc365b07e652",
   "metadata": {},
   "source": [
    "# RunnableEach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3a16d-8187-44f7-a36d-0ddeea4d512c",
   "metadata": {},
   "source": [
    "如果需要让同一个链执行多次，使用 RunnableEach 非常方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7a2c97be-6ad3-4ea1-8600-081d81e8cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +--------------+  \n",
      " | myfunc_input |  \n",
      " +--------------+  \n",
      "         *         \n",
      "         *         \n",
      "         *         \n",
      "+----------------+ \n",
      "| Lambda(myfunc) | \n",
      "+----------------+ \n",
      "         *         \n",
      "         *         \n",
      "         *         \n",
      "+---------------+  \n",
      "| myfunc_output |  \n",
      "+---------------+  \n",
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.base import RunnableEach, chain\n",
    "\n",
    "@chain\n",
    "def myfunc(x):\n",
    "    return(x * 2)\n",
    "\n",
    "runnable_each = RunnableEach(bound = myfunc)\n",
    "runnable_each.get_graph().print_ascii()\n",
    "\n",
    "output = runnable_each.invoke(range(1, 5))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eed718-864c-4b11-8bd1-b0ff22114a4c",
   "metadata": {},
   "source": [
    "# RunnableBranch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e50e7-efd8-4d6a-a328-09de7cf4be1e",
   "metadata": {},
   "source": [
    "有时候希望实现类似 ifelse 的条件分支，使用 RunnableBrach 可以接受 (条件函数, runnable) 的元组对和一个默认分支。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "da2e1e5e-a82e-44cb-a2be-b01102c7b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+  \n",
      "| BranchInput |  \n",
      "+-------------+  \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "   +--------+    \n",
      "   | Branch |    \n",
      "   +--------+    \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+--------------+ \n",
      "| BranchOutput | \n",
      "+--------------+ \n",
      "HELLO\n",
      "6\n",
      "goodbye\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch, chain\n",
    "\n",
    "@chain\n",
    "def myfunc(x):\n",
    "    return(x * 2)\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: isinstance(x, str), lambda x: x.upper()),\n",
    "    (lambda x: isinstance(x, int), myfunc),\n",
    "    lambda x: \"goodbye\",\n",
    ")\n",
    "branch.get_graph().print_ascii()\n",
    "\n",
    "print(branch.invoke(\"hello\")) # \"HELLO\"\n",
    "print(branch.invoke(3)) # 6\n",
    "print(branch.invoke(None)) # \"goodbye\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5042daf2-359c-4750-b62c-56bf4d59a793",
   "metadata": {},
   "source": [
    "# RouterRunnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc56108-adcf-428f-95bc-70caf8f001a8",
   "metadata": {},
   "source": [
    "条件分支中还有一种情况更为简单，适合使用RouterRunnable，可以比RunnableBranch简洁得多。\n",
    "<br>但传递参数时必须以 RouterInput 类型传入，或使用等价的字典结构。\n",
    "\n",
    "```\n",
    "class RouterInput(TypedDict):\n",
    "    key: str\n",
    "    input: Any\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0c8d78de-2d06-4144-95cc-3a553027882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+  \n",
      "| RouterRunnableInput |  \n",
      "+---------------------+  \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | RouterRunnable |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| RouterRunnableOutput | \n",
      "+----------------------+ \n",
      "HELLO\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RouterRunnable, chain\n",
    "\n",
    "@chain\n",
    "def lower(x):\n",
    "    return(x.lower())\n",
    "\n",
    "@chain\n",
    "def upper(x):\n",
    "    return(x.upper())\n",
    "\n",
    "router = RouterRunnable({\"lower\": lower, \"upper\": upper})\n",
    "router.get_graph().print_ascii()\n",
    "\n",
    "print(router.invoke({\"key\": \"upper\", \"input\": \"Hello\"}))\n",
    "print(router.invoke({\"key\": \"lower\", \"input\": \"Hello\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
