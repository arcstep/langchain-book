{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffc5dcb9-1b9d-4427-80e4-c7d46e7d4af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b3b67-26f5-427b-855f-665074d35241",
   "metadata": {},
   "source": [
    "# Runnable 协议"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b5276b-7477-4b71-b4b5-e5d99d15ff1c",
   "metadata": {},
   "source": [
    "要支持链式调用，就必须实现 **Runnable** 协议。 \n",
    "这是一个标准接口，可以轻松定义自定义链并以标准方式调用它们。 \n",
    "\n",
    "标准接口包括：\n",
    "\n",
    "- invoke：在输入上调用链\n",
    "- batch：批量执行invoke\n",
    "- stream：通过生成器实现流返回\n",
    "\n",
    "这些也有相应的异步方法：\n",
    "\n",
    "- ainvoke\n",
    "- abatch\n",
    "- astream\n",
    "- astream_log：打印中间步骤\n",
    "- astream_events：实现事件流（在 langchain-core 0.1.14 中引入）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a6ab9-ed58-4569-83f5-aa729d56b91a",
   "metadata": {},
   "source": [
    "不同组件的输入输出："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6506a-be94-4ae1-8bd7-267467bfc657",
   "metadata": {},
   "source": [
    "| 组件名称    | 输入类型   | 输出类型     |\n",
    "|-----------|------------|-------------|\n",
    "| Prompt模板    | 提示语和字典 | PromptValue |\n",
    "| Retriever | 字符串 | 文档列表 |\n",
    "| Tool      | 字符串或字典（依赖于工具的实现） | 依赖于工具的实现 |\n",
    "| ChatModel | 字符串，对话消息或PrompValue | ChatMessage |\n",
    "| LLM       | 字符串，对话消息或PrompValue | 字符串 |\n",
    "| OutputParser | LLM 或 ChatModel 的输出 | 依赖于解析器的实现 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee29906-1faf-491a-9eee-baee21d367f9",
   "metadata": {},
   "source": [
    "# 输入输出schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d55d32-cda5-4458-a6d1-f41ed17a8784",
   "metadata": {},
   "source": [
    "**chain**的输入输出都使用**pydantic**来检验**schema**是否合规。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23e5a29e-1a2d-465f-ae43-979ba2ab93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88be6a-b652-4124-8eaf-c1512910aebf",
   "metadata": {},
   "source": [
    "## Runnable的schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8962890e-f646-410e-9c43-44cb8671325e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptInput(topic=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6f706d-a678-45ee-ae95-96a040dcd921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5113763-c19c-4928-88be-04c17446a123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt.output_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b502b3c-239e-42d5-ba35-54dfcfdc11e2",
   "metadata": {},
   "source": [
    "## Chain的schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a4835-7475-4d14-b73d-556c92b08c35",
   "metadata": {},
   "source": [
    "### input_schema是链序列中第一个对象的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abdf6747-ea08-4fc5-bac9-ae17707d3b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptInput',\n",
       " 'type': 'object',\n",
       " 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a579a98a-089c-455b-8ff6-4e4ae8f7985d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='tell me a joke about {topic}'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da534c08-51ac-411c-a85e-05f4ef64ef2b",
   "metadata": {},
   "source": [
    "### output_schema是链序列中最后一个对象的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638712ef-c597-4deb-80d2-90af7311a266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chain.output_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb140a86-8794-4d68-91e9-2b13768eb719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11475eb90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x114798f40>, openai_api_key='sk-SctYLVDdKoqPLXoKlLEMjLqHG2BhuOtQgjmMWvrTDqlKJeqz', openai_proxy='')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1972cc5-ff0f-43bd-bf23-7ec75ed050dd",
   "metadata": {},
   "source": [
    "# 接口调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e0dda-e5ca-47cd-ab70-a16dead35f26",
   "metadata": {},
   "source": [
    "## invoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0538a2-76e7-49fb-b980-e9b7b80aa521",
   "metadata": {},
   "source": [
    "定制 Runnable 时**必须重载**这个接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113ba7f-5e70-4e64-96a9-be41ae5039cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f41e9-b9ce-43b1-ab55-ffa0c926161e",
   "metadata": {},
   "source": [
    "## ainvoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f739367-15ca-44fd-8387-b00487e23ce3",
   "metadata": {},
   "source": [
    "缺省实现是在 langchain 内异步调用 invoke 接口；如果大模型有异步接口**应当重载**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d88bf1d4-ea33-4a4f-8dde-b5f9ad4026d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the bear bring a flashlight to the party? \\n\\nBecause he heard it was going to be a \"beary\" good time!')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chain.ainvoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389fa93e-6eb2-4a9b-83c5-828d93bcc55d",
   "metadata": {},
   "source": [
    "## batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e766119-a659-4bbf-b041-dc479c8029ca",
   "metadata": {},
   "source": [
    "缺省实现是批量调用 invoke 接口；一般**不需要重载**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eeb4013-0685-4b99-9afe-f99fc94ab6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the distance between them!\"),\n",
       " AIMessage(content='Why do programmers prefer dark mode? Because the light attracts too many bugs!')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"programmer\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542f39b7-d33a-4406-a768-bef98de84410",
   "metadata": {},
   "source": [
    "## abatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b389c4-524f-406c-83f5-9b487766d7c5",
   "metadata": {},
   "source": [
    "缺省实现是批量调用 ainvoke 接口；一般**不需要重载**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773e928-3332-48a5-82bf-2d8b606248d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chain.abatch([{\"topic\": \"bears\"}, {\"topic\": \"programmer\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c52a1-33ff-4f56-97bf-0ca3d0ff45a8",
   "metadata": {},
   "source": [
    "## stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b684492a-6500-445a-b683-09780ed6d383",
   "metadata": {},
   "source": [
    "缺省实现是调用 invoke 接口；一般都**需要重载**，否则就退化为 invoke 调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e69bf362-a8b5-402f-b6c9-e84161a2fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a bear joke for you:\n",
      "\n",
      "Why don't bears use cellphones?\n",
      "\n",
      "Because they already have paws for \"bear-y\" good reception!"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543959b1-fdcb-4186-b338-db9e8f84fcd4",
   "metadata": {},
   "source": [
    "## astream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76bcc5-938b-47c3-be46-9c133ae7957f",
   "metadata": {},
   "source": [
    "缺省实现是调用 ainvoke 接口；一般都**需要重载**，否则就退化为 ainvoke 调用。<br>\n",
    "**值得注意**的是：即使实现了 stream 函数， asteram 的缺省实现也会调用 ainvoke（可能最后是间接调用 invoke ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "948d81f7-12bb-486e-b3c7-b9c653d67f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the bear bring a flashlight to the party?\n",
      "Because he heard it was going to be a \"beary\" dark night!"
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream({\"topic\": \"bears\"}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0457430-3369-4192-a7fa-ee6e0cc555f5",
   "metadata": {},
   "source": [
    "## astream_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d3f51-cc82-459f-96c8-1952a6520c8b",
   "metadata": {},
   "source": [
    "调用 astream_log 实现，当前仅支持 v1 版本；一般**不考虑重载**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78c9f15a-ce80-418e-a56f-31105f19c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='')}\n",
      "{'chunk': AIMessageChunk(content='Why')}\n",
      "{'chunk': AIMessageChunk(content=' don')}\n",
      "{'chunk': AIMessageChunk(content=\"'t\")}\n",
      "{'chunk': AIMessageChunk(content=' bears')}\n",
      "{'chunk': AIMessageChunk(content=' wear')}\n",
      "{'chunk': AIMessageChunk(content=' shoes')}\n",
      "{'chunk': AIMessageChunk(content='?\\n\\n')}\n",
      "{'chunk': AIMessageChunk(content='Because')}\n",
      "{'chunk': AIMessageChunk(content=' they')}\n",
      "{'chunk': AIMessageChunk(content=' have')}\n",
      "{'chunk': AIMessageChunk(content=' bear')}\n",
      "{'chunk': AIMessageChunk(content=' feet')}\n",
      "{'chunk': AIMessageChunk(content='!')}\n",
      "{'chunk': AIMessageChunk(content='')}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream_events({\"topic\": \"bears\"}, version=\"v1\", include_tags=['seq:step:2']):\n",
    "    if 'chunk' in chunk['data']:\n",
    "        print(chunk['data'], flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89cbb5c-4460-486d-a583-2584f64551df",
   "metadata": {},
   "source": [
    "## astream_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738d7b9-791c-4f03-ad6b-ae1864a43ea8",
   "metadata": {},
   "source": [
    "调用 stream 实现；一般**不考虑重载**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8257dd48-3035-4be9-b6ca-0f4f0c672b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': 'a7f3478b-d30e-4717-a121-96dc988d2fb2',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatPromptTemplate',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': 'e0bcca54-4521-4a16-a8e3-1154e1c815a1',\n",
      "            'metadata': {},\n",
      "            'name': 'ChatPromptTemplate',\n",
      "            'start_time': '2024-02-21T14:56:20.635+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'prompt'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatPromptTemplate/final_output',\n",
      "  'value': ChatPromptValue(messages=[HumanMessage(content='tell me a joke about bears')])},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatPromptTemplate/end_time',\n",
      "  'value': '2024-02-21T14:56:20.636+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '171a063f-740f-4c76-915c-7655d60cf5ea',\n",
      "            'metadata': {},\n",
      "            'name': 'ChatOpenAI',\n",
      "            'start_time': '2024-02-21T14:56:20.648+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2'],\n",
      "            'type': 'llm'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Why')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': 'Why'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Why')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' did')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' did'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' did')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' bear')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' bear'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' bear')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' dissolve')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' dissolve'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' dissolve')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' water')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in water')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' water'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' water')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='?\\n\\n')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in water?\\n\\n')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': '?\\n\\n'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='?\\n\\n')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Because')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in water?\\n\\nBecause')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': 'Because'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Because')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' it')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in water?\\n\\nBecause it')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' it'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' it')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' was')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in water?\\n\\nBecause it was')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' was'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' was')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' polar')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in water?\\n\\nBecause it was polar')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' polar'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' polar')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='!')},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': AIMessageChunk(content='Why did the bear dissolve in water?\\n\\nBecause it was polar!')})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': '!'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='!')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/final_output',\n",
      "  'value': {'generations': [[{'generation_info': {'finish_reason': 'stop'},\n",
      "                              'message': AIMessageChunk(content='Why did the bear dissolve in water?\\n\\nBecause it was polar!'),\n",
      "                              'text': 'Why did the bear dissolve in water?\\n'\n",
      "                                      '\\n'\n",
      "                                      'Because it was polar!',\n",
      "                              'type': 'ChatGenerationChunk'}]],\n",
      "            'llm_output': None,\n",
      "            'run': None}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/end_time',\n",
      "  'value': '2024-02-21T14:56:23.708+00:00'})\n"
     ]
    }
   ],
   "source": [
    "async for s in chain.astream_log({\"topic\": \"bears\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803aff9e-79b1-40ea-a834-4034413d2553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
