{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb811ebe-9317-455f-be73-29e91855fd84",
   "metadata": {},
   "source": [
    "# RunnableParallel（并行处理输入输出）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de1262-b4c0-497b-961b-b18f838871da",
   "metadata": {},
   "source": [
    "输入：**RunnableParallel** 对于操作一个 **Runnable** 的输出以匹配序列中下一个 **Runnable** 的输入格式非常有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ded23-8f81-4d4b-bffa-ea4433ecab4f",
   "metadata": {},
   "source": [
    "请注意，当将 **RunnableParallel** 与另一个 **Runnable** 组合时，\n",
    "我们甚至不需要将字典包装在 **RunnableParallel** 类中 - 类型转换已为我们处理。 \n",
    "在链的上下文中，这些是等效的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf8881c-2c86-43bc-8a43-dcc1b7c267dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 以KV形式直接在链的上下文中做类型转换\n",
    "{\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "## KV参数构造\n",
    "RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "## 逐个参数构造\n",
    "RunnableParallel(context=retriever, question=RunnablePassthrough())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3333eb-2991-4f73-95ed-b948632c237e",
   "metadata": {},
   "source": [
    "使用 **itemgetter** 提取尚未分配的值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210e198-95b8-4a20-a0a9-15087f69876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"where did harrison work\", \"language\": \"italian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b461309-2e4e-48eb-ab80-c21c8cac6668",
   "metadata": {},
   "source": [
    "输出：也可以实现多个 **chain** 的并发调用，并返回一个键值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f69887-b47e-40aa-851d-08cbc47c82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n",
    "poem_chain = (\n",
    "    ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\") | model\n",
    ")\n",
    "\n",
    "map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "\n",
    "map_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d92ab-20b3-428e-96b0-93da898d058e",
   "metadata": {},
   "source": [
    "# RunnablePassthrough（额外输入）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fca6ec0-794c-4080-88cb-cf0bf356a499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4a1c7-2c21-4c22-9b46-f12e606bf630",
   "metadata": {},
   "source": [
    "# RunnableLambda（入参转换）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953c8b8-76f7-4445-a32d-11e7d244ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3205b1-a3e4-4791-8b5f-03a12339702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"foo\": \"bar\", \"bar\": \"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ba5bd-916a-4330-941b-c963650ddc5c",
   "metadata": {},
   "source": [
    "# RunnableBranch（动态路由）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207cf04-3659-48bc-9cc5-4a93d45bf35c",
   "metadata": {},
   "source": [
    "**RunnableBranch** 使用（条件、可运行）对列表和默认可运行来初始化。\n",
    "它通过传递调用它的输入的每个条件来选择哪个分支。 \n",
    "它选择第一个条件来评估为 True，并使用输入运行与该条件相对应的可运行程序。\n",
    "\n",
    "如果没有提供的条件匹配，它将运行默认的可运行程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa8937-e9fe-4777-8c3c-0a7265271da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: \"anthropic\" in x[\"topic\"].lower(), anthropic_chain),\n",
    "    (lambda x: \"langchain\" in x[\"topic\"].lower(), langchain_chain),\n",
    "    general_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc0f00-c579-4972-85f5-0540fca3bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = {\"topic\": chain, \"question\": lambda x: x[\"question\"]} | branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77520b-004e-47a9-99a7-2c30c35a1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthropic?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696929e0-0135-4abb-8f30-166d6e13cfef",
   "metadata": {},
   "source": [
    "同样的功能也可以使用自定义函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27d9ee-f9a7-4b2c-a5f8-2ba0094bdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return anthropic_chain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return langchain_chain\n",
    "    else:\n",
    "        return general_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e79c7-b283-4e7f-abf7-0cfba280c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = {\"topic\": chain, \"question\": lambda x: x[\"question\"]} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd73e2-75e8-48a8-b5d1-e2816cdda012",
   "metadata": {},
   "source": [
    "# bind（动态传递参数到Runnable）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07aa4a-294a-47bb-a1e1-2cb9642392c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传递stop参数\n",
    "runnable = (\n",
    "    {\"equation_statement\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model.bind(stop=\"SOLUTION\")\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(runnable.invoke(\"x raised to the third plus seven equals 12\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99795360-e1da-4999-9515-d3f9c04d9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绑定gpt函数（Need gpt-4 to solve this one correctly）\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Write out the following equation using algebraic symbols then solve it.\",\n",
    "        ),\n",
    "        (\"human\", \"{equation_statement}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4\", temperature=0).bind(\n",
    "    function_call={\"name\": \"solver\"}, functions=[function]\n",
    ")\n",
    "runnable = {\"equation_statement\": RunnablePassthrough()} | prompt | model\n",
    "runnable.invoke(\"x raised to the third plus seven equals 12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf388543-23ac-4568-ae9d-5ee244744ffb",
   "metadata": {},
   "source": [
    "# 链的配置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d4a86-fce2-402f-ad83-6f1320fd1652",
   "metadata": {},
   "source": [
    "# 使用@chain装饰器创建runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc95f1-5be1-4a54-9c70-3cab10e8aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1286ce1e-b19b-4f7d-a69f-9a503f48ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"What is the subject of this joke: {joke}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d7ffa-e2ea-4237-bfdc-d02fcaf39edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    prompt_val1 = prompt1.invoke({\"topic\": text})\n",
    "    output1 = ChatOpenAI().invoke(prompt_val1)\n",
    "    parsed_output1 = StrOutputParser().invoke(output1)\n",
    "    chain2 = prompt2 | ChatOpenAI() | StrOutputParser()\n",
    "    return chain2.invoke({\"joke\": parsed_output1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ed329-e173-4e5d-b62f-fe092106dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_chain.invoke(\"bears\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3cc1e-b2f3-42bf-808d-badd5c49c2cb",
   "metadata": {},
   "source": [
    "# fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6318df54-4f66-4cfa-b027-b16722f51b63",
   "metadata": {},
   "source": [
    "# 流式输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022faab-4571-4f3d-bb69-eea65b71962d",
   "metadata": {},
   "source": [
    "# 检查runnable的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb2432d-3fd1-4b96-980f-4353cbf35431",
   "metadata": {},
   "source": [
    "# 增加消息历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125cd89b-c978-4a60-b5fe-b91e3351d007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
