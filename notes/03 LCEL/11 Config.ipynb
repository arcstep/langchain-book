{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c5f8ed0-c3d9-4a1f-bcd3-21eab230fe00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56cbef8-9f64-48cb-9e6c-3e83c7e850c8",
   "metadata": {},
   "source": [
    "# 基本示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0a3bd8a8-d18b-4221-8121-447d6cf1a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"讲一个关于{topic}的笑话\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "802a51eb-e33c-4859-93d8-18676b57e600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ModelField(name='name', type=Optional[str], required=False, default=None),\n",
       " 'cache': ModelField(name='cache', type=Optional[bool], required=False, default=None),\n",
       " 'verbose': ModelField(name='verbose', type=bool, required=False, default_factory='<function _get_verbosity>'),\n",
       " 'callbacks': ModelField(name='callbacks', type=Union[List[langchain_core.callbacks.base.BaseCallbackHandler], BaseCallbackManager, NoneType], required=False, default=None),\n",
       " 'callback_manager': ModelField(name='callback_manager', type=Optional[BaseCallbackManager], required=False, default=None),\n",
       " 'tags': ModelField(name='tags', type=Optional[List[str]], required=False, default=None),\n",
       " 'metadata': ModelField(name='metadata', type=Optional[Mapping[str, Any]], required=False, default=None),\n",
       " 'client': ModelField(name='client', type=Optional[Any], required=False, default=None),\n",
       " 'async_client': ModelField(name='async_client', type=Optional[Any], required=False, default=None),\n",
       " 'model_name': ModelField(name='model_name', type=str, required=False, default='gpt-3.5-turbo', alias='model'),\n",
       " 'temperature': ModelField(name='temperature', type=float, required=False, default=0.7),\n",
       " 'model_kwargs': ModelField(name='model_kwargs', type=Mapping[str, Any], required=False, default_factory='<function dict>'),\n",
       " 'openai_api_key': ModelField(name='openai_api_key', type=Optional[str], required=False, default=None, alias='api_key'),\n",
       " 'openai_api_base': ModelField(name='openai_api_base', type=Optional[str], required=False, default=None, alias='base_url'),\n",
       " 'openai_organization': ModelField(name='openai_organization', type=Optional[str], required=False, default=None, alias='organization'),\n",
       " 'openai_proxy': ModelField(name='openai_proxy', type=Optional[str], required=False, default=None),\n",
       " 'request_timeout': ModelField(name='request_timeout', type=Union[float, Tuple[float, float], Any, NoneType], required=False, default=None, alias='timeout'),\n",
       " 'max_retries': ModelField(name='max_retries', type=int, required=False, default=2),\n",
       " 'streaming': ModelField(name='streaming', type=bool, required=False, default=False),\n",
       " 'n': ModelField(name='n', type=int, required=False, default=1),\n",
       " 'max_tokens': ModelField(name='max_tokens', type=Optional[int], required=False, default=None),\n",
       " 'tiktoken_model_name': ModelField(name='tiktoken_model_name', type=Optional[str], required=False, default=None),\n",
       " 'default_headers': ModelField(name='default_headers', type=Optional[Mapping[str, str]], required=False, default=None),\n",
       " 'default_query': ModelField(name='default_query', type=Optional[Mapping[str, object]], required=False, default=None),\n",
       " 'http_client': ModelField(name='http_client', type=Optional[Any], required=False, default=None)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in model.__fields__]\n",
    "model.__fields__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4737f660-f9b4-4ffd-8c1a-e20c580f6148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client': 'Any',\n",
       " 'async_client': 'Any',\n",
       " 'model_name': 'str',\n",
       " 'temperature': 'float',\n",
       " 'model_kwargs': 'Dict[str, Any]',\n",
       " 'openai_api_key': 'Optional[str]',\n",
       " 'openai_api_base': 'Optional[str]',\n",
       " 'openai_organization': 'Optional[str]',\n",
       " 'openai_proxy': 'Optional[str]',\n",
       " 'request_timeout': 'Union[float, Tuple[float, float], Any, None]',\n",
       " 'max_retries': 'int',\n",
       " 'streaming': 'bool',\n",
       " 'n': 'int',\n",
       " 'max_tokens': 'Optional[int]',\n",
       " 'tiktoken_model_name': 'Optional[str]',\n",
       " 'default_headers': 'Union[Mapping[str, str], None]',\n",
       " 'default_query': 'Union[Mapping[str, object], None]',\n",
       " 'http_client': 'Union[Any, None]'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1745feb2-1c7a-41a1-a0d7-faa7e522756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.config import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a6f5e68d-9d3c-44d4-b2fb-7a08f01be5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': ForwardRef('List[str]'),\n",
       " 'metadata': ForwardRef('Dict[str, Any]'),\n",
       " 'callbacks': ForwardRef('Callbacks'),\n",
       " 'run_name': ForwardRef('str'),\n",
       " 'max_concurrency': ForwardRef('Optional[int]'),\n",
       " 'recursion_limit': ForwardRef('int'),\n",
       " 'configurable': ForwardRef('Dict[str, Any]')}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnableConfig.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aeb9a213-3558-4173-a43c-a37a4673de1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._lc_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2241a593-48a3-4668-a648-cb39c519679e",
   "metadata": {},
   "source": [
    "# RunnableConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a2e1e-1072-448d-97a9-d28cf9168395",
   "metadata": {},
   "source": [
    "```python\n",
    "class RunnableConfig(TypedDict, total=False):\n",
    "    \"\"\"Configuration for a Runnable.\"\"\"\n",
    "\n",
    "    tags: List[str]\n",
    "    \"\"\"\n",
    "    Tags for this call and any sub-calls (eg. a Chain calling an LLM).\n",
    "    You can use these to filter calls.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata: Dict[str, Any]\n",
    "    \"\"\"\n",
    "    Metadata for this call and any sub-calls (eg. a Chain calling an LLM).\n",
    "    Keys should be strings, values should be JSON-serializable.\n",
    "    \"\"\"\n",
    "\n",
    "    callbacks: Callbacks\n",
    "    \"\"\"\n",
    "    Callbacks for this call and any sub-calls (eg. a Chain calling an LLM).\n",
    "    Tags are passed to all callbacks, metadata is passed to handle*Start callbacks.\n",
    "    \"\"\"\n",
    "\n",
    "    run_name: str\n",
    "    \"\"\"\n",
    "    Name for the tracer run for this call. Defaults to the name of the class.\n",
    "    \"\"\"\n",
    "\n",
    "    max_concurrency: Optional[int]\n",
    "    \"\"\"\n",
    "    Maximum number of parallel calls to make. If not provided, defaults to \n",
    "    ThreadPoolExecutor's default.\n",
    "    \"\"\"\n",
    "\n",
    "    recursion_limit: int\n",
    "    \"\"\"\n",
    "    Maximum number of times a call can recurse. If not provided, defaults to 25.\n",
    "    \"\"\"\n",
    "\n",
    "    configurable: Dict[str, Any]\n",
    "    \"\"\"\n",
    "    Runtime values for attributes previously made configurable on this Runnable,\n",
    "    or sub-Runnables, through .configurable_fields() or .configurable_alternatives().\n",
    "    Check .output_schema() for a description of the attributes that have been made \n",
    "    configurable.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656359f-31ab-4e5d-bb35-d8a816c697b9",
   "metadata": {},
   "source": [
    "# ConfigurableField"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7862355-f150-4331-b69b-7c29b581ebd6",
   "metadata": {},
   "source": [
    "```python\n",
    "class ConfigurableField(NamedTuple):\n",
    "    \"\"\"Field that can be configured by the user.\"\"\"\n",
    "\n",
    "    id: str\n",
    "\n",
    "    name: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    annotation: Optional[Any] = None\n",
    "    is_shared: bool = False\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.id, self.annotation))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6f3e4b6-3d55-4158-bc75-9705a6d4caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigurableField(id='run_name', name=None, description=None, annotation=None, is_shared=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "abc = ConfigurableField(\n",
    "    id=\"run_name\",\n",
    "    is_shared=True\n",
    ")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3eeee5ad-66e6-4ca6-a964-fc9cf752ade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.main.ChatPromptTemplateConfig"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.config_schema(include={\"run_name\":\"ABC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096253ef-0a9e-42f0-9069-6718246da5db",
   "metadata": {},
   "source": [
    "# Runnable的可配置类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcfca3d-1483-4cb1-b8b6-b6ec51e89db8",
   "metadata": {},
   "source": [
    "**config_schema 方法** 使用 `include` 参数和 `config_specs` 方法的返回值来创建一个 pydantic 模型，这个模型可以用来验证这个 Runnable 对象的配置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a8dc2c-788f-48bd-8400-51bcb34a457a",
   "metadata": {},
   "source": [
    "`config_specs` 方法应当返回一个 ConfigurableFieldSpec 对象的列表，每个 ConfigurableFieldSpec 对象代表一个可配置的字段。每个 ConfigurableFieldSpec 对象应该有一个 id 属性（字段的名称），一个 annotation 属性（字段的类型），以及一个 default 属性（字段的默认值）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc1a5a-41e0-4abc-a480-16d568543856",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"padding:5px\">\n",
    "如果想在你定制的 Runnable 子类中添加可配置的字段，你可以重载<b>config_specs</b>方法并返回一个包含你的字段的 ConfigurableFieldSpec 对象的列表。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f28f7-cd01-437d-b659-233c84795d33",
   "metadata": {},
   "source": [
    "`include 参数`允许你选择 RunnableConfig 中已经定义的字段，这些字段将被包含在新创建的 pydantic 模型中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215e89e-c3e4-47e3-b466-9fb182bc8e73",
   "metadata": {},
   "source": [
    "所以，`include` 和 `config_specs` 允许你从两个方向来定制你的配置模型：include 允许你选择已经存在的字段，而 config_specs 允许你添加新的字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf26e65d-d5c4-4556-a08c-fc04c896f3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableConfigurableFields(default=ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='讲一个关于{topic}的笑话'))]), fields={})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.configurable_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a20f58c-3d67-4b26-b366-42aeae690d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableConfigurableFields(default=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1134bfd30>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x113369840>, model_name='gpt-3.5-turbo-1106', openai_api_key='sk-SctYLVDdKoqPLXoKlLEMjLqHG2BhuOtQgjmMWvrTDqlKJeqz', openai_proxy=''), fields={})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.configurable_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0094b4-cdeb-426d-b6b9-ebf17475249e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
