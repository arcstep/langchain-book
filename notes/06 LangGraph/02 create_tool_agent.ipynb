{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0975d3fa-f0fd-4ba4-ac8a-155b06d56666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f9e50-910d-4760-b6e7-142bd1e4b5fd",
   "metadata": {},
   "source": [
    "# Set up the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4e4dd8-8115-409a-8a0a-f97a4b914941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8241c484-f52b-4c36-a5db-ff4cc590bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/langgraph/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langgraph\n",
      "  Downloading langgraph-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.3,>=0.2.22 (from langgraph)\n",
      "  Downloading langchain_core-0.2.23-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (0.1.82)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (1.10.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.22->langgraph) (8.4.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.22->langgraph) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.22->langgraph) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.22->langgraph) (2024.6.2)\n",
      "Downloading langgraph-0.1.11-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m27.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.23-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m17.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-core, langgraph\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.10\n",
      "    Uninstalling langchain-core-0.2.10:\n",
      "      Successfully uninstalled langchain-core-0.2.10\n",
      "Successfully installed langchain-core-0.2.23 langgraph-0.1.11\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/textlong-1Y1OoLLu-py3.10/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063f6972-b269-481c-867e-2344e567376f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToolExecutor\n\u001b[1;32m      3\u001b[0m tool_executor \u001b[38;5;241m=\u001b[39m ToolExecutor(tools)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05fc1c-dd8f-42a8-8231-92df373f751a",
   "metadata": {},
   "source": [
    "# Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae6ffd8-6765-4544-9ff5-07313d38a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# We will set streaming=True so that we can stream tokens\n",
    "# See the streaming section for more information on this.\n",
    "model = ChatOpenAI(temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27bb63e1-8f42-4e33-8b03-23f0b58c5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "tools = [convert_to_openai_tool(t) for t in tools]\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29315f-40b7-465f-a269-1dc681c3fccf",
   "metadata": {},
   "source": [
    "# Define the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7dbbb0-072b-4209-85d4-eb55e8aa86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(messages):\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"tool_calls\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Define the function to execute tools\n",
    "async def call_tool(messages):\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the tool_calls\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"tool_calls\"][\"name\"],\n",
    "        tool_input=json.loads(\n",
    "            last_message.additional_kwargs[\"tool_calls\"][\"arguments\"]\n",
    "        ),\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = await tool_executor.ainvoke(action)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return function_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb827a-4cd9-464b-bea6-d451f65953c0",
   "metadata": {},
   "source": [
    "# Define the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe327610-28ef-466d-aecf-24dd20dbbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessageGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = MessageGraph()\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10be91-b41a-4954-a68f-a1398b82cc1b",
   "metadata": {},
   "source": [
    "# Streaming LLM Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3fa7338-93f5-4be6-8dd7-9d854a0513b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': '__start__', 'run_id': 'bd3aceee-9ac5-4c23-a54e-ae89defe8da9', 'tags': ['graph:step:0', 'langsmith:hidden'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？')], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？')]}}\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'ChannelRead<__root__>', 'run_id': 'b300d80f-5f72-49b4-93d0-3885915be813', 'tags': ['seq:step:1', 'langsmith:hidden'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？')], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？')]}}\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'ChannelWrite<agent:inbox>', 'run_id': 'ade1b6a6-8d69-4263-a0de-23ae2889ccb4', 'tags': ['seq:step:2', 'langsmith:hidden'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？')], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？')]}}\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': '__start__:edges', 'run_id': '3e690cc7-8832-443d-bb57-52a8a9a95aab', 'tags': ['graph:step:1', 'langsmith:hidden'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？')], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？')]}}\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'RunnablePassthrough', 'run_id': 'b9325856-65c3-4c07-b7eb-d30d62e99a3e', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？')], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？')]}}\n",
      "on_chat_model_start\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})}}\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': '{\"', 'name': None}, 'type': None}]})}}\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': 'query', 'name': None}, 'type': None}]})}}\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': '\":\"', 'name': None}, 'type': None}]})}}\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': 'programming', 'name': None}, 'type': None}]})}}\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': ' jokes', 'name': None}, 'type': None}]})}}\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': '\"}', 'name': None}, 'type': None}]})}}\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_stream\n",
      "{'event': 'on_chat_model_stream', 'name': 'ChatOpenAI', 'run_id': '0b955f77-51c9-41fd-86eb-7023eaa90603', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content='')}}\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chat_model_end\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'ChannelWrite<agent,__root__>', 'run_id': 'cb5140ba-6b7b-494e-ab52-a095cc78b2b9', 'tags': ['seq:step:3'], 'metadata': {}, 'data': {'input': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}), 'output': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})}}\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'agent', 'run_id': 'e7345f61-1825-4ab0-837d-2fc58919c8ab', 'tags': ['graph:step:2'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？')], 'output': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})}}\n",
      "on_chain_stream\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_start\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'ChannelRead<__root__>', 'run_id': '283f5b74-79cc-4fca-8627-2182f694a783', 'tags': ['seq:step:1', 'langsmith:hidden'], 'metadata': {}, 'data': {'input': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}), 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})]}}\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'ChannelWrite<action:inbox>', 'run_id': '48dc43f8-b38e-4d81-a5b0-f0c36a224641', 'tags': ['langsmith:hidden'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})]}}\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'agent_condition', 'run_id': '52f41a88-df96-4d04-a121-be43a2ba3b36', 'tags': ['seq:step:2', 'langsmith:hidden'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})]}}\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'agent:edges', 'run_id': '1768ac6e-719a-4cbc-84c6-c23daf4afd7b', 'tags': ['graph:step:3', 'langsmith:hidden'], 'metadata': {}, 'data': {'input': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}), 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})]}}\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_start\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'RunnablePassthrough', 'run_id': '6408e9af-2653-42f8-8b5a-48c6c97e2a1e', 'tags': ['seq:step:1'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})], 'output': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})]}}\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'call_tool', 'run_id': '36e2cd69-b9ef-42f9-83b6-f2d6ed68b2ad', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})], 'output': None}}\n",
      "on_chain_end\n",
      "--\n",
      "{'event': 'on_chain_end', 'name': 'action', 'run_id': '5e1e8482-c97b-43bf-bf0d-c2c8f56c8e44', 'tags': ['graph:step:4'], 'metadata': {}, 'data': {'input': [HumanMessage(content='给我讲一个关于程序员的笑话？'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_5A84KbuOY6nC3AdIM757GATx', 'function': {'arguments': '{\"query\":\"programming jokes\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]})], 'output': None}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[1;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m给我讲一个关于程序员的笑话？\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream_events(inputs, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     kind \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(kind)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:905\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m root_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;66;03m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m _astream_log_implementation(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    908\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    909\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    910\u001b[0m     diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    911\u001b[0m     with_streamed_output_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    913\u001b[0m ):\n\u001b[1;32m    914\u001b[0m     run_log \u001b[38;5;241m=\u001b[39m run_log \u001b[38;5;241m+\u001b[39m log\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;66;03m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:612\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;66;03m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:566\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    563\u001b[0m prev_final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    564\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    567\u001b[0m     prev_final_output \u001b[38;5;241m=\u001b[39m final_output\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py:657\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, output_keys, input_keys, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_stream\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]]:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 657\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matransform(\n\u001b[1;32m    658\u001b[0m     input_stream(),\n\u001b[1;32m    659\u001b[0m     config,\n\u001b[1;32m    660\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m    661\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    663\u001b[0m ):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py:675\u001b[0m, in \u001b[0;36mPregel.atransform\u001b[0;34m(self, input, config, output_keys, input_keys, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    674\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]]:\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m    676\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    677\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform,\n\u001b[1;32m    678\u001b[0m         config,\n\u001b[1;32m    679\u001b[0m         output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m    680\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    682\u001b[0m     ):\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1616\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m         py_anext(iterator),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1614\u001b[0m     )\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1616\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m cast(Output, \u001b[38;5;28;01mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_id \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;66;03m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;66;03m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_map_by_run_id\u001b[38;5;241m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py:524\u001b[0m, in \u001b[0;36mPregel._atransform\u001b[0;34m(self, input, run_manager, config, input_keys, output_keys, interrupt)\u001b[0m\n\u001b[1;32m    517\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(\n\u001b[1;32m    518\u001b[0m     futures,\n\u001b[1;32m    519\u001b[0m     return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[1;32m    520\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m    521\u001b[0m )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# interrupt on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m \u001b[43m_interrupt_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# apply writes to channels\u001b[39;00m\n\u001b[1;32m    527\u001b[0m _apply_writes(\n\u001b[1;32m    528\u001b[0m     checkpoint, channels, pending_writes, config, step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    529\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py:698\u001b[0m, in \u001b[0;36m_interrupt_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m    696\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;66;03m# TODO this is where retry of an entire step would happen\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langgraph/pregel/__init__.py:838\u001b[0m, in \u001b[0;36m_aconsume\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_aconsume\u001b[39m(iterator: AsyncIterator[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    837\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Consume an async iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 838\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:4149\u001b[0m, in \u001b[0;36mRunnableBindingBase.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastream\u001b[39m(\n\u001b[1;32m   4144\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4145\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4146\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4147\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4148\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 4149\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m   4150\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4151\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4152\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   4153\u001b[0m     ):\n\u001b[1;32m   4154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2471\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_aiter\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m-> 2471\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matransform(input_aiter(), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2472\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2454\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   2449\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2450\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2451\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2453\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2454\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2455\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2456\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform,\n\u001b[1;32m   2457\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2458\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2459\u001b[0m     ):\n\u001b[1;32m   2460\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1616\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m         py_anext(iterator),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1614\u001b[0m     )\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1616\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m cast(Output, \u001b[38;5;28;01mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_id \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;66;03m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;66;03m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_map_by_run_id\u001b[38;5;241m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2424\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2417\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39matransform(\n\u001b[1;32m   2418\u001b[0m         final_pipeline,\n\u001b[1;32m   2419\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2422\u001b[0m         ),\n\u001b[1;32m   2423\u001b[0m     )\n\u001b[0;32m-> 2424\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:273\u001b[0m, in \u001b[0;36mRunnablePassthrough.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28minput\u001b[39m, identity, config\n\u001b[1;32m    275\u001b[0m     ):\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1576\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1574\u001b[0m input_for_tracing, input_for_transform \u001b[38;5;241m=\u001b[39m atee(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Start the input iterator to ensure the input runnable starts before this one\u001b[39;00m\n\u001b[0;32m-> 1576\u001b[0m final_input: Optional[Input] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m py_anext(input_for_tracing, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1577\u001b[0m final_input_supported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/utils/aiter.py:62\u001b[0m, in \u001b[0;36mpy_anext.<locals>.anext_impl\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manext_impl\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[T, Any]:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# The C code is way more low-level than this, as it implements\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;66;03m# all methods of the iterator protocol. In this implementation\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m# we're relying on higher-level coroutine concepts, but that's\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# exactly what we want -- crosstest pure-Python high-level\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# implementation and low-level C anext() iterators.\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;21m__anext__\u001b[39m(iterator)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/utils/aiter.py:97\u001b[0m, in \u001b[0;36mtee_peer\u001b[0;34m(iterator, buffer, peers, lock)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m iterator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:3728\u001b[0m, in \u001b[0;36mRunnableLambda.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3722\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   3723\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3724\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   3725\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3726\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3727\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 3728\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   3729\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform,\n\u001b[1;32m   3731\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafunc\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[1;32m   3732\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3733\u001b[0m     ):\n\u001b[1;32m   3734\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1616\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m         py_anext(iterator),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1614\u001b[0m     )\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1616\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m cast(Output, \u001b[38;5;28;01mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_id \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;66;03m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;66;03m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_map_by_run_id\u001b[38;5;241m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:3697\u001b[0m, in \u001b[0;36mRunnableLambda._atransform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   3696\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3697\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m acall_func_with_variable_args(\n\u001b[1;32m   3698\u001b[0m         cast(Callable, afunc), cast(Input, final), config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   3699\u001b[0m     )\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, use its astream output\u001b[39;00m\n\u001b[1;32m   3702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mcall_tool\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m     20\u001b[0m last_message \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# We construct an ToolInvocation from the tool_calls\u001b[39;00m\n\u001b[1;32m     22\u001b[0m action \u001b[38;5;241m=\u001b[39m ToolInvocation(\n\u001b[0;32m---> 23\u001b[0m     tool\u001b[38;5;241m=\u001b[39m\u001b[43mlast_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     24\u001b[0m     tool_input\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(\n\u001b[1;32m     25\u001b[0m         last_message\u001b[38;5;241m.\u001b[39madditional_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m     ),\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# We call the tool_executor and get back a response\u001b[39;00m\n\u001b[1;32m     29\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tool_executor\u001b[38;5;241m.\u001b[39mainvoke(action)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = [HumanMessage(content=\"给我讲一个关于程序员的笑话？\")]\n",
    "async for event in app.astream_events(inputs, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    print(kind)\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(event)\n",
    "        # chunk = event[\"data\"][\"chunk\"]\n",
    "        # for x in chunk:\n",
    "        #     if \"content\" in chunk:\n",
    "        #         print(chunk['content'], end=\"|\", flush=True)\n",
    "    elif kind == \"on_chain_end\":\n",
    "        print(\"--\")\n",
    "        print(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f12383-9861-4bf0-931e-8aff2c867578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict, Union\n",
    "\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage, ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "\n",
    "\n",
    "def create_tool_calling_executor(\n",
    "    model: LanguageModelLike, tools: Union[ToolExecutor, Sequence[BaseTool]]\n",
    "):\n",
    "    if isinstance(tools, ToolExecutor):\n",
    "        tool_executor = tools\n",
    "        tool_classes = tools.tools\n",
    "    else:\n",
    "        tool_executor = ToolExecutor(tools)\n",
    "        tool_classes = tools\n",
    "    model = model.bind(tools=[convert_to_openai_tool(t) for t in tool_classes])\n",
    "\n",
    "    # We create the AgentState that we will pass around\n",
    "    # This simply involves a list of messages\n",
    "    # We want steps to return messages to append to the list\n",
    "    # So we annotate the messages attribute with operator.add\n",
    "    class AgentState(TypedDict):\n",
    "        messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "    # Define the function that determines whether to continue or not\n",
    "    def should_continue(state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If there is no function call, then we finish\n",
    "        if \"tool_calls\" not in last_message.additional_kwargs:\n",
    "            return \"end\"\n",
    "        # Otherwise if there is, we continue\n",
    "        else:\n",
    "            return \"continue\"\n",
    "\n",
    "    # Define the function that calls the model\n",
    "    def call_model(state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        response = model.invoke(messages)\n",
    "        # We return a list, because this will get added to the existing list\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    async def acall_model(state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        response = await model.ainvoke(messages)\n",
    "        # We return a list, because this will get added to the existing list\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # Define the function to execute tools\n",
    "    def _get_actions(state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        # Based on the continue condition\n",
    "        # we know the last message involves a tool call\n",
    "        last_message = messages[-1]\n",
    "        # We construct an AgentAction from each of the tool_calls\n",
    "        return (\n",
    "            [\n",
    "                ToolInvocation(\n",
    "                    tool=tool_call[\"function\"][\"name\"],\n",
    "                    tool_input=json.loads(tool_call[\"function\"][\"arguments\"]),\n",
    "                )\n",
    "                for tool_call in last_message.additional_kwargs[\"tool_calls\"]\n",
    "            ],\n",
    "            [\n",
    "                tool_call[\"id\"]\n",
    "                for tool_call in last_message.additional_kwargs[\"tool_calls\"]\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def call_tool(state: AgentState):\n",
    "        actions, ids = _get_actions(state)\n",
    "        # We call the tool_executor and get back a response\n",
    "        responses = tool_executor.batch(actions)\n",
    "        # We use the response to create a FunctionMessage\n",
    "        tool_messages = [\n",
    "            ToolMessage(content=str(response), tool_call_id=id)\n",
    "            for response, id in zip(responses, ids)\n",
    "        ]\n",
    "        # We return a list, because this will get added to the existing list\n",
    "        return {\"messages\": tool_messages}\n",
    "\n",
    "    async def acall_tool(state: AgentState):\n",
    "        actions, ids = _get_actions(state)\n",
    "        # We call the tool_executor and get back a response\n",
    "        responses = await tool_executor.abatch(actions)\n",
    "        # We use the response to create a FunctionMessage\n",
    "        tool_messages = [\n",
    "            ToolMessage(content=str(response), tool_call_id=id)\n",
    "            for response, id in zip(responses, ids)\n",
    "        ]\n",
    "        # We return a list, because this will get added to the existing list\n",
    "        return {\"messages\": tool_messages}\n",
    "\n",
    "    # Define a new graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Define the two nodes we will cycle between\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model, acall_model))\n",
    "    workflow.add_node(\"action\", RunnableLambda(call_tool, acall_tool))\n",
    "\n",
    "    # Set the entrypoint as `agent`\n",
    "    # This means that this node is the first one called\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "\n",
    "    # We now add a conditional edge\n",
    "    workflow.add_conditional_edges(\n",
    "        # First, we define the start node. We use `agent`.\n",
    "        # This means these are the edges taken after the `agent` node is called.\n",
    "        \"agent\",\n",
    "        # Next, we pass in the function that will determine which node is called next.\n",
    "        should_continue,\n",
    "        # Finally we pass in a mapping.\n",
    "        # The keys are strings, and the values are other nodes.\n",
    "        # END is a special node marking that the graph should finish.\n",
    "        # What will happen is we will call `should_continue`, and then the output of that\n",
    "        # will be matched against the keys in this mapping.\n",
    "        # Based on which one it matches, that node will then be called.\n",
    "        {\n",
    "            # If `tools`, then we call the tool node.\n",
    "            \"continue\": \"action\",\n",
    "            # Otherwise we finish.\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # We now add a normal edge from `tools` to `agent`.\n",
    "    # This means that after `tools` is called, `agent` node is called next.\n",
    "    workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "    # Finally, we compile it!\n",
    "    # This compiles it into a LangChain Runnable,\n",
    "    # meaning you can use it as you would any other runnable\n",
    "    return workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3af0c7-be19-4f69-9dc8-f746e9bd6b92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textlong-same-ipykernel",
   "language": "python",
   "name": "textlong-same-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
