{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b9eb04c-5f2c-498b-8061-29d552049a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab401a-d9ca-4507-9093-f3d17a1ee70f",
   "metadata": {},
   "source": [
    "# 对话缓存管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc96a10-3991-4298-b006-50d17a990916",
   "metadata": {},
   "source": [
    "## 基于内存的对话缓存：ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fedf6091-d87b-4861-b431-2376495fe67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'),\n",
       " AIMessage(content=\"what's up?\"),\n",
       " HumanMessage(content='你好啊'),\n",
       " AIMessage(content='你也好啊'),\n",
       " HumanMessage(content='你再好啊'),\n",
       " AIMessage(content='你又好啊')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")\n",
    "memory.save_context({\"input\": \"你好啊\"}, {\"output\": \"你也好啊\"})\n",
    "memory.save_context({\"input\": \"你再好啊\"}, {\"output\": \"你又好啊\"})\n",
    "\n",
    "memory.buffer_as_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab0cf5-84cd-4fec-b0de-0264c197437c",
   "metadata": {},
   "source": [
    "## 按窗口大保留对话缓存：ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "396a2598-358a-4a0d-84f8-907af42115ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='第二轮问'), AIMessage(content='第二轮答'), HumanMessage(content='第三轮问'), AIMessage(content='第三轮答')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "window = ConversationBufferWindowMemory(k=2)\n",
    "window.save_context({\"input\": \"第一轮问\"}, {\"output\": \"第一轮答\"})\n",
    "window.save_context({\"input\": \"第二轮问\"}, {\"output\": \"第二轮答\"})\n",
    "window.save_context({\"input\": \"第三轮问\"}, {\"output\": \"第三轮答\"})\n",
    "print(window.buffer_as_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b2890-17ae-4fc2-945f-798dedd04ab8",
   "metadata": {},
   "source": [
    "## 自动对历史信息做摘要：ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1910f63d-2fa0-4961-9330-65a88ce3486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': '\\n人类问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它能帮助人类发挥他们的全部潜力。人类向AI打招呼，AI回应说它是人类的AI助手，可以回答关于langchain的各种问题。'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    # buffer=\"The conversation is between a customer and a sales.\"\n",
    "    buffer=\"以中文表示\"\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"你好\"}, {\"output\": \"你好，我是你的AI助手。我能为你回答有关langchain的各种问题。\"})\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0797a312-fc58-4e4d-a217-f1cfb3658cdf",
   "metadata": {},
   "source": [
    "## 更多记忆类型\n",
    "\n",
    "- ConversationTokenBufferMemory: 根据 Token 数限定 Memory 大小\n",
    "  - https://python.langchain.com/docs/modules/memory/types/token_buffer\n",
    "- VectorStoreRetrieverMemory: 将 Memory 存储在向量数据库中，根据用户输入检索回最相关的部分\n",
    "  - https://python.langchain.com/docs/modules/memory/types/vectorstore_retriever_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023dd0f8-5b91-497a-8652-e497ea77fedd",
   "metadata": {},
   "source": [
    "# 在 LCEL 中直接使用对话缓存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949dee21-3488-4901-8523-c150a52a9d65",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\" style=\"padding: 5px\">\n",
    "    <b>进一步扩展</b><p>\n",
    "    这个例子中，使用了 langchain 的对话缓存类，同时也最大限度提供了代码逻辑的灵活性。<br>\n",
    "    在此基础上，很容易继续添加持久化的逻辑。\n",
    "\n",
    "langchain 中与记忆有关的两类工具都可以在下面的扩展中集成，如：\n",
    "\n",
    "- langchain.memory.chat_message_histories 对话数据持久化相关的\n",
    "- langchain.memory 按窗口大小、Token多少等建立缓存相关的\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc6827-589c-4758-9bce-c576a497b2be",
   "metadata": {},
   "source": [
    "## 在一个带有记忆体的上下文中执行LCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770dc986-e6bf-4e5b-bd03-866afe5f45d3",
   "metadata": {},
   "source": [
    "现在，构造一个基础的提示语模板："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0d8c6-0352-43f4-9c5f-33cd634cc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff63fb-7d97-4689-b311-157759f65ca3",
   "metadata": {},
   "source": [
    "实际上，我们的目标就是在LCEL运行逻辑中动态构造类似下面的提示语："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d09c09fb-6af6-4e40-87e8-ba2bcb39ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个AI助手'), AIMessage(content='你好,我的名字是王小明'), HumanMessage(content='你知道我现在的名字吗？')])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "prompt.invoke({\n",
    "    \"history\": [AIMessage(content=\"你好,我的名字是王小明\")],\n",
    "    \"question\": \"你知道我现在的名字吗？\"\n",
    "}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8c94f-6910-489c-bd19-76d67ac289c3",
   "metadata": {},
   "source": [
    "我们在LCEL运行环境中定义一个记忆体的共享变量，实现记忆体在各环节的提取和写入：<br>\n",
    "完整代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b05dfe8f-e01b-4698-9a59-7a9a279fd4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1：定义窗口记忆的上下文变量\n",
    "# ------------------------------\n",
    "# \n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "window = ConversationBufferWindowMemory(k=10)\n",
    "\n",
    "# step2：保存用户输入到记忆（实现 RunnableLambda 版本）\n",
    "# ------------------------------\n",
    "#\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import List, Iterator, AsyncIterator, Dict, Any\n",
    "\n",
    "def memory_input(input: Any) -> str:\n",
    "    window.chat_memory.add_user_message(input[\"question\"])\n",
    "    return window.buffer_as_messages\n",
    "\n",
    "# step3：保存AI输出到记忆\n",
    "# ------------------------------\n",
    "#\n",
    "def memory_output(messages: List[BaseMessage]) -> List[BaseMessage]:\n",
    "    window.chat_memory.add_ai_message(messages)\n",
    "    return(messages)\n",
    "\n",
    "# step4：定义Chain\n",
    "# ------------------------------\n",
    "#\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个AI助手\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(history=memory_input) \n",
    "    | prompt\n",
    "    | llm\n",
    "    | memory_output\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b2f14521-ff5f-4cf2-9dc8-a31722d39676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好，王小明！有什么问题我可以帮助你解决呢？'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\":\"我的名字是王小明\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5b189bed-ba08-4ef2-bbc9-522347997730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'是的，我知道你的名字是王小明。有什么问题我可以帮助你解决吗？'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以使用异步方法调用\n",
    "await chain.ainvoke({\"question\":\"你现在知道我的名字吗？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a866f6-3c5b-43ba-b175-52102506e531",
   "metadata": {},
   "source": [
    "## 支持流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d2330ab-d919-410b-b508-d942ce38fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存AI输出\n",
    "# 注意：如果要支持流式输出，就必须按照 RunnableGenerator 实现\n",
    "def memory_output_stream(x: Iterator[Any]) -> Iterator[str]:\n",
    "    chunks = \"\"\n",
    "    try:\n",
    "        for chunk in x:\n",
    "            chunks += chunk.content\n",
    "            yield chunk\n",
    "    finally:\n",
    "        window.chat_memory.add_ai_message(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85701ecd-ad4a-4c09-a2f8-badb59aaf9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(history=memory_input) \n",
    "    | prompt\n",
    "    | llm\n",
    "    | memory_output_stream\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaed787d-9fa8-44f2-a9bb-6f08a315fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|你|好|，|小|明|！|有|什|么|可以|帮|到|你|的|吗|？||"
     ]
    }
   ],
   "source": [
    "# invoke\n",
    "for chunk in chain.stream({\"question\": \"我是小明\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a8fbcf-86cd-44f2-bf22-23b422e3574c",
   "metadata": {},
   "source": [
    "## 支持异步流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b6a82cf-5394-4663-baa8-1822713aca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def memory_output_astream(x: AsyncIterator[Any]) -> AsyncIterator[str]:\n",
    "    chunks = \"\"\n",
    "    try:\n",
    "        async for chunk in x:\n",
    "            chunks += chunk.content\n",
    "            yield chunk\n",
    "    finally:\n",
    "        window.chat_memory.add_ai_message(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96d5e7d8-9cfb-48d1-8937-687f4ef9b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(history=memory_input) \n",
    "    | prompt\n",
    "    | llm\n",
    "    | memory_output_astream\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30bcf4e1-32b5-46c0-a5b7-691b0030ad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|你|好|，|小|明|！|有|什|么|可以|帮|助|你|的|吗|？||"
     ]
    }
   ],
   "source": [
    "# invoke\n",
    "async for chunk in chain.astream({\"question\": \"我是小明\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d2345-837a-4b2a-bfa7-7786e2244c6f",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c2b57-0a15-4c1b-9237-28fd28ad58f8",
   "metadata": {},
   "source": [
    "从上面实现的方法中可以看到：\n",
    "\n",
    "既要管理执行环境中的记忆体变量，又要实现 invoke / stream /astream 等方法，需要较多代码定义。<br>\n",
    "你可能需要一个封装好的框架。\n",
    "\n",
    "实际上，在langchain中已经有两种封装方案：\n",
    "- 依靠 Chain 结构使用记忆体\n",
    "- 使用 RunnableWithMessageHistory 使用记忆体\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cbbadc-820c-4053-aa7c-67cb59ae17b1",
   "metadata": {},
   "source": [
    "# 结合 LLMChain 中使用 Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db499dbf-c211-45fc-abe6-131c30586fd8",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\" style=\"padding:5px\">\n",
    "使用 LLMChain 非常方便，但没有实现 stream、astream、astream_events 等流式响应的方法。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9126d-80d3-4b1c-8cb5-b1c060046787",
   "metadata": {},
   "source": [
    "## 使用 LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fe254426-586d-4dbb-b7ea-f6a8c7fc5b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个懂得多轮对话的助手\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "# 注意：使用 `return_messages=True` 匹配 MessagesPlaceholder\n",
    "# 注意：使用 `\"chat_history\"` 匹配提示语中的 MessagesPlaceholder\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(llm=llm, prompt=prompt, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d43febd2-033f-4a2c-91de-147454f5aaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '我是孙小圣',\n",
       " 'chat_history': [HumanMessage(content='我是孙小圣'),\n",
       "  AIMessage(content='你好，孙小圣！有什么可以帮助你的吗？')],\n",
       " 'text': '你好，孙小圣！有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"input\": \"我是孙小圣\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6d1807f7-8d78-496a-b650-cf50c3d09b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道我的名字吗？',\n",
       " 'chat_history': [HumanMessage(content='我是孙小圣'),\n",
       "  AIMessage(content='你好，孙小圣！有什么可以帮助你的吗？'),\n",
       "  HumanMessage(content='你知道我的名字吗？'),\n",
       "  AIMessage(content='是的，你刚刚告诉我你是孙小圣。有什么问题需要我帮忙解决吗？')],\n",
       " 'text': '是的，你刚刚告诉我你是孙小圣。有什么问题需要我帮忙解决吗？'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"input\": \"你知道我的名字吗？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fd994-67aa-4f0d-9ac7-b3d374d93cba",
   "metadata": {},
   "source": [
    "## 使用 ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c229c8-93fa-4086-89ab-bccee5ee604b",
   "metadata": {},
   "source": [
    "LLMChain的子类 ConversationChain 可以简化上述代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fc64ab5c-5cbc-479d-927c-81683362c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "conversation = ConversationChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "990581b7-bb67-4bff-b3a5-0238b991ded9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '我是孙小圣',\n",
       " 'history': '',\n",
       " 'response': '你好，孙小圣先生！我是你的AI助手，很高兴认识你。有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"input\": \"我是孙小圣\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f26c45be-dd91-44f4-8c6b-9002a47b49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道我的名字吗？',\n",
       " 'history': 'Human: 我是孙小圣\\nAI: 你好，孙小圣先生！我是你的AI助手，很高兴认识你。有什么可以帮助你的吗？',\n",
       " 'response': '当然知道啦，你刚才告诉我你是孙小圣先生啊！你有什么想要了解或者讨论的吗？'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"input\": \"你知道我的名字吗？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71ceef-f2a9-4037-ab60-40d3e41d7b02",
   "metadata": {},
   "source": [
    "## LLMChain的不足"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3802a0-21a2-441d-9398-d306fe5122f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Chain 相关类是一个遗留技术分支</b><br>\n",
    "    LLMChain 属于 Chain 技术生态的一种是实现。<br>\n",
    "    这类实现使用起来都非常方便，但没有实现 stream、astream、astream_events 等方法。<br><br>\n",
    "    Chain 技术生态是一个遗留技术分支，新的功能模块应当尽量考虑采用 LCEL 或者 langgraph 两个技术分支。<br>\n",
    "    但 Chain 已经实现了包括 LLMChain 在内的非常丰富的生态成果。因此，langchain 官方打算继续维护 Chain 这个技术分支，直到给出 LCEL 的替代版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8eed6128-444f-425e-a01f-2528e338fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '你知道我的本领是什么吗？', 'history': 'Human: 我是孙小圣\\nAI: 你好，孙小圣先生！我是你的AI助手，很高兴认识你。有什么可以帮助你的吗？\\nHuman: 你知道我的名字吗？\\nAI: 当然知道啦，你刚才告诉我你是孙小圣先生啊！你有什么想要了解或者讨论的吗？', 'response': '据我的记录显示，您的本领包括编程、数据分析和人工智能等领域。您在这些领域有很深的造诣，是一个非常优秀的专家。您还有其他特长吗？我很乐意了解更多关于您的信息。'}\n"
     ]
    }
   ],
   "source": [
    "for chunk in conversation.stream({\"input\": \"你知道我的本领是什么吗？\"}):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e43f0-f52b-474e-873f-25faa7e6929d",
   "metadata": {},
   "source": [
    "# 使用 RunnableWithMessageHistory 管理记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e96cd-4c3d-41a6-8620-9aa37da22609",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\" style=\"padding:5px\">\n",
    "可以全面支持 LCEL 的所有方法，包括 stream 等，但不能灵活地管理对话窗口。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "294e4bee-9926-48a5-b537-0e50c0b1ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个擅长{ability}的助手，每次返回20个以内的字即可\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 构建链\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb5eec36-555d-4afd-a879-b8b998731476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptInput(ability=None, history=None, input=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在要运行链，需要三个输入参数\n",
    "chain.input_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561e699-e240-4081-8bcb-0c280a70e814",
   "metadata": {},
   "source": [
    "## 在内存中保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc9b163-2631-4570-997b-b1ff791c81d0",
   "metadata": {},
   "source": [
    "**ChatMessageHistory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc809546-158a-4023-9e32-e0414408f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2cdd2929-55c0-4bd4-aa10-0e238235679a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='三角函数是一类描述角度和三角形边长关系的数学函数。')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第 1 次\n",
    "with_message_history.invoke(\n",
    "    {\"ability\": \"数学\", \"input\": \"三角函数是什么意思?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3f78f48b-6abb-4e91-9570-d29b8dce42bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|三|角|函数|就|是|一|种|数|学|工|具|，|帮|助|我们|计|算|和|描述|三|角|形|里|面|的|角|度|和|边|长|关|系|。|就|像|用|魔|法|棒|一|样|，|帮|我们|解|决|数|学|难|题|。||"
     ]
    }
   ],
   "source": [
    "# 第 2 次\n",
    "for chunk in with_message_history.stream(\n",
    "    {\"ability\": \"数学\", \"input\": \"可以用小学三年级小朋友能听懂的话解释吗？\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    "):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9929491-632c-4e05-b94e-284d24c31780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': ChatMessageHistory(messages=[HumanMessage(content='三角函数是什么意思?'), AIMessage(content='三角函数是一类描述角与边之间关系的数学函数，包括正弦、余弦、正切、余切、正割和余割等。这些函数在几何学、物理学、工程学等领域中有广泛的应用。'), HumanMessage(content='可以用小学三年级小朋友能听懂的话解释吗？'), AIMessage(content='三角函数就是一种用来帮助我们计算三角形内角和边之间关系的工具。比如，我们可以用它来帮助我们求出三角形中的角度大小或者边长等信息。')])}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时 store 中多了两条消息历史\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29956563-6901-442c-b49d-a16faf631743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='当我们在数学里谈到\"20以内\"，就是指所有小于等于20的数字哦！比如1、2、3、4、5、6、7、8、9、10、11、12、13、14、15、16、17、18、19和20。')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果切换了 session_id 情况就会不同\n",
    "with_message_history.invoke(\n",
    "    {\"ability\": \"数学\", \"input\": \"可以用小学三年级小朋友能听懂的话解释吗？\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc456\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f7b98-da3b-4921-9ea3-ede4ef843bcb",
   "metadata": {},
   "source": [
    "## 自定义对话历史的键值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1db874a6-89f3-4350-a94e-ffd115d6c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    if (user_id, conversation_id) not in store:\n",
    "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
    "    return store[(user_id, conversation_id)]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"用户ID\",\n",
    "            description=\"用户唯一标识\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=\"对话ID\",\n",
    "            description=\"对话唯一标识\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40964694-2f7b-441e-ab99-0bd434945b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConfigurableFieldSpec(id='conversation_id', annotation=<class 'str'>, name='对话ID', description='对话唯一标识', default='', is_shared=True, dependencies=None),\n",
       " ConfigurableFieldSpec(id='user_id', annotation=<class 'str'>, name='用户ID', description='用户唯一标识', default='', is_shared=True, dependencies=None)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with_message_history 此时的配置项是 user_id 和 conversation_id\n",
    "with_message_history.config_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb702ae2-fb20-44d3-bdaf-4412ee32feb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，请问有什么数学问题我可以帮助您解决呢？')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此时调用就要提供 user_id 和 conversation_id\n",
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"你好\"},\n",
    "    config={\"configurable\": {\"user_id\": \"user-123\", \"conversation_id\": \"conv-1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6c46bd95-390a-4e7d-a4e3-5a87e7ab7d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('user-123',\n",
       "  'conv-1'): ChatMessageHistory(messages=[HumanMessage(content='你好'), AIMessage(content='你好，请问有什么数学问题我可以帮助您解决呢？')])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看对话历史记录，键值已经变为由 user_id 和 conversation_id 的值构成的元组\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6ef2f56-e0ae-4f63-ab81-d63a327ec9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'user_id': 'user-123',\n",
       "  'conversation_id': 'conv-1',\n",
       "  'message_history': ChatMessageHistory(messages=[HumanMessage(content='你好'), AIMessage(content='你好，请问有什么数学问题我可以帮助您解决呢？')])}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实际上 with_message_history 对象也已经通过 _merge_configs 函数动态绑定了对话历史\n",
    "with_message_history._merge_configs({\n",
    "    \"configurable\": {\n",
    "        \"user_id\": \"user-123\", \n",
    "        \"conversation_id\": \"conv-1\"\n",
    "    }\n",
    "})\n",
    "# 下面的输出结果在每次调用 invoke 时会作为 config 参数被携带"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9866fd-37b1-4ed7-9984-47fc512a3121",
   "metadata": {},
   "source": [
    "## 使用 output_messages_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036b2ef-54f0-4585-9a5e-9b500d4e680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel({\"output_message\": ChatOpenAI()})\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    output_messages_key=\"output_message\",\n",
    ")\n",
    "\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What did Simone de Beauvoir believe about free will\")],\n",
    "    config={\"configurable\": {\"session_id\": \"baz\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd898cc-ed13-490f-8eb4-c73cf44fbf6e",
   "metadata": {},
   "source": [
    "## 自定义记忆持久化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c04625-c166-4fe5-9dbc-d1571b036047",
   "metadata": {},
   "source": [
    "```python\n",
    "# 基类要求\n",
    "class BaseChatMessageHistory(ABC):\n",
    "    messages: List[BaseMessage]\n",
    "    \"\"\"必须重载：读取消息\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_message(self, message: BaseMessage) -> None:\n",
    "        \"\"\"必须重载：增加消息历史\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"必须重载：清除所有消息\"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98063d7e-dae8-4ae2-9784-4774c03d69c4",
   "metadata": {},
   "source": [
    "### 基于内存的记忆管理实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7704c4a1-0160-4406-96d1-9aac6d1d0c8a",
   "metadata": {},
   "source": [
    "```python\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "class ChatMessageHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"基于内存的消息历史管理，直接存储在内存列表中\"\"\"\n",
    "\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)    \n",
    "\n",
    "    def __init__(self, session_id: str, k: int):\n",
    "        self.file_path = Path(file_path)\n",
    "    \n",
    "    def add_message(self, message: BaseMessage) -> None:\n",
    "        \"\"\"增加新消息\"\"\"\n",
    "        self.messages.append(message)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7f654-58ea-47bb-ba9d-dc849103ee5c",
   "metadata": {},
   "source": [
    "### 基于文件的记忆管理实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901e1fb-1911-4c54-816c-55124a23a87c",
   "metadata": {},
   "source": [
    "这里是更完整的例子：[https://github.com/langchain-ai/langserve/blob/main/examples/chat_with_persistence_and_user/server.py]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6998a9-9606-4b94-a027-3bd041852c83",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    messages_from_dict,\n",
    "    messages_to_dict,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class FileChatMessageHistory(BaseChatMessageHistory):\n",
    "    \"\"\"基于文件管理消息历史的示范，所有消息存储在本地JSON文件中\n",
    "\n",
    "    参数:\n",
    "        file_path: 保存JSON文件的路径\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = Path(file_path)\n",
    "        if not self.file_path.exists():\n",
    "            self.file_path.touch()\n",
    "            self.file_path.write_text(json.dumps([]))\n",
    "\n",
    "    @property\n",
    "    def messages(self) -> List[BaseMessage]:  # type: ignore\n",
    "        \"\"\"从 JSON 文件提取历史消息\"\"\"\n",
    "        items = json.loads(self.file_path.read_text())\n",
    "        messages = messages_from_dict(items)\n",
    "        return messages\n",
    "\n",
    "    def add_message(self, message: BaseMessage) -> None:\n",
    "        \"\"\"将新消息增加到本地 JSON 文件\"\"\"\n",
    "        messages = messages_to_dict(self.messages)\n",
    "        messages.append(messages_to_dict([message])[0])\n",
    "        self.file_path.write_text(json.dumps(messages))\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"清理所有消息历史\"\"\"\n",
    "        self.file_path.write_text(json.dumps([]))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa028b3-c0f2-42b8-b6a5-e54685620ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
