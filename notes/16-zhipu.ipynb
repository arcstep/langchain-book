{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf794d1-56b9-4741-958c-e4c7a29cf680",
   "metadata": {},
   "source": [
    "# 智谱大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a08d8af-804e-4af6-a8c6-3d412a93bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c410b11-7325-4d64-9e95-46191ed599d4",
   "metadata": {},
   "source": [
    "## 智谱API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad20f5-2780-455e-9544-5986fbd04cfd",
   "metadata": {},
   "source": [
    "### 同步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ca73ad99-a4fe-4a54-ab10-3dd0c99de810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"讲一个关于程序员的笑话\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f15adf-8736-4bab-bbd6-5b42eec53bcc",
   "metadata": {},
   "source": [
    "### 异步调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0f840d-073f-480b-ab6b-225d4a5cf9c3",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>注意:</b><br>\n",
    "    智谱API的异步调用不支持流。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5dcc5-9905-478c-a4b9-5461a9efcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.asyncCompletions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "task_id = response.id\n",
    "prev_status = ''\n",
    "get_cnt = 0\n",
    "\n",
    "while prev_status != 'SUCCESS' and task_status != 'FAILED' and get_cnt <= 40:\n",
    "    result_response = client.chat.asyncCompletions.retrieve_completion_result(id=task_id)\n",
    "    current_status = result_response.task_status\n",
    "    if(current_status == \"PROCESSING\"):\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "    elif(current_status == \"SUCCESS\"):\n",
    "        print()\n",
    "        print(result_response.choices[0].message)\n",
    "    prev_status = current_status\n",
    "\n",
    "    time.sleep(2)\n",
    "    get_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574faba-7a31-4c2e-8772-ba6a5233175d",
   "metadata": {},
   "source": [
    "### 事件流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ba9b4-42a2-41dc-ae04-64a493c390db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\"},\n",
    "        {\"role\": \"user\", \"content\": \"我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    # print(chunk)\n",
    "    print(\"-\" * 80)\n",
    "    print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6522284-f42d-49ad-af52-6361a30b128c",
   "metadata": {},
   "source": [
    "### 函数回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3be26d-2688-49e2-b946-11d69a87d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8367745282338832529', function=Function(arguments='{\"date\":\"2024-01-01\",\"departure\":\"北京南站\",\"destination\":\"上海\"}', name='query_train_info'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你能帮我查询2024年1月1日从北京南站到上海的火车票吗？\"\n",
    "        }\n",
    "    ],\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"query_train_info\",\n",
    "                \"description\": \"根据用户提供的信息，查询对应的车次\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"departure\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"出发城市或车站\",\n",
    "                        },\n",
    "                        \"destination\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"目的地城市或车站\",\n",
    "                        },\n",
    "                        \"date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"要查询的车次日期\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"departure\", \"destination\", \"date\"],\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97719bd5-f6d3-42ea-8b8e-afe9f832efd0",
   "metadata": {},
   "source": [
    "## 作为 RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5638e8-0239-4d28-a823-b11fc3f018ee",
   "metadata": {},
   "source": [
    "### 基本功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0efd3192-a55e-43f4-87c3-eed109669e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "def zhipu_chat(messages: [str]):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-3-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b766065-6af9-4cc7-b4d0-2d166a559d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"讲一个关于程序员的笑话\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd003c64-d049-4086-bb9b-5b405a659933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146156, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。', role='assistant', tool_calls=None))], request_id='8367745522857040954', id='8367745522857040954', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhipu_chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f0fc0-c56e-4666-9326-2b1665d4206f",
   "metadata": {},
   "source": [
    "### 包装为 Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38630740-a807-4abe-a2bb-fa0453570906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "my_zhipu_chat = RunnableLambda(zhipu_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa9f933b-3d87-44a4-b30f-cce4077af8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146224, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。', role='assistant', tool_calls=None))], request_id='8367743907949124838', id='8367743907949124838', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_zhipu_chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0eeac3-e13d-4f0b-b596-224ceb4edfe2",
   "metadata": {},
   "source": [
    "## ZhipuAIChatTiny：最小实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae00ed7-e906-4c8c-84de-b49ad16f1205",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d42b0f75-38e2-4ee9-a05e-2b62e6852312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee69cc23-7cf2-4781-b22c-d7f3c6ac051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatTiny(BaseChatModel):\n",
    "    \"\"\"支持最新的智谱API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "    \n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        try:\n",
    "            # 声明 ZhipuAI 的客户端\n",
    "            from zhipuai import ZhipuAI\n",
    "            self.client = ZhipuAI()\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\n",
    "                \"Could not import zhipuai package. \"\n",
    "                \"Please install it via 'pip install zhipuai'\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"使用 ZhiputAI 的同步调用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[ChatGeneration(message=AIMessage(content=content))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb671693-67b2-419c-b45d-6f71748897f1",
   "metadata": {},
   "source": [
    "model='glm-3-turbo' created=1708153877 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='一个程序员走进一家酒吧，对调酒师说：“我要一杯咖啡，请不要加糖。”\\n\\n调酒师回答：“对不起，这里只卖酒。”\\n\\n程序员微笑着说：“那好吧，那就给我一杯while循环。”\\n\\n调酒师疑惑地问：“while循环是什么酒？”\\n\\n程序员回答：“就是一直给我倒，直到我说停。”', role='assistant', tool_calls=None))] request_id='8367745660295992105' id='8367745660295992105' usage=CompletionUsage(prompt_tokens=11, completion_tokens=83, total_tokens=94)\n",
    "content='一个程序员走进一家酒吧，对调酒师说：“我要一杯咖啡，请不要加糖。”\\n\\n调酒师回答：“对不起，这里只卖酒。”\\n\\n程序员微笑着说：“那好吧，那就给我一杯while循环。”\\n\\n调酒师疑惑地问：“while循环是什么酒？”\\n\\n程序员回答：“就是一直给我倒，直到我说停。”' role='assistant' tool_calls=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4064b74-9b37-49c7-af85-0bb8e4a93714",
   "metadata": {},
   "source": [
    "### 使用 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3849056a-737a-48a4-b277-b96be53b9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tiny = ZhipuAIChatTiny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e769ea77-cf06-4a70-ae9f-d4e850183a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='为什么程序员总是携带电脑？因为他们不想被人叫做\"裸奔者\"。')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tiny.invoke(\"讲一个关于程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dafe8-3367-4e67-be39-2e8bfa2aae86",
   "metadata": {},
   "source": [
    "### 使用 LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2efbe57-af87-465e-a87a-848e44a2b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm_tiny | StrOutputParser()\n",
    "chain.invoke(\"讲一个关于程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a949f28-944a-4de3-a968-a638d2a692ac",
   "metadata": {},
   "source": [
    "### 使用 Prompt + LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f315c64f-42c5-4309-a5eb-317539426b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好的，下面是一个关于程序员的笑话：\\n\\n为什么程序员不喜欢自然界？\\n\\n因为那里有太多的bugs（虫子/错误）！\\n\\n希望这个笑话能让您开心一下！'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"讲一个关于{topic}的笑话\")\n",
    "chain = prompt | llm_tiny | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"topic\": \"程序员\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8cde2-562d-4693-ae26-e001127e0d8f",
   "metadata": {},
   "source": [
    "### 使用流式输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad73202-4d5e-4589-b966-fd6eee9fa26d",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\", style=\"padding: 5px\">\n",
    "    <b>注意：</b><br>\n",
    "    因为我们没有实现 stream 方法，基类中的实现将自动调用 invoke 方法，然后一次性返回结果。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ab323c7-1763-41d4-b25c-333429bc622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么程序员总是混淆圣诞节和万圣节？因为 Oct 31 等于 Dec 25。_"
     ]
    }
   ],
   "source": [
    "for chunk in llm_tiny.stream(\"讲一个关于程序员的一句话笑话\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9dbbd-c90e-4d0c-b142-2f51bee0ca60",
   "metadata": {},
   "source": [
    "## ZhipuAIChatStream：支持流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd91e9f-4370-4f1b-be68-baad04563ffb",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a49c34a7-90b0-4fd3-8b52-901027cbf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "03e52ee2-19e2-4f39-a436-ddad0548abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatStream(BaseChatModel):\n",
    "    \"\"\"支持最新的智谱API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        try:\n",
    "            # 声明 ZhipuAI 的客户端\n",
    "            from zhipuai import ZhipuAI\n",
    "            self.client = ZhipuAI()\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\n",
    "                \"Could not import zhipuai package. \"\n",
    "                \"Please install it via 'pip install zhipuai'\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"使用 ZhiputAI 的同步调用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        choice = response.choices[0]\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[\n",
    "                ChatGeneration(\n",
    "                    message=AIMessage(content=choice.message.content),\n",
    "            )],\n",
    "        )\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        \"\"\"使用 ZhiputAI 的事件流用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        # 使用流输出\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in response:\n",
    "            choice = chunk.choices[0]\n",
    "            yield ChatGenerationChunk(\n",
    "                message=AIMessageChunk(content=choice.delta.content),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d0923-a2ae-4dfa-8a28-24c5845d2b73",
   "metadata": {},
   "source": [
    "### 使用 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1f7b2ce7-5d53-47d4-9ea6-eff280f8ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_stream = ZhipuAIChatStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "969c12be-0cd7-4fdd-89bc-0a49f4421bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_stream.invoke(\"讲一个程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcb2e1-e587-4bef-994f-c2338cc674bb",
   "metadata": {},
   "source": [
    "### 使用流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6b667e06-281d-4b03-9779-fe1b497aae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么_程序_员_总是_混淆_圣诞_节_和_万_圣_节_？_因为_ Oct_ _3_1_ _等于_ Dec_ _2_5_。__"
     ]
    }
   ],
   "source": [
    "for chunk in llm_stream.stream(\"讲一个关于程序员的一句话笑话\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7576f-ba07-4af2-bfde-48addef52ffc",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\", style=\"padding: 5px\">\n",
    "    <b>成功了！</b><br>\n",
    "    现在运行上面的代码，应当可以看到流式输出！\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa408cba-9e05-462a-a573-5f84ee025d9e",
   "metadata": {},
   "source": [
    "## ZhipuAIChat：完整实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a8d2e-2c69-4f72-b94a-16976a4bc62d",
   "metadata": {},
   "source": [
    "完整的实现较为繁琐，可以在前面实践的基础上补充：\n",
    "\n",
    "- 支持所有模型参数\n",
    "- 支持异步方法\n",
    "- 支持事件流推送\n",
    "- 支持智谱的Tool回调\n",
    "- 支持内置的search工具\n",
    "- 支持内置的检索工具\n",
    "- 支持图片生成能力\n",
    "- 支持调用中的异常\n",
    "- 提供便利的bind_tools方法\n",
    "- 提供基于Tool调用的Agent\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfd0fb-c590-4df6-b8fd-81551d54e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain_chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588e60c-2643-4ba1-9f41-881313d59d51",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <b>ZhipuAIChat的完整实现已经发布</b><br>\n",
    "    我将完整的实现作为 langchain_chinese 包的一部份发布了。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fe773-d3d5-4300-9e34-e08a00fe9414",
   "metadata": {},
   "source": [
    "**项目地址** [https://pypi.org/project/langchain_chinese/](https://pypi.org/project/langchain_chinese/)<br> \n",
    "**源代码地址** [https://github.com/arcstep/langchain_chinese](https://github.com/arcstep/langchain_chinese)\n",
    "\n",
    "你可以通过 pip 安装：\n",
    "\n",
    "```\n",
    "pip install langchain_chinese\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ef813-c528-45fc-b05f-1df5e2e3460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add langchain_chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "298c6312-53a4-477b-8291-607fe84d0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chinese import ZhipuAIChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "12ac93f3-3594-4a40-8738-9b0c4d7f1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ZhipuAIChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c6f497c0-cd86-464b-9b32-0fbd4b576a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='好的，我来讲一个轻松的笑话给您听。\\n\\n有一天，一只乌龟走进了一个酒吧，跟酒保说：“请给我来杯热腾腾的牛肉汤。”\\n\\n酒保有些惊讶地看着乌龟说：“你确定你要牛肉汤？但是我们这里是酒吧啊。”\\n\\n乌龟回答：“我知道，但是这么冷的天气，再喝酒我怕冻成龟汤了。”')"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"讲个笑话来听吧\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d01fbcce-2432-4559-b803-692057db62b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当|面对|这个问题|时|，|我们可以|根据|两种|不同的|情况进行|分析|：|\n",
      "\n",
      "-| 你|还没|出生|：|在|大多数|情况下|，|父母|在|结婚|时|，|他们的|孩子|还未|出生|。|也就是说|，|你|之所以|没有被|邀请|，|是因为|你还|未来|到|这个|世界上|。|这是|最|常见|和|最|普遍|的情况|。|\n",
      "-| 你|已|出生|但是|年|幼|：|如果你|在你的|父母|结婚|时|已经|出生|了|，|那么|你可能|没有被|邀请|是因为|你|太小|，|无法|理解|或|参与|婚礼|的全部|流程|。|在|许多|文化|中|，|小孩|往往|在|一定|年龄|后|才会|开始|参加|一些|正式|的|社交|活动|，|包括|婚礼|。|或者|有时候|父母|可能|认为|儿童|在|婚礼|上|可能会|感到|无聊|或|累|。|\n",
      "\n",
      "总的来说|，|请|记住|，|这不是|你的|错|，|也|并不|表示|你的|父母|不|爱你|。|他们|有|他们的|理由|，|这|可能|只是|因为|某些|实际情况|或者|社会|习俗|。|若|这是|出于|你的|好奇心|和对|父母|婚礼|典礼|的|渴望|，|你可以|尝试|跟|他们|聊聊|，|看看|他们|是否|愿意|分享|当时的|照片|、|故事|或|录像|。|这|无疑是|更|了解|他们|爱情|故事|的好|方法|。||"
     ]
    }
   ],
   "source": [
    "for s in llm.stream(\"我父母结婚为什么不邀请我参加？\"):\n",
    "    print(s.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b01bd70f-2d54-4caf-81da-4e43dd6b8e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZhipuAIChat(client=<zhipuai._client.ZhipuAI object at 0x1192c81c0>)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = ZhipuAIChat(model=\"ABC\")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b0002b6a-dce9-45c2-8773-500d642a45b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glm-3-turbo'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f91ceb-7768-4afb-85b8-a6e847174ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
