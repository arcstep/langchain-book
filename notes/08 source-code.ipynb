{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be2c1f8-18eb-44ee-9760-dab03e479495",
   "metadata": {},
   "source": [
    "# langchain源码解读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9364e2a-53e2-4c03-a3b0-dea52e298a0b",
   "metadata": {},
   "source": [
    "## langchain模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3751a0-abc9-4ad9-9447-0a1029949644",
   "metadata": {},
   "source": [
    "### langchain主要生态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a25fdd-4ae1-477a-a397-be23551bc76d",
   "metadata": {},
   "source": [
    "- langchain 模块：以LCEL方式开发DAG结构的chain，也可以作为访问远程chain的python客户端\n",
    "- langgraph 模块：让LCEL支持循环结构的chain\n",
    "- langserve 模块：将chain转化为API\n",
    "- langchain-js 模块：提供langchain的`js`版本，也可以作为访问远程chain的JS客户端\n",
    "- langsmith 模块：跟踪和调试的平台\n",
    "- langfuse 模块：langsmith的开源平替"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b710ac2-bdb3-471a-aef1-3231f02334d9",
   "metadata": {},
   "source": [
    "### langchain模块的代码结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4bee0-1207-48c2-8aae-68b592e78ddc",
   "metadata": {},
   "source": [
    "- langchain：入口主模块\n",
    "- core：核心模块\n",
    "- community：社区贡献\n",
    "- partners：合作伙伴模块\n",
    "- experimetal：实验性模块\n",
    "- cli：命令行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be274e71-d310-4e7c-9979-42aed38bccdc",
   "metadata": {},
   "source": [
    "### LCEL相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d94e3f-6146-4b43-bfda-ccaf2f3357d9",
   "metadata": {},
   "source": [
    "- Runnable\n",
    "    **实用方法:**\n",
    "    - assign()\n",
    "    - bind()\n",
    "    - with_config()\n",
    "    - get_graph()\n",
    "\n",
    "    - RunnableSerializable（**LCEL**规则主要由**RunnableSequence**和**RunnableParallel**实现）\n",
    "        **实用方法:**\n",
    "        - dumps()\n",
    "        - loads(json: str)\n",
    "\n",
    "        **配置能力:**\n",
    "        - RunnableBindingBase\n",
    "            - RunnableBinding（向Runnable实例传递参数）\n",
    "        - DynamicRunnable\n",
    "            - RunnableConfigurableFields\n",
    "            - RunnableConfigurableAlternatives\n",
    "\n",
    "        **流程控制:**\n",
    "        - RunnablePassthrough（传递额外输入）\n",
    "        - RunnableSequence（实现顺序执行，可以用重载国的`|`符号或`RunnableSequence`来构造）\n",
    "        - RunnableParallel（实现并行执行，可以用`Dict`或`RunnableParallel`类来构造，别名`RunnableMap`）\n",
    "\n",
    "        **大模型:**\n",
    "        - BaseLanguageModel\n",
    "            - BaseLLM（派生其他大模型）\n",
    "                - LLM（派生其他大模型）\n",
    "                - OpenAIChat\n",
    "                - Tongyi\n",
    "\n",
    "        **提示语:**\n",
    "        - BasePromptTemplate `[Dict, PromptValue]`\n",
    "            - StringPromptTemplate（字符串模板）\n",
    "            - BaseChatPromptTemplate（对话模板）\n",
    "            - ImagePromptTemplate\n",
    "            - PipelinePromptTemplate\n",
    "\n",
    "        **检索器:**\n",
    "        - BaseRetriever `[RetrieverInput, RetrieverOutput]`（派生各类检索器）\n",
    "\n",
    "        **Tool:**\n",
    "        - BaseTool `[Union[str, Dict], Any]`（派生各类工具）\n",
    "\n",
    "        **输出解析:**      \n",
    "        - BaseGenerationOutputParser `[Union[str, BaseMessage], T]`\n",
    "        - BaseOutputParser（派生各类输出解析）\n",
    "\n",
    "        **输入赋值:**      \n",
    "        - RunnablePassthrough\n",
    "        - RunnableAssign\n",
    "        - RunnablePick\n",
    "\n",
    "        **Chains:**      \n",
    "        - Chain（结构化Runnable）\n",
    "            - AgentExecutor（执行智能体）\n",
    "\n",
    "    **定制能力:**\n",
    "    - RunnableGenerator（常用于处理输出可能是迭代器结果的chain）\n",
    "    - RunnableLambda（常用于包装普通函数，别名函数@chain）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b0f7c-535e-4b4c-a65f-28cd3c5e5b38",
   "metadata": {},
   "source": [
    "## Runnable（提供原语的基类）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679a335-8943-426e-bc6a-a8e0107e839d",
   "metadata": {},
   "source": [
    "**LangChain Runnable** 是一种工作单元, 支持同步、异步、批处理和流式操作。\n",
    "\n",
    "**LangChain表达式语言(LCEL)** 提供了一种声明式的方法来构建使用大语言模型的生产级程序。\n",
    "\n",
    "使用 **LCEL** 和 **LangChain Runnable** 构建的程序内在地支持同步、异步、批处理和流式操作。\n",
    "\n",
    "支持异步可以让托管基于 **LCEL** 程序的服务器更好地扩展,以处理更高的并发负载。\n",
    "\n",
    "流式输出中间结果的能力可以创建更响应的用户体验。\n",
    "\n",
    "**Runnable** 模块包含了 **LangChain Runnable** 原语的模式和实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5699e5-7e75-4d84-b645-8ed3bd68de1a",
   "metadata": {},
   "source": [
    "### 最主要的原语方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d972a-a568-4fbc-9d98-6b2bc72122d3",
   "metadata": {},
   "source": [
    "主要方法:\n",
    "\n",
    "- invoke/ainvoke: 将单个输入转换为输出。  \n",
    "- batch/abatch: 有效地将多个输入转换为输出。\n",
    "- stream/astream: 流式输出单个输入生成的结果。\n",
    "- astream_log: 流式输出输入的输出以及所选的中间结果。\n",
    "\n",
    "内置优化:  \n",
    "\n",
    "- 批处理: 默认情况下,批处理使用线程池执行器并行运行invoke()。 \n",
    "  <br>可以重写以优化批处理。\n",
    "\n",
    "- 异步: 带有“a”后缀的方法是异步的。默认情况下,它们使用asyncio的线程池执行同步版本。\n",
    "  <br>可以重写为原生异步。\n",
    "\n",
    "所有方法都接受一个可选的config参数,可用于配置执行、添加标签和元数据,以进行跟踪、调试等。  <br/>\n",
    "Runnable通过input_schema属性、output_schema属性和config_schema方法公开其输入、输出和配置的模式信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cee839-07b9-4e50-8ffe-9c724baff3b7",
   "metadata": {},
   "source": [
    "### 链的基本示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1884bd05-f2b6-414f-a0bc-cea2a842787b",
   "metadata": {},
   "source": [
    "LangChain表达式语言(LCEL)是一种声明式的方式来将Runnable组合成链。\n",
    "这样构建的任何链都将自动支持同步、异步、批处理和流操作。\n",
    "主要的组合原语是RunnableSequence和RunnableParallel。\n",
    "\n",
    "RunnableSequence按顺序调用一系列runnable,一个runnable的输出作为下一个的输入。\n",
    "可以使用 | 运算符构造,或者通过向RunnableSequence传入runnable列表。\n",
    "RunnableParallel并发调用runnable,向每个都提供相同的输入。\n",
    "可以在序列中使用字典字面量构造,或者通过向RunnableParallel传入字典来构造。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed48f8-e728-4ff8-af4e-8aadff9d1e50",
   "metadata": {},
   "source": [
    "代码示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5590f265-1411-4157-960d-7b90ba5fb720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[4, 5, 6]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, chain\n",
    "\n",
    "@chain\n",
    "def a(x):\n",
    "    return(x + 1)\n",
    "\n",
    "@chain\n",
    "def b(x):\n",
    "    return(x + 2)\n",
    "\n",
    "@chain\n",
    "def c(dict):\n",
    "    return(dict[\"x\"] + dict[\"y\"])\n",
    "    \n",
    "sequence = a | b\n",
    "\n",
    "print(sequence.invoke(1))\n",
    "print(sequence.batch([1, 2, 3]))\n",
    "\n",
    "parral = {\"x\": a, \"y\": b} | c\n",
    "print(parral.invoke(1)) # (1+1) + (1+2) = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd3aaa-1f65-49e0-8280-0e8e1acbd867",
   "metadata": {},
   "source": [
    "### LCEL提供的好处"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460d100-ea6e-4ca0-84d9-d1c71e2dc887",
   "metadata": {},
   "source": [
    "LangChain Expression Language（LCEL）是一种声明式语言，可轻松组合不同的调用顺序构成 Chain。LCEL 自创立之初就被设计为能够支持将原型投入生产环境，**无需代码更改**，从最简单的“提示+LLM”链到最复杂的链（已有用户成功在生产环境中运行包含数百个步骤的 LCEL Chain）。\n",
    "\n",
    "LCEL的一些亮点包括：\n",
    "\n",
    "1. **流支持**：使用 LCEL 构建 Chain 时，你可以获得最佳的首个令牌时间（即从输出开始到首批输出生成的时间）。\n",
    "对于某些 Chain，这意味着可以直接从LLM流式传输令牌到流输出解析器，从而以与 LLM 提供商输出原始令牌相同的速率获得解析后的、增量的输出。\n",
    "\n",
    "2. **异步支持**：任何使用 LCEL 构建的链条都可以通过同步API（例如，在 Jupyter 笔记本中进行原型设计时）和异步 API（例如，在 LangServe 服务器中）调用。\n",
    "这使得相同的代码可用于原型设计和生产环境，具有出色的性能，并能够在同一服务器中处理多个并发请求。\n",
    "\n",
    "3. **优化的并行执行**：当你的 LCEL 链条有可以并行执行的步骤时（例如，从多个检索器中获取文档），我们会自动执行，无论是在同步还是异步接口中，以实现最小的延迟。\n",
    "\n",
    "4. **重试和回退**：为 LCEL 链的任何部分配置重试和回退。这是使链在规模上更可靠的绝佳方式。\n",
    "目前我们正在添加重试/回退的流媒体支持，因此你可以在不增加任何延迟成本的情况下获得增加的可靠性。\n",
    "\n",
    "5. **访问中间结果**：对于更复杂的链条，访问在最终输出产生之前的中间步骤的结果通常非常有用。\n",
    "这可以用于让最终用户知道正在发生一些事情，甚至仅用于调试链条。你可以流式传输中间结果，并且在每个LangServe服务器上都可用。\n",
    "\n",
    "6. **输入和输出模式**：输入和输出模式为每个 LCEL 链提供了从链的结构推断出的 Pydantic 和 JSONSchema 模式。\n",
    "这可以用于输入和输出的验证，是 LangServe 的一个组成部分。\n",
    "\n",
    "7. **无缝LangSmith跟踪集成**：随着链条变得越来越复杂，理解每一步发生了什么变得越来越重要。\n",
    "通过 LCEL，所有步骤都自动记录到 LangSmith，以实现最大的可观察性和可调试性。\n",
    "\n",
    "8. **无缝LangServe部署集成**：任何使用 LCEL 创建的链都可以轻松地使用 LangServe 进行部署。\n",
    "\n",
    "原文：[https://python.langchain.com/docs/expression_language]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af900c6-6eb5-4ac0-916e-1772967c6b06",
   "metadata": {},
   "source": [
    "#### 流支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86556b-ad13-4458-aa4f-ad9711f022ca",
   "metadata": {},
   "source": [
    "#### 异步支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc281ee-b75a-4e50-8bb1-29bf1bdf457a",
   "metadata": {},
   "source": [
    "#### 优化的并行执行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e95f49-f47f-40ae-bf3d-70b0192782a6",
   "metadata": {},
   "source": [
    "#### 重试和回退"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9b766-088e-43b0-8a5b-5067afb95e35",
   "metadata": {},
   "source": [
    "with_retry："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ae77cbb-8ea9-4c05-8f3e-93d622bbff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RunnableSequence\n",
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n",
      "<class 'list'>\n",
      "<class 'langchain_core.runnables.retry.RunnableRetry'>\n",
      "---Runnable\n",
      "RunnableSequence\n",
      "[]\n",
      "{'title': 'add_one_input', 'type': 'integer'}\n",
      "{'title': 'buggy_double_output', 'type': 'integer'}\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "This code failed, and will probably be retried!\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import random\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "def buggy_double(y: int) -> int:\n",
    "    '''Buggy code that will fail 70% of the time'''\n",
    "    if random.random() > 0.3:\n",
    "        print('This code failed, and will probably be retried!')\n",
    "        raise ValueError('Triggered buggy code')\n",
    "    return y * 2\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(add_one) |\n",
    "    RunnableLambda(buggy_double).with_retry( # Retry on failure\n",
    "        stop_after_attempt = 10,\n",
    "        wait_exponential_jitter = False\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"---RunnableSequence\")\n",
    "print(type(chain.first))\n",
    "print(type(chain.middle))\n",
    "print(type(chain.last))\n",
    "print(\"---Runnable\")\n",
    "print(chain.get_name())\n",
    "print(chain.get_prompts())\n",
    "print(chain.input_schema.schema()) # Show inferred input schema\n",
    "print(chain.output_schema.schema()) # Show inferred output schema\n",
    "\n",
    "print(chain.invoke(2)) # invoke the sequence (note the retry above!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f32d00-af1b-42fe-a9dd-bcfa6431f935",
   "metadata": {},
   "source": [
    "#### 访问中间结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eaef92-14b9-4d86-bcd1-484d9831a30c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**set_debug**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c763b-1a05-44e3-96d2-055957452e72",
   "metadata": {},
   "source": [
    "随着链的变长,能够看到中间结果以调试和跟踪链是很有用的。<br>\n",
    "您可以将全局调试标志设置为True,以为所有链启用调试输出:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f4676-ab2a-4820-aadf-8a5eabaa5361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_debug\n",
    "set_debug(True)\n",
    "\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e5c4f-1057-478e-8038-6b4915ce3768",
   "metadata": {},
   "source": [
    "**callbacks**：可以将现有或自定义回调传递给任何给定的链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5722a-f646-4352-8a6e-fd6585419309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.tracers import ConsoleCallbackHandler\n",
    "from langchain_core.globals import set_debug\n",
    "set_debug(False)\n",
    "\n",
    "chain.invoke(\n",
    "    3,\n",
    "    config={'callbacks': [ConsoleCallbackHandler()]} # 这与设置debug为true的效果类似\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b2507-0040-48d2-af16-98cac0194df5",
   "metadata": {},
   "source": [
    "**绘制LCEL执行结构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ec78c67c-9604-4db2-86dc-e18ef9a0bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +---------------+   \n",
      " | add_one_input |   \n",
      " +---------------+   \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+-----------------+  \n",
      "| Lambda(add_one) |  \n",
      "+-----------------+  \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+-----------------+  \n",
      "| Lambda(add_one) |  \n",
      "+-----------------+  \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+----------------+   \n",
      "| add_one_output |   \n",
      "+----------------+   \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.graph_draw import draw\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(add_one) | add_one\n",
    ")\n",
    "\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9957bf5-576d-45d8-90fe-ed6c494a1662",
   "metadata": {},
   "source": [
    "## 配置能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bdabf-f155-4254-bbce-225f91273817",
   "metadata": {},
   "source": [
    "`RunnableBinding` 可以被看作是一个\"Runnable对象的装饰器\"，它保留了 `Runnable` 的基本特性，即批处理、流处理和异步支持，同时添加了额外的功能。\n",
    "\n",
    "任何继承自 `Runnable` 的类都可以绑定到一个 `RunnableBinding`。\n",
    "`Runnable` 提供了一套标准的方法来创建 `RunnableBindings` 或 `RunnableBindings` 的子类（例如，`RunnableRetry`，`RunnableWithFallbacks`）以添加额外的功能。\n",
    "\n",
    "这些方法包括：\n",
    "- `bind`：绑定 kwargs 以在运行底层可运行对象时传递。\n",
    "- `with_config`：绑定配置以在运行底层可运行对象时传递。\n",
    "- `with_listeners`：将生命周期监听器绑定到底层可运行对象。\n",
    "- `with_types`：覆盖底层可运行对象的输入和输出类型。\n",
    "- `with_retry`：将重试策略绑定到底层可运行对象。\n",
    "- `with_fallbacks`：将回退策略绑定到底层可运行对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3778a99-a2b8-47ab-a6f9-d69736ff4080",
   "metadata": {},
   "source": [
    "### 配置能力相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770012c3-6dcb-49d3-b17b-ecb8a21256ca",
   "metadata": {},
   "source": [
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - RunnableBindingBase\n",
    "            - RunnableBinding（向Runnable底层传递参数，`.bind()`）\n",
    "            - RunnableWithMessageHistory（支持对话历史）\n",
    "            - RunnableRetry（支持重试，`.with_retry()`）\n",
    "            - HubRunnable（访问`LangChain Hub`的实例）\n",
    "            - OpenAIFunctionsRouter\n",
    "        - DynamicRunnable（支持动态配置）\n",
    "            - RunnableConfigurableFields\n",
    "            - RunnableConfigurableAlternatives\n",
    "        - RunnableWithFallbacks（支持报错回滚，`.with_fallbacks()`）\n",
    "        - RunnableAssign（`.assign()`）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14107ee5-04a0-4a1e-97d1-80db1e0150db",
   "metadata": {},
   "source": [
    "### assign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80031ca6-3183-4daf-a975-39a57bebdf38",
   "metadata": {},
   "source": [
    "为字典对象或RunnableParallel对象赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "96ca65d5-0e11-49bb-b0ec-35852af6982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'passed': {'num': 1}, 'num': 1, 'extra': {'num': 1, 'mult': 3}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed = RunnablePassthrough(),\n",
    "    num = itemgetter(\"num\"),\n",
    "    extra = RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3)\n",
    ")\n",
    "\n",
    "print(runnable.invoke({\"num\": 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d944895-354e-41c9-9420-b39c05aa537b",
   "metadata": {},
   "source": [
    "### bind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313fb2c-86bc-4bdc-8e8f-35be7a72f870",
   "metadata": {},
   "source": [
    "使用`bind`：可以绑定 kwargs 以在运行底层可运行对象时传递。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181c092-585b-4d64-9ab6-a4fd82aef167",
   "metadata": {},
   "source": [
    "#### 将 stop 传递给 OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ac9d261e-f675-4fa9-b77f-9dd83a879f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Parrot')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个可运行绑定，它在运行时调用 ChatModel，并传递额外的 kwarg `stop=['-']`。\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI()\n",
    "model.invoke('Say \"Parrot-MAGIC\"', stop=['-']) # 应返回 `Parrot`\n",
    "\n",
    "# 通过 `bind` 方法（它返回一个新的 RunnableBinding）来简单地使用它\n",
    "runnable_binding = model.bind(stop=['-'])\n",
    "runnable_binding.invoke('Say \"Parrot-MAGIC\"') # 应返回 `Parrot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85734af-9f38-4730-8c14-6b8c879cf615",
   "metadata": {},
   "source": [
    "#### 将 seed 传递给 OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "52dab158-f2cc-4ee1-8f62-2740d9e5a371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是一个基于神经网络的模型，被称为GPT-3（Generative Pre-trained Transformer 3）。我是由OpenAI开发的，用于自然语言处理和生成文本的任务。')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bind(seed=42).invoke(\"你是什么模型?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "03c9e1f2-e5b1-4032-8d13-b21b6afa2e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是一个基于神经网络的模型，被称为GPT-3（Generative Pre-trained Transformer 3）。我是由OpenAI开发的，用于自然语言处理和生成文本的任务。')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bind(seed=42).invoke(\"你是什么模型?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8221b4ab-68cc-492a-a328-e5a710ffc99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是一个基于人工智能技术的对话系统模型，被称为GPT-3（Generative Pre-trained Transformer 3）。我被训练来理解和生成自然语言，可以提供各种领域的信息和帮助回答问题。')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bind(seed=43).invoke(\"你是什么模型?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ae616-4759-4820-b8b4-911e73939f05",
   "metadata": {},
   "source": [
    "### 根据配置动态选择Runnable对象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd489d-bf2f-4931-9e16-4f511be345f2",
   "metadata": {},
   "source": [
    "## 流程控制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae48fa-3c63-408f-8b7e-419371713c91",
   "metadata": {},
   "source": [
    "Runnable 可以支持包括顺序、分支、条件、迭代等多种控制方式，构建较复杂的有向无环图。\n",
    "\n",
    "与直接使用python代码控制流程不同的是，下面这些流程控制手段仍然保持以Runnable返回，以便获得LCEL的诸多额外好处，如：Runnable的统一方法、序列化能力、重试能力、回滚能力、Langsmith追踪和Langserve的API集成等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fa90f-bdae-426e-bfcf-d51910ee51f2",
   "metadata": {},
   "source": [
    "### 流程控制相关类结构"
   ]
  },
  {
   "cell_type": "raw",
   "id": "663b876f-f58b-41d3-b336-54536794e31f",
   "metadata": {},
   "source": [
    "可接受参数：\n",
    "\n",
    "Union[\n",
    "    Runnable[Input, Output],\n",
    "    Callable[[Input], Output],\n",
    "    Callable[[Input], Awaitable[Output]],\n",
    "    Callable[[Iterator[Input]], Iterator[Output]],\n",
    "    Callable[[AsyncIterator[Input]], AsyncIterator[Output]],\n",
    "    Mapping[str, Any],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4af7a9-5f32-480f-8f6d-5f61b01e2504",
   "metadata": {},
   "source": [
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - RunnableSequence（实现顺序执行，可以用|符号或RunnableSequence来构造）\n",
    "        - RunnableParallel（实现并行执行，可以用Dict或RunnableParallel类来构造，别名RunnableMap）\n",
    "        - RunnableEach（实现相同的链迭代多次）\n",
    "        - RunnableBranch（实现流程分支，根据条件选择不同的链执行）\n",
    "        - RouterRunnable（实现流程分支，根据枚举值选择不同的链执行）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7adb8a-ffc1-4b85-b88d-1f0d55b56a57",
   "metadata": {},
   "source": [
    "### RunnableSerializable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ae80c-4945-4211-974f-56885a2d4c4d",
   "metadata": {},
   "source": [
    "主要增加了序列化的方法，可以将Runnable以JSON字符串的方式保存或加载：\n",
    "\n",
    "- loads / dumps （按JSON字符串）\n",
    "- load / dumpd （按Dict类型）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c73a1-e9f0-4aea-9569-8d988a1a1e1c",
   "metadata": {},
   "source": [
    "#### 将Runnable保存为JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c142f978-a4d7-4be1-8092-3294c977aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from typing import Iterator\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chant = (\n",
    "    ChatPromptTemplate.from_template(\"Give me a 3 word chant about {topic}\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fc6a0158-5e63-416d-88f3-81ff99f52fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"runnable\", \"RunnableSequence\"], \"kwargs\": {\"first\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"chat\", \"ChatPromptTemplate\"], \"kwargs\": {\"input_variables\": [\"topic\"], \"messages\": [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"chat\", \"HumanMessagePromptTemplate\"], \"kwargs\": {\"prompt\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"prompts\", \"prompt\", \"PromptTemplate\"], \"kwargs\": {\"input_variables\": [\"topic\"], \"template\": \"Give me a 3 word chant about {topic}\", \"template_format\": \"f-string\", \"partial_variables\": {}}}}}]}}, \"middle\": [{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"openai_api_key\": {\"lc\": 1, \"type\": \"secret\", \"id\": [\"OPENAI_API_KEY\"]}}}], \"last\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output_parser\", \"StrOutputParser\"], \"kwargs\": {}}, \"name\": null}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.load import loads, dumps\n",
    "json = dumps(chant)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34fe0a5-4d95-4511-8917-46e5b8a34288",
   "metadata": {},
   "source": [
    "#### 从JSON中恢复Runnable并调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b620d7e3-e74b-44ef-9576-6d77d9f7b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Apple, sweet success!\"'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loads(json).invoke({\"topic\":\"苹果\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1af0a-63cb-44e8-9b8d-043cabb1b916",
   "metadata": {},
   "source": [
    "#### 根据配置动态选择Runnable对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1912a9be-7785-4850-be90-bba30ff99153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.runnables import ConfigurableField, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Give me a 3 word chant about {topic}\")\n",
    "openai = ChatOpenAI()\n",
    "llm = OpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "configurable_model = llm.configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"), \n",
    "    default_key=\"llm_openai\", \n",
    "    chat_openai=openai\n",
    ")\n",
    "\n",
    "configurable_chain = (\n",
    "    {\"topic\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | configurable_model \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f995debe-49b1-4fc8-8cc1-357da777d6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Sweet, cold, yum!\"'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurable_chain.invoke(\n",
    "    \"ice cream\", \n",
    "    config={\"model\": \"llm_openai\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "94d81db8-2b05-447d-9ca2-a310f1516d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Scoop, swirl, savor!\"'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurable_chain.invoke(\n",
    "    \"ice cream\", \n",
    "    config={\"model\": \"chat_openai\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8722827-eb83-4b28-b114-6084683b60df",
   "metadata": {},
   "source": [
    "#### 查看有哪些动态选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9a198-559c-4812-a1da-36e3bac92121",
   "metadata": {},
   "source": [
    "### RunnableSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13790fd6-4b37-48e4-a4a3-6bdb35e7d14a",
   "metadata": {},
   "source": [
    "RunnableSequence 是最最重要的流程控制组件。\n",
    "\n",
    "另外，RunnableSequence 也增加了几个属性：\n",
    "- first: 第一个Runnable组件\n",
    "- middle: 中间的Runnable组件列表\n",
    "- last: 最后一个Runnable组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "fc4145d9-ae34-4907-bdf6-5279d9532327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +---------------+    \n",
      "    | add_one_input |    \n",
      "    +---------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "  +-----------------+    \n",
      "  | Lambda(add_one) |    \n",
      "  +-----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| Lambda(buggy_double) | \n",
      "+----------------------+ \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+---------------------+  \n",
      "| buggy_double_output |  \n",
      "+---------------------+  \n",
      "---RunnableSequence\n",
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n",
      "<class 'list'>\n",
      "<class 'langchain_core.runnables.retry.RunnableRetry'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import random\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "def buggy_double(y: int) -> int:\n",
    "    '''Buggy code that will fail 70% of the time'''\n",
    "    if random.random() > 0.3:\n",
    "        print('This code failed, and will probably be retried!')\n",
    "        raise ValueError('Triggered buggy code')\n",
    "    return y * 2\n",
    "\n",
    "chain = (\n",
    "    RunnableLambda(add_one) |\n",
    "    RunnableLambda(buggy_double).with_retry( # Retry on failure\n",
    "        stop_after_attempt = 10,\n",
    "        wait_exponential_jitter = False\n",
    "    )\n",
    ")\n",
    "chain.get_graph().print_ascii()\n",
    "\n",
    "print(\"---RunnableSequence\")\n",
    "print(type(chain.first))\n",
    "print(type(chain.middle))\n",
    "print(type(chain.last))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab68d4a-e2d0-4be6-a235-3ffe463579c9",
   "metadata": {},
   "source": [
    "### RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a5ee6-e2bc-4037-9377-9eea5fe12689",
   "metadata": {},
   "source": [
    "一种情况是从同一个输入生成多个分支链："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "41ab2674-1656-47e7-b632-10131e951395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    +---------------+                     \n",
      "                    | add_one_input |                     \n",
      "                    +---------------+                     \n",
      "                            *                             \n",
      "                            *                             \n",
      "                            *                             \n",
      "                  +-----------------+                     \n",
      "                  | Lambda(add_one) |                     \n",
      "                  +-----------------+                     \n",
      "                            *                             \n",
      "                            *                             \n",
      "                            *                             \n",
      "          +----------------------------------+            \n",
      "          | Parallel<mul_two,mul_three>Input |            \n",
      "          +----------------------------------+            \n",
      "                  ***               ***                   \n",
      "               ***                     ***                \n",
      "             **                           **              \n",
      "+-----------------+                 +-------------------+ \n",
      "| Lambda(mul_two) |                 | Lambda(mul_three) | \n",
      "+-----------------+                 +-------------------+ \n",
      "                  ***               ***                   \n",
      "                     ***         ***                      \n",
      "                        **     **                         \n",
      "          +-----------------------------------+           \n",
      "          | Parallel<mul_two,mul_three>Output |           \n",
      "          +-----------------------------------+           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'mul_two': 4, 'mul_three': 6},\n",
       " {'mul_two': 6, 'mul_three': 9},\n",
       " {'mul_two': 8, 'mul_three': 12}]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "def mul_three(x: int) -> int:\n",
    "    return x * 3\n",
    "\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(mul_two)\n",
    "runnable_3 = RunnableLambda(mul_three)\n",
    "\n",
    "sequence = runnable_1 | {  # this dict is coerced to a RunnableParallel\n",
    "    \"mul_two\": runnable_2,\n",
    "    \"mul_three\": runnable_3,\n",
    "}\n",
    "# Or equivalently:\n",
    "# sequence = runnable_1 | RunnableParallel(\n",
    "#     {\"mul_two\": runnable_2, \"mul_three\": runnable_3}\n",
    "# )\n",
    "# Also equivalently:\n",
    "# sequence = runnable_1 | RunnableParallel(\n",
    "#     mul_two=runnable_2,\n",
    "#     mul_three=runnable_3,\n",
    "# )\n",
    "\n",
    "sequence.invoke(1)\n",
    "sequence.get_graph().print_ascii()\n",
    "\n",
    "await sequence.ainvoke(1)\n",
    "\n",
    "sequence.batch([1, 2, 3])\n",
    "await sequence.abatch([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7d97c-b790-49d6-8937-c4b6a362bc50",
   "metadata": {},
   "source": [
    "### RunnableEach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3ee8f-a0e8-470f-8f7b-1f8a520c24d4",
   "metadata": {},
   "source": [
    "如果需要让同一个链执行多次，使用 RunnableEach 非常方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5f567fa0-1393-4985-b945-9db0a2106c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +--------------+  \n",
      " | myfunc_input |  \n",
      " +--------------+  \n",
      "         *         \n",
      "         *         \n",
      "         *         \n",
      "+----------------+ \n",
      "| Lambda(myfunc) | \n",
      "+----------------+ \n",
      "         *         \n",
      "         *         \n",
      "         *         \n",
      "+---------------+  \n",
      "| myfunc_output |  \n",
      "+---------------+  \n",
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.base import RunnableEach, chain\n",
    "\n",
    "@chain\n",
    "def myfunc(x):\n",
    "    return(x * 2)\n",
    "\n",
    "runnable_each = RunnableEach(bound = myfunc)\n",
    "runnable_each.get_graph().print_ascii()\n",
    "\n",
    "output = runnable_each.invoke(range(1, 5))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594d23d-867e-4fbd-975f-0cdbaad1f08c",
   "metadata": {},
   "source": [
    "### RunnableBranch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703302c6-16c8-4748-8a4e-e0fefc5f70ba",
   "metadata": {},
   "source": [
    "有时候希望实现类似 ifelse 的条件分支，使用 RunnableBrach 可以接受 (条件函数, runnable) 的元组对和一个默认分支。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "23d1db5b-1842-4a1d-b5ab-b530a6af1823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+  \n",
      "| BranchInput |  \n",
      "+-------------+  \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "   +--------+    \n",
      "   | Branch |    \n",
      "   +--------+    \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+--------------+ \n",
      "| BranchOutput | \n",
      "+--------------+ \n",
      "HELLO\n",
      "6\n",
      "goodbye\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch, chain\n",
    "\n",
    "@chain\n",
    "def myfunc(x):\n",
    "    return(x * 2)\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: isinstance(x, str), lambda x: x.upper()),\n",
    "    (lambda x: isinstance(x, int), myfunc),\n",
    "    lambda x: \"goodbye\",\n",
    ")\n",
    "branch.get_graph().print_ascii()\n",
    "\n",
    "print(branch.invoke(\"hello\")) # \"HELLO\"\n",
    "print(branch.invoke(3)) # 6\n",
    "print(branch.invoke(None)) # \"goodbye\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0855246-be22-4710-86df-ebfbbffa26ee",
   "metadata": {},
   "source": [
    "### RouterRunnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8562e4-6103-48b0-8ee3-d9875d755a59",
   "metadata": {},
   "source": [
    "条件分支中还有一种情况更为简单，适合使用RouterRunnable，可以比RunnableBranch简洁得多。\n",
    "<br>但传递参数时必须以 RouterInput 类型传入，或使用等价的字典结构。\n",
    "\n",
    "```\n",
    "class RouterInput(TypedDict):\n",
    "    key: str\n",
    "    input: Any\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2ff74e65-d0c8-43c5-aafa-ef3eede6d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+  \n",
      "| RouterRunnableInput |  \n",
      "+---------------------+  \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "   +----------------+    \n",
      "   | RouterRunnable |    \n",
      "   +----------------+    \n",
      "            *            \n",
      "            *            \n",
      "            *            \n",
      "+----------------------+ \n",
      "| RouterRunnableOutput | \n",
      "+----------------------+ \n",
      "HELLO\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RouterRunnable, chain\n",
    "\n",
    "@chain\n",
    "def lower(x):\n",
    "    return(x.lower())\n",
    "\n",
    "@chain\n",
    "def upper(x):\n",
    "    return(x.upper())\n",
    "\n",
    "router = RouterRunnable({\"lower\": lower, \"upper\": upper})\n",
    "router.get_graph().print_ascii()\n",
    "\n",
    "print(router.invoke({\"key\": \"upper\", \"input\": \"Hello\"}))\n",
    "print(router.invoke({\"key\": \"lower\", \"input\": \"Hello\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0d891-4836-43bf-b88c-d67934a03f92",
   "metadata": {},
   "source": [
    "## 大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55533a3-cde7-439d-92e1-3122b52d2a01",
   "metadata": {},
   "source": [
    "### 大模型相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f4db4-dea5-47bb-a721-f77d20f176b6",
   "metadata": {},
   "source": [
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseLanguageModel（大模型）\n",
    "            - BaseChatModel `[LanguageModelInput, LanguageModelOutputVar]`\n",
    "                - SimpleChatModel\n",
    "                - ChatOpenAI\n",
    "                    - AzureChatOpenAI\n",
    "            - BaseLLM\n",
    "                - BaseOpenAI\n",
    "                    - OpenAI\n",
    "                    - AzureOpenAI\n",
    "                - HuggingFacePipeline\n",
    "                - LLM\n",
    "                    - FakeListLLM\n",
    "                        - FakeStreamingListLLM\n",
    "                    - HumanInputLLM\n",
    "                    - HuggingFaceHub\n",
    "                    - HuggingFaceEndpoint\n",
    "                    - HuggingFaceTextGenInference\n",
    "                    - QianfanLLMEndpoint\n",
    "                    - BaichuanLLM\n",
    "                - Tongyi\n",
    "                - Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d93bf-ced9-4186-880f-758de4379148",
   "metadata": {},
   "source": [
    "### 定制大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621fe55f-0cde-41d8-b9ea-e6827a7603fa",
   "metadata": {},
   "source": [
    "## 提示语和消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497ab06-532c-4d30-9f0c-098dda10273a",
   "metadata": {},
   "source": [
    "### 提示语和消息相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c18be-9f8d-49b6-9788-bc7e1f48ea1a",
   "metadata": {},
   "source": [
    "- PromptValue\n",
    "    - StringPromptValue\n",
    "    - ChatPromptValue\n",
    "        - ChatPromptValueConcrete\n",
    "    - ImagePromptValue\n",
    "\n",
    "- BaseMessage\n",
    "    - BaseMessageChunk\n",
    "    - AIMessage\n",
    "        - AIMessageChunk(AIMessage, BaseMessageChunk)\n",
    "    - ChatMessage\n",
    "        - ChatMessageChunk(ChatMessage, BaseMessageChunk)\n",
    "    - FunctionMessage\n",
    "        - FunctionMessageChunk(FunctionMessage, BaseMessageChunk)\n",
    "    - HumanMessage\n",
    "        - HumanMessageChunk(HumanMessage, BaseMessageChunk)\n",
    "    - SystemMessage\n",
    "        - SystemMessageChunk(SystemMessage, BaseMessageChunk)\n",
    "    - ToolMessage\n",
    "        - ToolMessageChunk(ToolMessage, BaseMessageChunk)\n",
    "\n",
    "- BaseExampleSelector\n",
    "    - LengthBasedExampleSelector\n",
    "    - SemanticSimilarityExampleSelector\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BasePromptTemplate `[Dict, PromptValue]`\n",
    "            - StringPromptTemplate\n",
    "                - PromptTemplate\n",
    "                - FewShotPromptWithTemplates\n",
    "                - FewShotPromptTemplate\n",
    "            - BaseChatPromptTemplate\n",
    "                - AutoGPTPrompt\n",
    "                - ChatPromptTemplate\n",
    "                    - AgentScratchPadChatPromptTemplate\n",
    "            - ImagePromptTemplate\n",
    "            - PipelinePromptTemplate\n",
    "        - BaseMessagePromptTemplate\n",
    "            - _StringImageMessagePromptTemplate\n",
    "                - ChatMessagePromptTemplate\n",
    "                - AIMessagePromptTemplate\n",
    "                - HumanMessagePromptTemplate\n",
    "                - SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252d390-7f26-495a-9378-101c64867c61",
   "metadata": {},
   "source": [
    "### 提示语模板库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8718b-7082-43b2-b891-9051f9d67084",
   "metadata": {},
   "source": [
    "### 从文件加载提示语"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0038b-926a-4755-b3d9-a738f558e93a",
   "metadata": {},
   "source": [
    "### 相关类结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafbd203-fbc2-469d-88b4-e6c94f9831cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "- BaseMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d6913-209e-4013-94a7-31b6145b6014",
   "metadata": {},
   "source": [
    "## 检索器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ad342-3604-4bd6-8470-be2e59b41286",
   "metadata": {},
   "source": [
    "### 相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1efd02f-a599-417b-a2d0-073dfec29471",
   "metadata": {},
   "source": [
    "- Embeddings\n",
    "    - embed_documents / aembed_documents\n",
    "    - embed_query / aembed_query\n",
    "        - OpenAIEmbeddings\n",
    "            - AzureOpenAIEmbeddings\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseRetriever `[RetrieverInput, RetrieverOutput]`\n",
    "            - VectorStoreRetriever\n",
    "            - AzureCognitiveSearchRetriever\n",
    "            - AmazonKnowledgeBasesRetriever\n",
    "            - ChatGPTPluginRetriever\n",
    "            - ElasticSearchBM25Retriever\n",
    "            - KNNRetriever\n",
    "            - LlamaIndexRetriever\n",
    "            - MetalRetriever\n",
    "            - MilvusRetriever\n",
    "            - OutlineRetriever\n",
    "            - PineconeHybridSearchRetriever\n",
    "            - QdrantSparseVectorRetriever\n",
    "            - RemoteLangChainRetriever\n",
    "            - SVMRetriever\n",
    "            - TavilySearchAPIRetriever\n",
    "            - TFIDFRetriever\n",
    "            - WeaviateHybridSearchRetriever\n",
    "            - WikipediaRetriever\n",
    "\n",
    "- BaseStore\n",
    "- VectorStore\n",
    "    - VectorStoreRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb685cb-9a46-4585-ae67-f7bfb1f1f394",
   "metadata": {},
   "source": [
    "## 输出解析和文档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f263bcce-e3ef-47b4-bb31-cf228d236678",
   "metadata": {},
   "source": [
    "### 相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca07f8c-16cd-4ed4-8146-edccbb9c3777",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- Document\n",
    "- BaseDocumentTransformer\n",
    "\n",
    "- Generation\n",
    "    - ChatGeneration\n",
    "        - ChatGenerationChunk\n",
    "- ChatResult\n",
    "- LLMResult\n",
    "- RunInfo\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseGenerationOutputParser `[Union[str, BaseMessage], T]`\n",
    "            - OutputFunctionsParser\n",
    "                - PydanticOutputFunctionsParser\n",
    "                    - PydanticAttrOutputFunctionsParser\n",
    "            - JsonOutputToolsParser\n",
    "                - JsonOutputKeyToolsParser\n",
    "                - PydanticToolsParser\n",
    "        - BaseOutputParser\n",
    "            - BaseTransformOutputParser\n",
    "                - BaseCumulativeTransformOutputParser\n",
    "                    - JsonOutputParser（别名SimpleJsonOutputParser）\n",
    "                    - JsonOutputFunctionsParser\n",
    "                        - JsonKeyOutputFunctionsParser\n",
    "                - StrOutputParser\n",
    "                - XMLOutputParser\n",
    "                - ListOutputParser\n",
    "                    - CommaSeparatedListOutputParser\n",
    "                    - NumberedListOutputParser\n",
    "                    - MarkdownListOutputParser\n",
    "            - BooleanOutputParser\n",
    "            - CombiningOutputParser\n",
    "            - DatetimeOutputParser\n",
    "            - EnumOutputParser\n",
    "            - OutputFixingParser（使用LLM修复错误）\n",
    "            - PandasDataFrameOutputParser\n",
    "            - PydanticOutputParser\n",
    "            - RegexDictParser\n",
    "            - RegexParser\n",
    "            - RetryOutputParser\n",
    "            - RetryWithErrorOutputParser\n",
    "            - StructuredOutputParser\n",
    "            - YamlOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bcefb-21a1-4146-929e-30cdd8b0fa8b",
   "metadata": {},
   "source": [
    "### 定制一个输出解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7d058-efd1-4e79-a459-6e9b4940eae3",
   "metadata": {},
   "source": [
    "## 回调和跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b30bfc-0014-40cd-b72f-61600c4ca95f",
   "metadata": {},
   "source": [
    "### 相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1803281-a337-4f30-8981-6fcf96c4872b",
   "metadata": {},
   "source": [
    "- CallbackManagerMixin\n",
    "    - BaseCallbackManager\n",
    "        - CallbackManager\n",
    "            - CallbackManagerForChainGroup\n",
    "        - AsyncCallbackManager\n",
    "            - AsyncCallbackManagerForChainGroup\n",
    "- RunManagerMixin\n",
    "    - BaseRunManager\n",
    "        - RunManager\n",
    "            - ParentRunManager\n",
    "                - CallbackManagerForChainRun(ParentRunManager, ChainManagerMixin)\n",
    "                - CallbackManagerForToolRun(ParentRunManager, ToolManagerMixin)\n",
    "                - CallbackManagerForRetrieverRun(ParentRunManager, RetrieverManagerMixin)\n",
    "            - CallbackManagerForLLMRun(RunManager, LLMManagerMixin)\n",
    "    - AsyncRunManager\n",
    "        - AsyncParentRunManager\n",
    "            - AsyncCallbackManagerForChainRun(AsyncParentRunManager, ChainManagerMixin)\n",
    "            - AsyncCallbackManagerForToolRun(AsyncParentRunManager, ToolManagerMixin)\n",
    "            - AsyncCallbackManagerForRetrieverRun(AsyncParentRunManager, RetrieverManagerMixin)\n",
    "        - AsyncCallbackManagerForLLMRun(AsyncRunManager, LLMManagerMixin)\n",
    "- BaseCallbackHandler(\n",
    "        LLMManagerMixin,\n",
    "        ChainManagerMixin,\n",
    "        ToolManagerMixin,\n",
    "        RetrieverManagerMixin,\n",
    "        CallbackManagerMixin,\n",
    "        RunManagerMixin,\n",
    "    )\n",
    "    - AsyncCallbackHandler\n",
    "    - StdOutCallbackHandler\n",
    "    - StreamingStdOutCallbackHandler\n",
    "    - BaseTracer\n",
    "        - EvaluatorCallbackHandler\n",
    "        - LangChainTracerV1\n",
    "        - LangChainTracer\n",
    "        - LogStreamCallbackHandler\n",
    "        - RootListenersTracer\n",
    "        - RunCollectorCallbackHandler\n",
    "        - FunctionCallbackHandler\n",
    "            - ConsoleCallbackHandler\n",
    "- RunLogPatch\n",
    "    - RunLog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12e0ae-ae75-4e86-b52a-7eee7cd020fc",
   "metadata": {},
   "source": [
    "- TracerSessionV1Base\n",
    "    - TracerSessionV1Create\n",
    "    - TracerSessionV1\n",
    "    - TracerSessionBase\n",
    "        - TracerSession\n",
    "- ExampleBase\n",
    "    - ExampleCreate\n",
    "    - Example\n",
    "- ExampleUpdate\n",
    "- DataType\n",
    "- DatasetBase\n",
    "    - DatasetCreate\n",
    "    - Dataset\n",
    "- RunTypeEnum\n",
    "- BaseRun\n",
    "    - LLMRun\n",
    "    - ChainRun \n",
    "    - ToolRun\n",
    "    - Run\n",
    "- RunLikeDict\n",
    "- RunBase\n",
    "    - RunWithAnnotationQueueInfo\n",
    "- FeedbackSourceBase\n",
    "    - APIFeedbackSource\n",
    "    - ModelFeedbackSource\n",
    "- FeedbackSourceType\n",
    "- FeedbackBase\n",
    "    - FeedbackCreate\n",
    "    - Feedback\n",
    "- TracerSession\n",
    "    - TracerSessionResult\n",
    "- BaseMessageLike\n",
    "- DatasetShareSchema\n",
    "- AnnotationQueue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f80766-28ef-4883-a9b6-4efd122bff85",
   "metadata": {},
   "source": [
    "### 自定义一个callback函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "56eb9b31-1305-49c6-9048-0aa594cad70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My custom handler, token: \n",
      "My custom handler, token: Why\n",
      "My custom handler, token:  don\n",
      "My custom handler, token: 't\n",
      "My custom handler, token:  scientists\n",
      "My custom handler, token:  trust\n",
      "My custom handler, token:  atoms\n",
      "My custom handler, token: ?\n",
      "My custom handler, token:  \n",
      "\n",
      "\n",
      "My custom handler, token: Because\n",
      "My custom handler, token:  they\n",
      "My custom handler, token:  make\n",
      "My custom handler, token:  up\n",
      "My custom handler, token:  everything\n",
      "My custom handler, token: !\n",
      "My custom handler, token: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\")"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        time.sleep(1)\n",
    "        print(f\"My custom handler, token: {token}\")\n",
    "\n",
    "# To enable streaming, we pass in `streaming=True` to the ChatModel constructor\n",
    "# Additionally, we pass in a list with our custom handler\n",
    "chat = ChatOpenAI(max_tokens=25, streaming=True, callbacks=[MyCustomHandler()])\n",
    "\n",
    "chat.invoke([HumanMessage(content=\"Tell me a joke\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6f2c6-52d7-4a47-9811-7eab225c73db",
   "metadata": {},
   "source": [
    "### 自定义个一个异步回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8ae19b90-4dd3-4468-8f38-b13081aafc4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My custom handler, token: \n",
      "My custom handler, token: Sure\n",
      "My custom handler, token: ,\n",
      "My custom handler, token:  here\n",
      "My custom handler, token: 's\n",
      "My custom handler, token:  a\n",
      "My custom handler, token:  joke\n",
      "My custom handler, token:  for\n",
      "My custom handler, token:  you\n",
      "My custom handler, token: :\n",
      "\n",
      "\n",
      "My custom handler, token: Why\n",
      "My custom handler, token:  don\n",
      "My custom handler, token: 't\n",
      "My custom handler, token:  scientists\n",
      "My custom handler, token:  trust\n",
      "My custom handler, token:  atoms\n",
      "My custom handler, token: ?\n",
      "\n",
      "\n",
      "My custom handler, token: Because\n",
      "My custom handler, token:  they\n",
      "My custom handler, token:  make\n",
      "My custom handler, token:  up\n",
      "My custom handler, token:  everything\n",
      "My custom handler, token: !\n",
      "My custom handler, token: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\")"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import asyncio\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    async def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        await asyncio.sleep(1)\n",
    "        print(f\"My custom handler, token: {token}\")\n",
    "\n",
    "# To enable streaming, we pass in `streaming=True` to the ChatModel constructor\n",
    "# Additionally, we pass in a list with our custom handler\n",
    "chat = ChatOpenAI(max_tokens=25, streaming=True, callbacks=[MyCustomHandler()])\n",
    "\n",
    "await chat.ainvoke([HumanMessage(content=\"Tell me a joke\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d2740-9a59-4b22-8eec-ef5abafadcfe",
   "metadata": {},
   "source": [
    "## 记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82993470-530d-488d-a643-f5125f784cd9",
   "metadata": {},
   "source": [
    "### 记忆体相关结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d755414-c50d-439a-a0b6-a74867819e59",
   "metadata": {},
   "source": [
    "- BaseMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72132d05-d623-4c1d-afe0-7102432203dd",
   "metadata": {},
   "source": [
    "## 智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b5de3-9f15-44f6-bf57-93df044120b7",
   "metadata": {},
   "source": [
    "### 智能体相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d553bd47-9247-4960-bba3-9a55d5210f69",
   "metadata": {},
   "source": [
    "**Agent**\n",
    "- AgentType\n",
    "    - ZERO_SHOT_REACT_DESCRIPTION（**ReAct**的一般实现）\n",
    "    - REACT_DOCSTORE（ReAct，支持RAG）\n",
    "    - SELF_ASK_WITH_SEARCH（使用**search 工具**不断反思获得答案）\n",
    "    - CONVERSATIONAL_REACT_DESCRIPTION（**ReAct**，支持对话）\n",
    "    - CHAT_ZERO_SHOT_REACT_DESCRIPTION（同上）\n",
    "    - CHAT_CONVERSATIONAL_REACT_DESCRIPTION（同上）\n",
    "    - STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION（**ReAct**，为对话模型优化，支持多输入）\n",
    "    - OPENAI_FUNCTIONS（支持**OpenAI Function Calling**）\n",
    "    - OPENAI_MULTI_FUNCTIONS（支持**OpenAI Function Calling**，支持多函数调度）\n",
    "\n",
    "**主要结构**\n",
    "- AgentAction\n",
    "    - AgentActionMessageLog\n",
    "\n",
    "- AgentStep\n",
    "- AgentFinish\n",
    "\n",
    "**智能体类结构**\n",
    "- BaseSingleActionAgent\n",
    "    - RunnableAgent\n",
    "    - LLMSingleActionAgent（__遗留__，__修改为__：create_***_agent）\n",
    "    - XMLAgent（__遗留__，__修改为__：create_xml_agent）\n",
    "    - Agent\n",
    "        - ChatAgent（__遗留__，__修改为__：create_react_agent）\n",
    "        - ConversationalAgent（__遗留__，__修改为__：create_react_agent）\n",
    "        - ConversationalChatAgent（__遗留__，__修改为__：create_json_chat_agent）\n",
    "        - StructuredChatAgent（__遗留__，__修改为__：create_structured_chat_agent）\n",
    "        - ZeroShotAgent（__遗留__，__修改为__：create_react_agent）\n",
    "        - ReActDocstoreAgent（__遗留__）\n",
    "            - ReActTextWorldAgent（__遗留__）\n",
    "        - SelfAskWithSearchAgent（__遗留__，__修改为__：create_self_ask_with_search）\n",
    "    - OpenAIFunctionsAgent（__遗留__，__修改为__：create_openai_functions_agent）\n",
    "\n",
    "- BaseMultiActionAgent\n",
    "    - RunnableMultiActionAgent\n",
    "    - OpenAIMultiFunctionsAgent（__遗留__，__修改为__：create_openai_tools_agent）\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - Chain\n",
    "            - AgentExecutor（__NEW__）\n",
    "                - MRKLChain（__遗留__）\n",
    "                - ReActChain（__遗留__）\n",
    "                - SelfAskWithSearchChain（__遗留__）\n",
    "        - OpenAIAssistantRunnable\n",
    "\n",
    "- DocstoreExplorer（__遗留__）\n",
    "\n",
    "**Prompt**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BasePromptTemplate `[Dict, PromptValue]`\n",
    "            - BaseChatPromptTemplate\n",
    "                - ChatPromptTemplate\n",
    "                    - AgentScratchPadChatPromptTemplate\n",
    "\n",
    "**OutputParser**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseOutputParser\n",
    "            - AgentOutputParser\n",
    "            - MultiActionAgentOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0716a4-2a01-445b-afb7-d1b219a1b377",
   "metadata": {},
   "source": [
    "### Function Calling 和 智能体的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93705dc8-90f4-427d-b3d9-5a4fbe59662d",
   "metadata": {},
   "source": [
    "在概念上，OpenAI tools 和 OpenAI function calling 并不属于 Agent 范畴。\n",
    "\n",
    "Agent通常指的是可以自主做出决策和采取行动的系统。而 function calling 更像是一种技术手段,用于触发外部函数的执行。\n",
    "<br>\n",
    "但是, 在大部分 Agent 实现中, function calling 机制被用来实现 Agent 的行为，用来触发外部工具和服务。\n",
    "所以它是往往启用 Agent 行为的一个组成部分。\n",
    "总的来说,function calling本身只是一种技术功能。\n",
    "\n",
    "而 OpenAI tools 是 OpenAI function calling 的替代机制，其主要区别在于:\n",
    "\n",
    "- tools 支持同时调用多个函数, 而 function calling 只能调用单个函数。\n",
    "- tools 允许函数之间交互和组合使用, function calling 中的函数是相互独立的。\n",
    "- tools 提供了更多控制流程的选项, 如条件语句、循环等。\n",
    "- tools 是 OpenAI 最新推出的函数调用机制, 而 function calling 是早期的格式,现在被视为legacy。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ab7dd-f271-467e-89b1-dfeb1fb9e8f6",
   "metadata": {},
   "source": [
    "使用智能体框架比直接使用 tools 或 function calling 有以下几个主要优势:\n",
    "\n",
    "- 封装性更好,使用更简单。智能体框架提供了现成的接口和抽象,开发者不需要处理底层的 tools 或 function calling细节。\n",
    "- 支持更复杂的逻辑。智能体框架内置了决策、推理、计划等更高级的能力,不仅是简单的函数触发。\n",
    "- 可解释性和可靠性更好。智能体的行为过程可以通过日志展示,输出更可解释。并且可以配置规则避免无意义的循环。\n",
    "- 支持工具和服务的统一集成。工具可以用标准化方式集成到智能体框架中,而不需要不同的接入方式。\n",
    "- 可扩展性更好,自定义能力更强。智能体框架提供了扩展接口,可以插入自定义的组件。\n",
    "\n",
    "总体上,相比直接的 tools 或 function calling,智能体框架提供了更高层次的封装与抽象,使用更简单,功能也更全面和强大。\n",
    "<br>这是使用智能体框架的主要优势所在。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285628a4-1ce0-40f7-8c90-4010fa7cf6e6",
   "metadata": {},
   "source": [
    "### Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b3be7-b24b-46b0-966b-9f0a212d32c7",
   "metadata": {},
   "source": [
    "**Tool**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseTool `[Union[str, Dict], Any]`\n",
    "            - Tool\n",
    "            - ExceptionTool\n",
    "        \n",
    "            **输入:**\n",
    "            - StructuredTool\n",
    "            - HumanInputRun\n",
    "        \n",
    "            **git:**\n",
    "            - GitHubAction\n",
    "            - GitLabAction\n",
    "        \n",
    "            **json:**\n",
    "            - JsonListKeysTool\n",
    "            - JsonGetValueTool\n",
    "        \n",
    "            **记忆:**\n",
    "            - Memorize\n",
    "        \n",
    "            **天气查询:**\n",
    "            - OpenWeatherMapQueryRun\n",
    "        \n",
    "            **sleep函数:**\n",
    "            - SleepTool\n",
    "        \n",
    "            **shell:**\n",
    "            - ShellTool\n",
    "        \n",
    "            **sql:**\n",
    "            - QuerySQLDataBaseTool\n",
    "            - InfoSQLDatabaseTool\n",
    "            - QuerySQLCheckerTool\n",
    "        \n",
    "            **搜索引擎:**\n",
    "            - TavilySearchResults\n",
    "            - TavilyAnswer\n",
    "        \n",
    "            **QA向量检索:**\n",
    "            - VectorStoreQATool\n",
    "            - VectorStoreQAWithSourcesTool\n",
    "        \n",
    "            **wiki:**\n",
    "            - WikipediaQueryRun\n",
    "        \n",
    "            **文件:**\n",
    "            - CopyFileTool\n",
    "            - DeleteFileTool\n",
    "            - FileSearchTool\n",
    "            - ListDirectoryTool\n",
    "            - MoveFileTool\n",
    "            - ReadFileTool\n",
    "            - WriteFileTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672ddec-7ac8-44c9-8858-c3dada26aabf",
   "metadata": {},
   "source": [
    "### 智能体和工具箱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fac65e-cb17-4a2f-934b-231365979d5c",
   "metadata": {},
   "source": [
    "\n",
    "#### pbi智能体\n",
    "- create_pbi_agent\n",
    "- create_pbi_chat_agent\n",
    "\n",
    "#### sql生成智能体\n",
    "- create_spark_sql_agent\n",
    "- create_sql_agent\n",
    "\n",
    "#### 结构化输出智能体\n",
    "- create_xml_agent\n",
    "\n",
    "\n",
    "create_json_agent\n",
    "- create_json_chat_agent\n",
    "- create_structured_chat_agent\n",
    "\n",
    "#### 向量检索智能体\n",
    "- create_vectorstore_agent\n",
    "- create_vectorstore_router_agent\n",
    "\n",
    "#### ReAct智能体\n",
    "- create_react_agent\n",
    "\n",
    "#### 自搜索智能体\n",
    "- create_self_ask_with_search_agent\n",
    "\n",
    "#### 遗留方法\n",
    "- load_agent（__遗留__）\n",
    "- load_agent_from_config（__遗留__）\n",
    "- initialize_agent（__遗留__，__修改为__：create_***_agent）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c67acc-7694-40a8-a539-f1f26436281c",
   "metadata": {},
   "source": [
    "### 文件管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052c218-e5bd-4e37-882e-9469c424d41c",
   "metadata": {},
   "source": [
    "#### Toolkit：FileManagementToolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc087c-26e4-4b91-a5a3-883a1d4e5dd9",
   "metadata": {},
   "source": [
    "```\n",
    "from langchain.agent_toolkits import FileManagementToolkit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a919f-ec33-4fab-b698-92fc7908267e",
   "metadata": {},
   "source": [
    "包含的Tool清单："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0838261-668b-4596-9a38-43fc6f8297af",
   "metadata": {},
   "source": [
    "- CopyFileTool\n",
    "- DeleteFileTool\n",
    "- FileSearchTool\n",
    "- MoveFileTool\n",
    "- ReadFileTool\n",
    "- WriteFileTool\n",
    "- ListDirectoryTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35327fe5-9c7c-44c3-b370-cceb24bf640c",
   "metadata": {},
   "source": [
    "### JSON查询"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81308eb8-e3d0-4f9d-b449-de22b4e2dcbb",
   "metadata": {},
   "source": [
    "#### 创建Agent：create_json_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad71e2-e1f1-41ba-8198-06f46af82ff8",
   "metadata": {},
   "source": [
    "让智能体一边与JSON数据交互一边思考，将JSON查询结果作为答案返回。\n",
    "```\n",
    "from langchain.agents import create_json_agent\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cee309-87a8-4b50-b75f-2845023a7009",
   "metadata": {},
   "source": [
    "#### Toolkit：JsonToolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f8d8e-66dd-4623-91f3-0344c38471c2",
   "metadata": {},
   "source": [
    "```\n",
    "from langchain_community.agent_toolkits import JsonToolkit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86cfbe3-3aa7-40ff-b116-8c7a1cb41fce",
   "metadata": {},
   "source": [
    "包含的Tool清单："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6ab55-e994-406d-ab0b-2f021b2254ad",
   "metadata": {},
   "source": [
    "- JsonListKeysTool\n",
    "- JsonGetValueTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095fc130-1c61-4454-b9ce-9896f9e48ab2",
   "metadata": {},
   "source": [
    "#### 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "bbc65458-a01d-4417-b327-22b0862be990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from langchain.agents import create_json_agent\n",
    "from langchain_community.agent_toolkits import JsonToolkit\n",
    "from langchain_community.tools.json.tool import JsonSpec\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "07e9e038-ff84-4f17-acb3-21904f63627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/openapi.yaml\") as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "json_spec = JsonSpec(dict_=data, max_value_length=4000)\n",
    "json_toolkit = JsonToolkit(spec=json_spec)\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0645f4ab-9e5b-48b4-8aa6-bfcd11de21cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: json_spec_list_keys\n",
      "Action Input: data\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['openapi', 'info', 'servers', 'paths', 'components']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the keys that exist in data[\"info\"] to see what I have access to\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"info\"]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['title', 'description', 'version']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look at the value of data[\"info\"][\"version\"] to see the API version\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"info\"][\"version\"]\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mv1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: v1\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '告诉我这个API的版本', 'output': 'v1'}"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_agent_executor.invoke(\n",
    "    \"告诉我这个API的版本\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0738b4-2661-4a85-8304-ef8b7393320c",
   "metadata": {},
   "source": [
    "### OpenAI智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da3b9e-24a2-4a96-9e44-b030656d142b",
   "metadata": {},
   "source": [
    "#### 创建Agent方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e72d56-bb74-443f-8b3d-4be59670b8d8",
   "metadata": {},
   "source": [
    "**create_openapi_agent**\n",
    "\n",
    "通过\n",
    "  \n",
    "**create_openai_functions_agent**\n",
    "\n",
    "单一函数回调。\n",
    "\n",
    "**create_openai_tools_agent**\n",
    "  \n",
    "多函数回调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac97a7f-1ca1-4422-afcc-2b4c3330f45f",
   "metadata": {},
   "source": [
    "#### 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "ef45ee90-1dca-427f-adf0-b37e1c03d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent, create_openai_functions_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "85653db3-1451-497f-b796-0d56bb57e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc0b9a-6625-4b52-91d9-8ae9d7d5c0cc",
   "metadata": {},
   "source": [
    "#### 使用create_openai_functions_agent创建Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccbe51-9810-46f5-a5f9-b9a6e19a8113",
   "metadata": {},
   "source": [
    "create_openai_functions_agent是openai早期实现的接口，仅支持一次函数调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "2260440c-c2f2-41d1-8b69-3c4479b86044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Erick和Harrison与langchain项目的关系'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://zhuanlan.zhihu.com/p/645358531', 'content': '关于软件复杂性和复杂性下的流行性之争是永恒的话题。没有人愿意成为批评 LangChain 这样的免费开源软件的混蛋，但我愿意承担这个责任。明确地说，我并不反对 Harrison Chase 或 LangChain  简单来说，LangChain 是一个 Python 和 JavaScript 库，由 Harrison Chase 开发，用于连接 OpenAI 的 GPT API（后续已扩展到更多模型）以生成人工智能文本。  Chase 或 LangChain 的其他维护者（他们鼓励反馈）。  体现了「它很复杂，所以它一定更好」这一经常困扰后期代码库的哲学，可是 LangChain 甚至还不到一年。简单来说，LangChain 是一个 Python 和 JavaScript 库，由 Harrison Chase 开发，用于连接 OpenAI 的 GPT API（后续已扩展到更多模型）以生成人工智能文本。 更具体地说，它是论文《ReAct: Synergizing Reasoning and Acting in Language Models》的实现：该论文展示了一种提示技术，允许模型「推理」（通过思维链）和「行动」（通过能够使用预定义工具集中的工具，例如能够搜索互联网）。 论文链接： arxiv.org/pdf/2210.0362 事实证明，这种组合能够大幅提高输出文本的质量，并使大型语言模型具备正确解决问题的能力。'}]\u001b[0m\u001b[32;1m\u001b[1;3mErick和Harrison与langchain项目的关系是，Harrison Chase是LangChain项目的开发者，LangChain是一个Python和JavaScript库，用于连接OpenAI的GPT API以生成人工智能文本。因此，Erick和Harrison都与LangChain项目有密切的开发和贡献关系。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Erick和Harrison都为langchain项目做了不少贡献，他们与langchain项目有什么关系吗?请用中文回答。',\n",
       " 'output': 'Erick和Harrison与langchain项目的关系是，Harrison Chase是LangChain项目的开发者，LangChain是一个Python和JavaScript库，用于连接OpenAI的GPT API以生成人工智能文本。因此，Erick和Harrison都与LangChain项目有密切的开发和贡献关系。'}"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions_agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "functions_agent_executor = AgentExecutor(agent=functions_agent, tools=tools, verbose=True)\n",
    "functions_agent_executor.invoke({\n",
    "    \"input\": \"Erick和Harrison都为langchain项目做了不少贡献，他们与langchain项目有什么关系吗?请用中文回答。\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a735d-10ef-4069-a303-0c320e9842b3",
   "metadata": {},
   "source": [
    "#### 使用create_openai_functions_agent创建Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389729f-40d6-47bc-abd7-0916e9ee1257",
   "metadata": {},
   "source": [
    "使用create_openai_functions_agent时，“Erick和Harrison都为...”会被拆解为两个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "55c51e53-23eb-40cb-bc15-4efa1f53ee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Erick langchain project'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.linkedin.com/pulse/llm-framework-how-langchain-redefine-application-2024-singh-ph-d--ikgmc', 'content': 'New to LinkedIn? Join now LLM Framework: How LangChain will Redefine Application Development in 2024  Embrace the power of LangChain and be part of this AI revolution.  In this ever-increasing need for Artificial Intelligence in all business forms, LangChain emerges as a game-changer,  This blog explores the multifaceted applications of LangChain and its groundbreaking impact on industries worldwide.LangChain is indeed a robust framework that is redefining AI application development. It allows developers to build context-aware reasoning applications with its flexible abstractions and AI-first ...'}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Harrison langchain project'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.latent.space/p/langchain', 'content': 'As Harrison explains, LangChain is an open source framework for building context-aware reasoning applications,  [00:50:25] Responding to LangChain criticisms [00:54:11] Harrison\\'s advice to AI engineers [00:55:43] Lightning Round  LangChain Hub UI “LangChain is Pointless” Harrison’s links sports - estimating player compatibility in the NBA  What is LangChain?From the back to back and (rumored) $20-25m Sequoia Series A in April, to back to back critiques of \" LangChain is Pointless teaching with Andrew Ng and keynoting at basically every AI conference this fall (including ), it has been an rollercoaster for Harrison and his team creating one of the most popular (>60k stars at time of writing) buildin...'}]\u001b[0m\u001b[32;1m\u001b[1;3mErick和Harrison都与LangChain项目有关。Erick在LangChain项目中探讨了LangChain的应用和影响，而Harrison则解释了LangChain是一个用于构建上下文感知推理应用的开源框架。因此，他们都与LangChain项目有密切关系。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Erick和Harrison都为langchain项目做了不少贡献，他们与langchain项目有什么关系吗?请用中文回答。',\n",
       " 'output': 'Erick和Harrison都与LangChain项目有关。Erick在LangChain项目中探讨了LangChain的应用和影响，而Harrison则解释了LangChain是一个用于构建上下文感知推理应用的开源框架。因此，他们都与LangChain项目有密切关系。'}"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "tools_agent_executor = AgentExecutor(agent=tools_agent, tools=tools, verbose=True)\n",
    "tools_agent_executor.invoke({\n",
    "    \"input\": \"Erick和Harrison都为langchain项目做了不少贡献，他们与langchain项目有什么关系吗?请用中文回答。\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502cd09-c237-434f-983c-a565ec923db5",
   "metadata": {},
   "source": [
    "#### 加入对话历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "0aab7852-4632-46c5-8101-6f268bdb64fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': '谢楠主持过的综艺节目'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://ent.qianlong.com/2024/0207/8200732.shtml', 'content': '2024央视龙年春晚节目单 2024央视龙年春晚节目单 2月6日晚,2024央视龙年春晚北京主会场主持阵容正式官宣发布任鲁豫C位 2024央视龙年春晚湖南长沙分会场主持人发布:何炅、张舒越 2024央视龙年春晚新疆喀什分会场主持人马跃  附2024央视龙年春晚完整节目单 顾问:张艺谋、张一一 总导演:于蕾 主持人:任鲁豫、撒贝宁、尼格买提、龙洋、马凡舒(北京主会场) 张舒悦、何炅(湖南长沙分会场) 杨帆、刘心悦(辽宁沈阳分会场) 朱迅、徐杰(陕西西安分会场)  附2024央视龙年春晚完整节目单 顾问:张艺谋、张一一 总导演:于蕾 主持人:任鲁豫、撒贝宁、尼格买提、龙洋、马凡舒(北京主会场) 张舒悦、何炅(湖南长沙分会场) 杨帆、刘心悦(辽宁沈阳分会场) 朱迅、徐杰(陕西西安分会场)  综艺频道主持人杨帆与在2023中央广播电视总台主持人大赛中表现不俗获得银奖的辽宁卫视当家花旦刘心悦主持沈阳分会场,2018年和2020年已两次主持春晚分会场(贵州黔东南、河南郑州)的马跃和新疆卫视主持人维妮娜主持新疆喀什分会场,朱迅则与陕西2月6日,甲辰龙年2024中央广播电视总台春节联欢晚会进入最后3天的冲刺倒计时,随着龙年春晚四次带妆彩排的完成,通过现场观众、明星嘉宾、艺人助理 ...'}]\u001b[0m\u001b[32;1m\u001b[1;3m根据搜索结果，谢楠曾主持过央视的春晚节目。您可以在以下链接中找到更多信息：[谢楠主持的综艺节目](https://ent.qianlong.com/2024/0207/8200732.shtml)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '吴京的老婆主持过什么综艺节目?',\n",
       " 'chat_history': [HumanMessage(content='吴京的老婆是谁？'),\n",
       "  AIMessage(content='吴京的妻子是节目主持人谢楠。')],\n",
       " 'output': '根据搜索结果，谢楠曾主持过央视的春晚节目。您可以在以下链接中找到更多信息：[谢楠主持的综艺节目](https://ent.qianlong.com/2024/0207/8200732.shtml)'}"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "tools_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"吴京的老婆主持过什么综艺节目?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"吴京的老婆是谁？\"),\n",
    "            AIMessage(content=\"吴京的妻子是节目主持人谢楠。\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf39ba8-a8a8-437f-b487-bd54013c8ead",
   "metadata": {},
   "source": [
    "### create_csv_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f525105-9481-4710-a1b7-aa2da2daa670",
   "metadata": {},
   "source": [
    "### create_json_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54370791-a10c-4981-b825-f0a5d48fff95",
   "metadata": {},
   "source": [
    "### Toolkits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255bf89-52ce-4622-9033-437a057b3cf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 定制工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fa994-ec15-494d-a9e9-d089dee00ae1",
   "metadata": {},
   "source": [
    "### 定制智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5aee5-3a14-42c3-99db-aa05ecd1a417",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df19fb-6eff-4222-864d-eca588d11b5d",
   "metadata": {},
   "source": [
    "### 相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fecac4-c082-4e62-a83e-6fa78e54c23d",
   "metadata": {},
   "source": [
    "- BaseCache\n",
    "- BaseChatMessageHistory\n",
    "- ChatSession\n",
    "- LangChainException\n",
    "    - TracerException\n",
    "    - OutputParserException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fede3d-d7d4-4d9e-836e-1e900a00fbb4",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c144b2-87b3-4187-ac35-c2a9b20f10ce",
   "metadata": {},
   "source": [
    "### 在LCEL出现之前的遗留Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173bc36-ab41-4b03-a300-fa474d3e6155",
   "metadata": {},
   "source": [
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - Chain\n",
    "            - LLMChain\n",
    "                - ConversationChain\n",
    "                - QuestionGeneratorChain\n",
    "                - FlareChain\n",
    "            - LLMCheckerChain\n",
    "            - LLMRequestsChain\n",
    "            - LLMMathChain（使用python代码执行数学计算）\n",
    "            - LLMSummarizationCheckerChain\n",
    "            - MapReduceChain\n",
    "            - OpenAIModerationChain\n",
    "            - SequentialChain\n",
    "            - SimpleSequentialChain\n",
    "            - APIChain\n",
    "            - BaseCombineDocumentsChain\n",
    "            - AnalyzeDocumentChain\n",
    "            - ConstitutionalChain\n",
    "            - BaseConversationalRetrievalChain\n",
    "                - ConversationalRetrievalChain\n",
    "                - ChatVectorDBChain\n",
    "            - ElasticsearchDatabaseChain\n",
    "            - NatBotChain（实现一个基于LLM的浏览器）\n",
    "            - QAGenerationChain（问答对生成）\n",
    "            - BaseQAWithSourcesChain\n",
    "                - QAWithSourcesChain\n",
    "            - BaseRetrievalQA\n",
    "                - RetrievalQA\n",
    "                - VectorDBQA\n",
    "            - RouterChain\n",
    "                - MultiRouteChain\n",
    "                    - MultiRetrievalQAChain\n",
    "                - EmbeddingRouterChain\n",
    "                - LLMRouterChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05696f-404b-4bbf-ac95-90ec5aef455b",
   "metadata": {},
   "source": [
    "### 使用LCEL构建的预制 Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd31566-9bd0-45c0-99d5-81e1e9ee44c5",
   "metadata": {},
   "source": [
    "- create_stuff_documents_chain（**携带Document**的链）\n",
    "- create_openai_fn_runnable（执行**OpenAI Function Calling**，在必要时选择一个函数执行）\n",
    "- create_structured_output_runnable （执行**OpenAI Function Calling**，强制选择至少一个函数执行）\n",
    "- load_query_constructor_runnable\n",
    "- create_sql_query_chain（生成**SQL**的链）\n",
    "- create_history_aware_retriever\n",
    "- create_retrieval_chain（结合`create_stuff_documents_chain`构建**RAG**链）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18987a1-c66a-4ef9-b81b-8cc82b25592f",
   "metadata": {},
   "source": [
    "#### create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "62baa62e-523a-4206-8593-938d84ee7af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jesse's favorite color is red\\nJamal's favorite color is orange\""
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"What are everyone's favorite colors:\\n\\n{context}\")]\n",
    ")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"Jesse loves red but not yellow\"),\n",
    "    Document(page_content = \"Jamal loves green but not as much as he loves orange\")\n",
    "]\n",
    "\n",
    "chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3ea57-e2c0-43e1-9de4-82343c7f5249",
   "metadata": {},
   "source": [
    "#### create_openai_fn_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c8bf2b4a-5fa2-4e74-af33-949b863d00b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecordDog(name='Harry', color='brown', fav_food='chicken')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.openai_functions import create_openai_fn_runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class RecordPerson(BaseModel):\n",
    "    \"\"\"Record some identifying information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The person's name\")\n",
    "    age: int = Field(..., description=\"The person's age\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The person's favorite food\")\n",
    "\n",
    "\n",
    "class RecordDog(BaseModel):\n",
    "    \"\"\"Record some identifying information about a dog.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The dog's name\")\n",
    "    color: str = Field(..., description=\"The dog's color\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The dog's favorite food\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a world class algorithm for recording entities.\"),\n",
    "        (\"human\", \"Make calls to the relevant function to record the entities in the following input: {input}\"),\n",
    "        (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "    ]\n",
    ")\n",
    "chain = create_openai_fn_runnable([RecordPerson, RecordDog], llm, prompt)\n",
    "chain.invoke({\"input\": \"Harry was a chubby brown beagle who loved chicken\"})\n",
    "# -> RecordDog(name=\"Harry\", color=\"brown\", fav_food=\"chicken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfcd30-332a-4344-a89b-dd7fbb283e88",
   "metadata": {},
   "source": [
    "#### load_query_constructor_runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a39bfe-1dd1-410a-8847-2e4797c85a3f",
   "metadata": {},
   "source": [
    "#### create_sql_query_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "cb147991-075c-4e51-9991-d4612c55dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuehongwei/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/duckdb_engine/__init__.py:180: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# poetry add langchain langchain-community langchain-openai\n",
    "# poetry add duckdb-engine\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# 这段代码由于duckdb暂时不支持查询索引元数据，因此会出现警告信息\n",
    "db = SQLDatabase.from_uri(\"duckdb:///data/langchain.duckdb\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1f0d8fa2-968d-48a8-a4f2-9bd140a61571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT (LENGTH(content) / 1000) * 1000 AS length_range, COUNT(*) AS count\n",
      "FROM text_blocks\n",
      "GROUP BY length_range\n",
      "ORDER BY length_range\n",
      "LIMIT 5;\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"question\": \"我想知道文本块的长度分布，按照每1000个字一个步长分别统计\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff5140-b6a4-4f27-b1c4-874bfdcba1b6",
   "metadata": {},
   "source": [
    "#### create_history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4ecc0-dedd-4a5c-a7ca-27dc14072508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain import hub\n",
    "\n",
    "rephrase_prompt = hub.pull(\"langchain-ai/chat-langchain-rephrase\")\n",
    "llm = ChatOpenAI()\n",
    "retriever = ...\n",
    "chat_retriever_chain = create_history_aware_retriever(\n",
    "    llm, retriever, rephrase_prompt\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"...\", \"chat_history\": })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4bf59-dd32-46f1-904c-3ce1a9cb09f1",
   "metadata": {},
   "source": [
    "#### create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "58741552-7284-4cb3-8aa1-7d626a6f73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import LanceDB\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "documents = CharacterTextSplitter().split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "3bc721a5-b7dc-45e3-b1a3-39f0776ad81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"data/demo.lancedb\")\n",
    "table = db.create_table(\n",
    "    \"my_table\",\n",
    "    data=[\n",
    "        {\n",
    "            \"vector\": embeddings.embed_query(\"Hello World\"),\n",
    "            \"text\": \"Hello World\",\n",
    "            \"id\": \"1\",\n",
    "        }\n",
    "    ],\n",
    "    mode=\"overwrite\",\n",
    ")\n",
    "\n",
    "search_docs = LanceDB.from_documents(documents, embeddings, connection=table)\n",
    "retriever = search_docs.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924494c1-7458-4fa6-aa2b-80bd4a2c7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0ad3dab2-c5da-4396-a39a-13dfeddeceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.lancedb.LanceDB at 0x12cff5450>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs.search("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d926a018-1cb2-4cc5-aa60-b15cb7076e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain import hub\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "llm = ChatOpenAI()\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm, retrieval_qa_chat_prompt\n",
    ")\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "c713feee-03a8-4ddf-b8ab-8e9a0f1b1589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '总统说了什么？',\n",
       " 'context': [Document(page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters. \\n\\nPutin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland. \\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.', metadata={'vector': array([-0.00365787, -0.02292356, -0.01156492, ..., -0.01817933,\n",
       "          0.01212872, -0.01853687], dtype=float32), 'id': '7393f846-04b4-4359-ab4d-4d79fa08bb6b', '_distance': 0.4615442454814911}),\n",
       "  Document(page_content='We are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \\n\\nThe only nation that can be defined by a single word: possibilities. \\n\\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union. \\n\\nAnd my report is this: the State of the Union is strong—because you, the American people, are strong. \\n\\nWe are stronger today than we were a year ago. \\n\\nAnd we will be stronger a year from now than we are today. \\n\\nNow is our moment to meet and overcome the challenges of our time. \\n\\nAnd we will, as one people. \\n\\nOne America. \\n\\nThe United States of America. \\n\\nMay God bless you all. May God protect our troops.', metadata={'vector': array([-0.00224148, -0.02951822, -0.00897236, ..., -0.00608219,\n",
       "          0.00787409, -0.01848421], dtype=float32), 'id': 'f76475e5-32ba-404a-98c6-9cc6cf239cd3', '_distance': 0.47451984882354736}),\n",
       "  Document(page_content='We meet tonight in an America that has lived through two of the hardest years this nation has ever faced. \\n\\nThe pandemic has been punishing. \\n\\nAnd so many families are living paycheck to paycheck, struggling to keep up with the rising cost of food, gas, housing, and so much more. \\n\\nI understand. \\n\\nI remember when my Dad had to leave our home in Scranton, Pennsylvania to find work. I grew up in a family where if the price of food went up, you felt it. \\n\\nThat’s why one of the first things I did as President was fight to pass the American Rescue Plan.  \\n\\nBecause people were hurting. We needed to act, and we did. \\n\\nFew pieces of legislation have done more in a critical moment in our history to lift us out of crisis. \\n\\nIt fueled our efforts to vaccinate the nation and combat COVID-19. It delivered immediate economic relief for tens of millions of Americans.  \\n\\nHelped put food on their table, keep a roof over their heads, and cut the cost of health insurance. \\n\\nAnd as my Dad used to say, it gave people a little breathing room. \\n\\nAnd unlike the $2 Trillion tax cut passed in the previous administration that benefitted the top 1% of Americans, the American Rescue Plan helped working people—and left no one behind. \\n\\nAnd it worked. It created jobs. Lots of jobs. \\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year  \\nthan ever before in the history of America. \\n\\nOur economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.  \\n\\nFor the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else. \\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century. \\n\\nVice President Harris and I ran for office with a new economic vision for America. \\n\\nInvest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up  \\nand the middle out, not from the top down.  \\n\\nBecause we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \\n\\nAmerica used to have the best roads, bridges, and airports on Earth. \\n\\nNow our infrastructure is ranked 13th in the world. \\n\\nWe won’t be able to compete for the jobs of the 21st Century if we don’t fix that. \\n\\nThat’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history. \\n\\nThis was a bipartisan effort, and I want to thank the members of both parties who worked to make it happen. \\n\\nWe’re done talking about infrastructure weeks. \\n\\nWe’re going to have an infrastructure decade. \\n\\nIt is going to transform America and put us on a path to win the economic competition of the 21st Century that we face with the rest of the world—particularly with China.  \\n\\nAs I’ve told Xi Jinping, it is never a good bet to bet against the American people. \\n\\nWe’ll create good jobs for millions of Americans, modernizing roads, airports, ports, and waterways all across America. \\n\\nAnd we’ll do it all to withstand the devastating effects of the climate crisis and promote environmental justice. \\n\\nWe’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school, provide affordable high-speed internet for every American—urban, suburban, rural, and tribal communities. \\n\\n4,000 projects have already been announced. \\n\\nAnd tonight, I’m announcing that this year we will start fixing over 65,000 miles of highway and 1,500 bridges in disrepair. \\n\\nWhen we use taxpayer dollars to rebuild America – we are going to Buy American: buy American products to support American jobs.', metadata={'vector': array([-0.01198708, -0.01653345, -0.00826672, ..., -0.02187278,\n",
       "         -0.00984606, -0.01268754], dtype=float32), 'id': '4aeaa6cd-99ab-4f59-be53-d1a8a4fd63c5', '_distance': 0.4809805452823639}),\n",
       "  Document(page_content='That’s why I’ve proposed closing loopholes so the very wealthy don’t pay a lower tax rate than a teacher or a firefighter.  \\n\\nSo that’s my plan. It will grow the economy and lower costs for families. \\n\\nSo what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted. \\n\\nBut in my administration, the watchdogs have been welcomed back. \\n\\nWe’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year. \\n\\nLowering your costs also means demanding more competition. \\n\\nI’m a capitalist, but capitalism without competition isn’t capitalism. \\n\\nIt’s exploitation—and it drives up prices. \\n\\nWhen corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under. \\n\\nWe see it happening with ocean carriers moving goods in and out of America. \\n\\nDuring the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits. \\n\\nTonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \\n\\nThat ends on my watch. \\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \\n\\nWe’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \\n\\nLet’s pass the Paycheck Fairness Act and paid leave.  \\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \\n\\nLet’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges. \\n\\nAnd let’s pass the PRO Act when a majority of workers want to form a union—they shouldn’t be stopped.  \\n\\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven’t done in a long time: build a better America. \\n\\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \\n\\nAnd I know you’re tired, frustrated, and exhausted. \\n\\nBut I also know this. \\n\\nBecause of the progress we’ve made, because of your resilience and the tools we have, tonight I can say  \\nwe are moving forward safely, back to more normal routines.  \\n\\nWe’ve reached a new moment in the fight against COVID-19, with severe cases down to a level not seen since last July.  \\n\\nJust a few days ago, the Centers for Disease Control and Prevention—the CDC—issued new mask guidelines. \\n\\nUnder these new guidelines, most Americans in most of the country can now be mask free.   \\n\\nAnd based on the projections, more of the country will reach that point across the next couple of weeks. \\n\\nThanks to the progress we have made this past year, COVID-19 need no longer control our lives.  \\n\\nI know some are talking about “living with COVID-19”. Tonight – I say that we will never just accept living with COVID-19.', metadata={'vector': array([-2.1565778e-02, -1.6201356e-02, -1.4039375e-02, ...,\n",
       "         -7.7960161e-05, -5.2326736e-03, -3.2294612e-02], dtype=float32), 'id': '156c2cca-02c6-419a-8e02-9bd76407af32', '_distance': 0.5110093951225281})],\n",
       " 'answer': '总统在上下文中讲了以下几个主要内容：\\n\\n1. 讲述了俄罗斯总统普京对乌克兰的侵略行为，并表示美国与其他国家一起对俄罗斯实施经济制裁，以支持乌克兰人民。\\n\\n2. 强调了美国的经济复苏和创造就业机会，提到了通过美国救援计划和基础设施法案来支持经济增长和改善中产阶级生活的措施。\\n\\n3. 承诺改善医疗保健系统，提高护理家庭和护理院的质量，提供更多的培训和学徒机会，提高最低工资，支持工会组织等。\\n\\n4. 强调了对COVID-19的抗击取得的进展，称已经达到了可以回归更正常生活的阶段，并表示不会接受与COVID-19长期共存的观点。'}"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke({\"input\": \"总统说了什么？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3f4a0-4a82-411b-9bb7-4a02faf28841",
   "metadata": {},
   "source": [
    "## 支持的LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a2341-2019-4d1a-9778-9a6bebdecb67",
   "metadata": {},
   "source": [
    "## 支持的向量数据库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa5206-84b8-4bd1-9696-779375d2fa61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 项目模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d1dfe-2773-4a49-b95b-78d840103a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c3d4de-a689-4d59-a457-5244eb77305f",
   "metadata": {},
   "source": [
    "#### 输入和输出模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d488b0-32af-4ddc-aa4e-7abea35c8bb4",
   "metadata": {},
   "source": [
    "#### 无缝LangSmith跟踪集成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a78a6c0-303f-473d-ac02-98b429407bb3",
   "metadata": {},
   "source": [
    "#### 无缝LangServe部署集成"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
