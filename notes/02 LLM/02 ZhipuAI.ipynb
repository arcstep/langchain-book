{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf794d1-56b9-4741-958c-e4c7a29cf680",
   "metadata": {},
   "source": [
    "# 智谱大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a08d8af-804e-4af6-a8c6-3d412a93bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c410b11-7325-4d64-9e95-46191ed599d4",
   "metadata": {},
   "source": [
    "## 智谱API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5a22e-5cee-47fc-aac2-7f6b873b18a0",
   "metadata": {},
   "source": [
    "### 安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84106a2-80c2-40b4-a0dc-ba8416933643",
   "metadata": {},
   "source": [
    "由于智谱官方的 zhipuai 需要 pydantic v2，与 langchain的某些包（如langserve）不兼容，因此在langchain中不建议使用。<br>\n",
    "我从 zhipuai 专门修改了一个 zhipuai_pydantic_v1，用来兼容 pydantic v1，所有API与 zhipuai 完全一致。\n",
    "\n",
    "我们可以使用 zhipuai_pydantic_v1 来做接下来的所有测试。\n",
    "（如果你执意要用 zhipuai，那么在使用 langchain_chinese 之前记得将其卸载）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520afc5d-d756-44a7-9e77-51ef609bd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_zhipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad20f5-2780-455e-9544-5986fbd04cfd",
   "metadata": {},
   "source": [
    "### 同步调用（原生API调用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbfb318c-caea-439a-927c-37dabd8ca2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='glm-4' created=1710868411 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='我是「文成」，您的AI助手。有什么可以帮助您的？', role='assistant', tool_calls=None))] request_id='8489588694179864513' id='8489588694179864513' usage=CompletionUsage(prompt_tokens=82, completion_tokens=15, total_tokens=97)\n"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\", \n",
    "    temperature = 0.95,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是一个强大的助手，你的名字叫「文成」，不要啰嗦\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"我的名字是「文成」，我是一名AI助手，请向我提问。\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"我是小明，你叫什么名字呢？\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7950752f-b64f-4498-9f8a-e016c582cea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "\n",
    "llm = ChatZhipuAI()\n",
    "llm.get_num_tokens(\"你是？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca73ad99-a4fe-4a54-ab10-3dd0c99de810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='glm-4' created=1708402885 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='我是文成，一个基于人工智能技术的助手。很高兴遇见你，小明！如果你有任何问题或需要帮助，请随时告诉我。', role='assistant', tool_calls=None))] request_id='8367747962398260138' id='8367747962398260138' usage=CompletionUsage(prompt_tokens=80, completion_tokens=29, total_tokens=109)\n"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\", \n",
    "    temperature = 0.95,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是一个强大的助手，你的名字叫「文成」\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"我的名字是「文成」，我是一名AI助手，请向我提问。\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"我是小明，你叫什么名字呢？\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574faba-7a31-4c2e-8772-ba6a5233175d",
   "metadata": {},
   "source": [
    "### 事件流（原生API调用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb9ba9b4-42a2-41dc-ae04-64a493c390db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "土|星|是|太阳|系|中的一|颗|气体|巨星|行星|，|位于|太阳|系的|第六|位|，|是|继|木|星|之后|太阳|系|中|最大的|行星|。|土|星|的一些|基本|信息|如下|：|\n",
      "\n",
      "大小|和|质量|：|\n",
      "-| |直径|约为|1|2|0|,|5|3|6|公里|，|大约|是|地球|直径|的|9|.|5|倍|。|\n",
      "-| |质量|约为|5|.|6|8|3| × |1|0|^|2|6|千克|，|大约|是|地球|质量|的|9|5|倍|。|\n",
      "\n",
      "组成|：|\n",
      "-| |土|星|主要由|氢|和|氦|组成|，|这两种|元素|占据了|其|大部分|体积|和|质量|。|\n",
      "-| |内部|结构|由|金属|氢|、|液|态|氢|和|氦|组成|，|外部|是由|氢|和|氦|组成|的大|气|层|。|\n",
      "\n",
      "环|系统|：|\n",
      "-| |土|星|最|著名的|特征|之一|是其|壮|观的|环|系统|，|由|冰|颗粒|、|岩石|碎片|和|尘埃|组成|。|\n",
      "-| |这些|环|围绕|土|星的|赤|道|平面|，|呈现出|一种|明|亮的|环|状|结构|。|\n",
      "-| |环|中的|颗粒|物质|大小|不一|，|从|微|小的|尘埃|粒子|到|较大的|岩石|块|。|\n",
      "\n",
      "独特|的天|文|现象|：|\n",
      "-| |土|星的|北极|呈|正|六|边|形|，|南极|像|台风|眼|，|这是|由|土|星|大气|层|中|的一种|奇特|现象|造成的|。|\n",
      "-| 这个|六|边|形的|云|带|被称为|“|土|星的|北极|六|边|形|”，|其|边缘|像|巨大的|喷|气|流|一样|高速|旋转|。|\n",
      "\n",
      "卫星|：|\n",
      "-| |土|星|已知|有|6|2|颗|卫星|，|其中|一些|非常|著名|，|包括|泰|坦|（|土|卫|六|）、|瑞|亚|（|土|卫|八|）|和|恩|塞|拉|达|斯|（|土|卫|五|）。|\n",
      "-| |泰|坦|是|土|星|系统中|最大|和|太阳|系|中|第二|大的|卫星|，|直径|约为|5|,|1|5|0|公里|。|\n",
      "\n",
      "观测|和|探索|：|\n",
      "-| |土|星|可以通过|肉眼|观测|到|，|但由于|其|距离|太阳|较|远|，|视|星|等|较|暗|。|\n",
      "-| |借助|望远镜|，|可以|观察|到|土|星的|环|系统和|一些|卫星|。|\n",
      "-| |土|星|已被|多个|太空|探测器|访问|过|，|其中|最|著名|的是|卡|西|尼|号|探测器|，|它在|2|0|0|4|年|进入|土|星|轨道|，|并|进行了|长达|1|3|年的|详细|观察|和研究|，|直到|2|0|1|7|年|任务|结束|。|\n",
      "\n",
      "这些|信息|提供了|对|土|星|的基本|了解|，|土|星|是|太阳|系|中最|吸引|人的|研究|对象|之一|，|其|壮|观的|环|系统和|丰富的|卫星|系统|为|天|文学家|提供了|许多|研究|的机会|。||"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\"},\n",
    "        {\"role\": \"user\", \"content\": \"我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    # print(chunk)\n",
    "    print(chunk.choices[0].delta.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6522284-f42d-49ad-af52-6361a30b128c",
   "metadata": {},
   "source": [
    "### 函数回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3be26d-2688-49e2-b946-11d69a87d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8367745282338832529', function=Function(arguments='{\"date\":\"2024-01-01\",\"departure\":\"北京南站\",\"destination\":\"上海\"}', name='query_train_info'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你能帮我查询2024年1月1日从北京南站到上海的火车票吗？\"\n",
    "        }\n",
    "    ],\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"query_train_info\",\n",
    "                \"description\": \"根据用户提供的信息，查询对应的车次\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"departure\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"出发城市或车站\",\n",
    "                        },\n",
    "                        \"destination\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"目的地城市或车站\",\n",
    "                        },\n",
    "                        \"date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"要查询的车次日期\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"departure\", \"destination\", \"date\"],\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97719bd5-f6d3-42ea-8b8e-afe9f832efd0",
   "metadata": {},
   "source": [
    "## 作为 RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5638e8-0239-4d28-a823-b11fc3f018ee",
   "metadata": {},
   "source": [
    "### 基本功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0efd3192-a55e-43f4-87c3-eed109669e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "def zhipu_chat(messages: [str]):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-3-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b766065-6af9-4cc7-b4d0-2d166a559d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"讲一个关于程序员的笑话\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd003c64-d049-4086-bb9b-5b405a659933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146156, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。', role='assistant', tool_calls=None))], request_id='8367745522857040954', id='8367745522857040954', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhipu_chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f0fc0-c56e-4666-9326-2b1665d4206f",
   "metadata": {},
   "source": [
    "### 包装为 Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38630740-a807-4abe-a2bb-fa0453570906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "my_zhipu_chat = RunnableLambda(zhipu_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa9f933b-3d87-44a4-b30f-cce4077af8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146224, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。', role='assistant', tool_calls=None))], request_id='8367743907949124838', id='8367743907949124838', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_zhipu_chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0eeac3-e13d-4f0b-b596-224ceb4edfe2",
   "metadata": {},
   "source": [
    "## ZhipuAIChatTiny：最小实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae00ed7-e906-4c8c-84de-b49ad16f1205",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d42b0f75-38e2-4ee9-a05e-2b62e6852312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee69cc23-7cf2-4781-b22c-d7f3c6ac051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatTiny(BaseChatModel):\n",
    "    \"\"\"支持最新的智谱API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "    \n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        try:\n",
    "            # 声明 ZhipuAI 的客户端\n",
    "            from zhipuai import ZhipuAI\n",
    "            self.client = ZhipuAI()\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\n",
    "                \"Could not import zhipuai package. \"\n",
    "                \"Please install it via 'pip install zhipuai'\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"使用 ZhiputAI 的同步调用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[ChatGeneration(message=AIMessage(content=content))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4064b74-9b37-49c7-af85-0bb8e4a93714",
   "metadata": {},
   "source": [
    "### 使用 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3849056a-737a-48a4-b277-b96be53b9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tiny = ZhipuAIChatTiny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e769ea77-cf06-4a70-ae9f-d4e850183a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='为什么程序员总是携带电脑？因为他们不想被人叫做\"裸奔者\"。')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tiny.invoke(\"讲一个关于程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dafe8-3367-4e67-be39-2e8bfa2aae86",
   "metadata": {},
   "source": [
    "### 使用 LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2efbe57-af87-465e-a87a-848e44a2b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm_tiny | StrOutputParser()\n",
    "chain.invoke(\"讲一个关于程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a949f28-944a-4de3-a968-a638d2a692ac",
   "metadata": {},
   "source": [
    "### 使用 Prompt + LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f315c64f-42c5-4309-a5eb-317539426b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好的，下面是一个关于程序员的笑话：\\n\\n为什么程序员不喜欢自然界？\\n\\n因为那里有太多的bugs（虫子/错误）！\\n\\n希望这个笑话能让您开心一下！'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"讲一个关于{topic}的笑话\")\n",
    "chain = prompt | llm_tiny | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"topic\": \"程序员\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8cde2-562d-4693-ae26-e001127e0d8f",
   "metadata": {},
   "source": [
    "### 使用流式输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad73202-4d5e-4589-b966-fd6eee9fa26d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>⚠️ 注意：</b><br>\n",
    "    因为我们没有实现 stream 方法，基类中的实现将自动调用 invoke 方法，然后一次性返回结果。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ab323c7-1763-41d4-b25c-333429bc622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么程序员总是混淆圣诞节和万圣节？因为 Oct 31 等于 Dec 25。_"
     ]
    }
   ],
   "source": [
    "for chunk in llm_tiny.stream(\"讲一个关于程序员的一句话笑话\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9dbbd-c90e-4d0c-b142-2f51bee0ca60",
   "metadata": {},
   "source": [
    "## ZhipuAIChatStream：支持流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd91e9f-4370-4f1b-be68-baad04563ffb",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a49c34a7-90b0-4fd3-8b52-901027cbf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "03e52ee2-19e2-4f39-a436-ddad0548abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatStream(BaseChatModel):\n",
    "    \"\"\"支持最新的智谱API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.client = ZhipuAI()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"使用 ZhiputAI 的同步调用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        choice = response.choices[0]\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[\n",
    "                ChatGeneration(\n",
    "                    message=AIMessage(content=choice.message.content),\n",
    "            )],\n",
    "        )\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        \"\"\"使用 ZhiputAI 的事件流用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        # 使用流输出\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in response:\n",
    "            choice = chunk.choices[0]\n",
    "            yield ChatGenerationChunk(\n",
    "                message=AIMessageChunk(content=choice.delta.content),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d0923-a2ae-4dfa-8a28-24c5845d2b73",
   "metadata": {},
   "source": [
    "### 使用 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1f7b2ce7-5d53-47d4-9ea6-eff280f8ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_stream = ZhipuAIChatStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "969c12be-0cd7-4fdd-89bc-0a49f4421bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_stream.invoke(\"讲一个程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcb2e1-e587-4bef-994f-c2338cc674bb",
   "metadata": {},
   "source": [
    "### 使用流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6b667e06-281d-4b03-9779-fe1b497aae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么_程序_员_总是_混淆_圣诞_节_和_万_圣_节_？_因为_ Oct_ _3_1_ _等于_ Dec_ _2_5_。__"
     ]
    }
   ],
   "source": [
    "for chunk in llm_stream.stream(\"讲一个关于程序员的一句话笑话\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7576f-ba07-4af2-bfde-48addef52ffc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>🏅️ 成功了！</b><br>\n",
    "    现在运行上面的代码，应当可以看到流式输出！\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa408cba-9e05-462a-a573-5f84ee025d9e",
   "metadata": {},
   "source": [
    "## ChatZhipuAI：在 langchain_chinese 中完整实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a8d2e-2c69-4f72-b94a-16976a4bc62d",
   "metadata": {},
   "source": [
    "完整的实现较为繁琐，可以在前面实践的基础上补充：\n",
    "\n",
    "- 支持所有模型参数\n",
    "- 支持异步方法\n",
    "- 支持事件流推送\n",
    "- 支持智谱的Tool回调\n",
    "- 支持内置的search工具\n",
    "- 支持内置的检索工具\n",
    "- 支持图片生成能力\n",
    "- 支持调用中的异常\n",
    "- 提供便利的bind_tools方法\n",
    "- 提供基于Tool调用的Agent\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68bfd0fb-c590-4df6-b8fd-81551d54e60d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe currently activated Python version 3.9.18 is not supported by the project (>=3.10,<3.12).\n",
      "Trying to find and use a compatible version.\u001b[39m \n",
      "Using \u001b[36mpython3\u001b[39m (3.10.0)\n",
      "Using version \u001b[39;1m^0.2.13\u001b[39;22m for \u001b[36mlangchain-chinese\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl  13%\u001b[39m \u001b[39;2m(109.3s)\u001b[39;22mmm9m \u001b[39;2m(39.8s)\u001b[39;22mloading https://files.pythonhosted.org/packages/33/47/fc483df0b7ddeee987b6ff146c879d3556fcea82cc9aa4203d16e5871c62/numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl\u001b[39m \u001b[39;2m(2.2s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/33/47/fc483df0b7ddeee987b6ff146c879d3556fcea82cc9aa4203d16e5871c62/numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl   8%\u001b[39m \u001b[39;2m(3.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/33/47/fc483df0b7ddeee987b6ff146c879d3556fcea82cc9aa4203d16e5871c62/numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl  66%\u001b[39m \u001b[39;2m(4.6s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(7.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(9.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(15.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(18.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(22.7s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(23.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(28.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(30.6s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(34.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(35.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(36.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(37.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(38.2s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(40.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(42.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(47.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl\u001b[39m \u001b[39;2m(48.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(49.7s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(53.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(57.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(58.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(61.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(63.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(65.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(71.7s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\u001b[39m \u001b[39;2m(74.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  17%\u001b[39m \u001b[39;2m(76.6s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  28%\u001b[39m \u001b[39;2m(77.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  50%\u001b[39m \u001b[39;2m(80.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  61%\u001b[39m \u001b[39;2m(81.2s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  72%\u001b[39m \u001b[39;2m(82.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  86%\u001b[39m \u001b[39;2m(83.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(86.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/1e/07/bf730d44c2fe1b676ad9cc2be5f5f861eb5d153fb6951987a2d6a96379a9/nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl  56%\u001b[39m \u001b[39;2m(87.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/1e/07/bf730d44c2fe1b676ad9cc2be5f5f861eb5d153fb6951987a2d6a96379a9/nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl  99%\u001b[39m \u001b[39;2m(87.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl   5%\u001b[39m \u001b[39;2m(89.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl  72%\u001b[39m \u001b[39;2m(91.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(93.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  16%\u001b[39m \u001b[39;2m(94.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  61%\u001b[39m \u001b[39;2m(98.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  70%\u001b[39m \u001b[39;2m(99.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  94%\u001b[39m \u001b[39;2m(102.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl   3%\u001b[39m \u001b[39;2m(105.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl   9%\u001b[39m \u001b[39;2m(107.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl  13%\u001b[39m \u001b[39;2m(109.1s)\u001b[39;22m^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!poetry add langchain_chinese@latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588e60c-2643-4ba1-9f41-881313d59d51",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <b>ChatZhipuAI的完整实现已经发布</b><br>\n",
    "    我将完整的实现作为 langchain_chinese 包的一部份发布了。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fe773-d3d5-4300-9e34-e08a00fe9414",
   "metadata": {},
   "source": [
    "**项目地址** [https://pypi.org/project/langchain_chinese/](https://pypi.org/project/langchain_chinese/)<br> \n",
    "**源代码地址** [https://github.com/arcstep/langchain_chinese](https://github.com/arcstep/langchain_chinese)\n",
    "\n",
    "你可以通过 pip 安装：\n",
    "\n",
    "```\n",
    "pip install -U langchain_chinese\n",
    "```\n",
    "或\n",
    "\n",
    "```\n",
    "poetry add langchain_chinese@latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298c6312-53a4-477b-8291-607fe84d0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chinese import ChatZhipuAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ac93f3-3594-4a40-8738-9b0c4d7f1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatZhipuAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f497c0-cd86-464b-9b32-0fbd4b576a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个强力助手。\"),\n",
    "    (\"assistant\", \"我是一名AI助手，请向我提问。\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa50d0-027a-405a-aecf-0ab025878e79",
   "metadata": {},
   "source": [
    "#### 2024年清明假怎么安排的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499dcba6-6172-4093-8c4c-ac5ca7913808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202|4|年的|清明节|放假|安排|如下|：|4|月|4|日至|6|日|放假|调|休|，|共计|3|天|。|具体|来说|，|4|月|7|日|（|星期|日|）|需要|上班|。|清明节|是|中国的|传统|节日|，|也是|重要的|祭祀|节日|之一|，|主要用于|祭|祖|和|扫|墓|，|以|纪念|已|故|的|亲人|。|在这一|天|，|人们|通常会|携带|祭|品|前往|墓地|，|进行|祭|拜|活动|。|同时|，|清明节|也被|称作|踏|青|节|，|在|春|光明|媚|的季节|里|，|许多人|也会|选择|外出|踏|青|，|享受|春天的|自然|景色|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01)\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024年清明假怎么安排的？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b837d7e2-4fdb-4a92-881e-1ed87f30ca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据|国务院|的|安排|，|202|4|年|清明节|放假|调|休|如下|：|4|月|4|日至|6|日|放假|，|共|3|天|。|4|月|7|日|（|星期|日|）|上班|。|这意味着|清明节|期间|，|大家|可以从|4|月|4|日开始|连续|休息|三天|，|但是|需要在|4|月|7|日|（|周日|）|补|班|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01).bind(\n",
    "    tools=[{\n",
    "        \"type\": \"web_search\", \n",
    "        \"web_search\":{\n",
    "            \"enable\":True,\n",
    "            \"search_query\": \"国务院2024年放假安排\"\n",
    "        }\n",
    "    }])\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024年清明假怎么安排的？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b607f0cb-c504-4a99-a194-9eebd3268dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截至|我的|知识|更新|日期|（|202|3|年|），|我|无法|提供|202|4|年|清明|假的|具体|安排|，|因为这些|信息|通常|会在|当年|年初|由|相关部门|公布|。|清明节|是|中国的|传统|节日|，|也是|公众|假期|之一|，|通常|会有|1|天的|法定|假期|，|但|具体的|放假|安排|可能会|结合|周末|调|休|形成|小|长假|。\n",
      "\n",
      "为了|获取|202|4|年|清明|假的|准确|安排|，|建议|您|在|接近|那个|时期|时|关注|官方|发布的|节假日|安排|通知|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01).bind(\n",
    "    tools=[{\n",
    "        \"type\": \"web_search\", \n",
    "        \"web_search\":{\n",
    "            \"enable\":False\n",
    "        }\n",
    "    }])\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024年清明假怎么安排的？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694aff7-06fe-48ef-9694-8e0946f942fc",
   "metadata": {},
   "source": [
    "#### 今天星期几？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f29bf02-120c-47ab-b9fe-55a05f1e51a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抱歉|，|作为一个|AI|，|我没有|实|时的|日期|和时间|信息|。|我|建议|您|查看|您的|设备|上的|日|历来|确定|今天是|星期|几|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01)\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"今天星期几？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50c8bdc2-46eb-481e-9340-9361d8798b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个强力助手。'), AIMessage(content='我是一名AI助手，请向我提问。'), HumanMessage(content='你是谁？')])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"你是谁？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d01fbcce-2432-4559-b803-692057db62b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我是由 OpenAI 开发的一个人工智能助手，旨在帮助用户回答问题、提供信息、解决问题和执行各种任务。我的设计是为了与用户进行自然对话，并在多个领域提供支持。很高兴见到你，ChatGLM！如果有任何问题或需要帮助，请随时告诉我。'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"你是谁？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b01bd70f-2d54-4caf-81da-4e43dd6b8e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZhipuAIChat(client=<zhipuai._client.ZhipuAI object at 0x1192c81c0>)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = ZhipuAIChat(model=\"ABC\")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b0002b6a-dce9-45c2-8773-500d642a45b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glm-3-turbo'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f91ceb-7768-4afb-85b8-a6e847174ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chain.ainvoke({\"question\": \"你是谁？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b480c-f2cb-4914-b6be-2d7461a5f0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
