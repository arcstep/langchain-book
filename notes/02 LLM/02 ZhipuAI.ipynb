{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf794d1-56b9-4741-958c-e4c7a29cf680",
   "metadata": {},
   "source": [
    "# æ™ºè°±å¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a08d8af-804e-4af6-a8c6-3d412a93bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c410b11-7325-4d64-9e95-46191ed599d4",
   "metadata": {},
   "source": [
    "## æ™ºè°±API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5a22e-5cee-47fc-aac2-7f6b873b18a0",
   "metadata": {},
   "source": [
    "### å®‰è£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84106a2-80c2-40b4-a0dc-ba8416933643",
   "metadata": {},
   "source": [
    "ç”±äºæ™ºè°±å®˜æ–¹çš„ zhipuai éœ€è¦ pydantic v2ï¼Œä¸ langchainçš„æŸäº›åŒ…ï¼ˆå¦‚langserveï¼‰ä¸å…¼å®¹ï¼Œå› æ­¤åœ¨langchainä¸­ä¸å»ºè®®ä½¿ç”¨ã€‚<br>\n",
    "æˆ‘ä» zhipuai ä¸“é—¨ä¿®æ”¹äº†ä¸€ä¸ª zhipuai_pydantic_v1ï¼Œç”¨æ¥å…¼å®¹ pydantic v1ï¼Œæ‰€æœ‰APIä¸ zhipuai å®Œå…¨ä¸€è‡´ã€‚\n",
    "\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ zhipuai_pydantic_v1 æ¥åšæ¥ä¸‹æ¥çš„æ‰€æœ‰æµ‹è¯•ã€‚\n",
    "ï¼ˆå¦‚æœä½ æ‰§æ„è¦ç”¨ zhipuaiï¼Œé‚£ä¹ˆåœ¨ä½¿ç”¨ langchain_chinese ä¹‹å‰è®°å¾—å°†å…¶å¸è½½ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520afc5d-d756-44a7-9e77-51ef609bd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_zhipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad20f5-2780-455e-9544-5986fbd04cfd",
   "metadata": {},
   "source": [
    "### åŒæ­¥è°ƒç”¨ï¼ˆåŸç”ŸAPIè°ƒç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbfb318c-caea-439a-927c-37dabd8ca2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='glm-4' created=1710868411 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='æˆ‘æ˜¯ã€Œæ–‡æˆã€ï¼Œæ‚¨çš„AIåŠ©æ‰‹ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ', role='assistant', tool_calls=None))] request_id='8489588694179864513' id='8489588694179864513' usage=CompletionUsage(prompt_tokens=82, completion_tokens=15, total_tokens=97)\n"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\", \n",
    "    temperature = 0.95,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åŠ©æ‰‹ï¼Œä½ çš„åå­—å«ã€Œæ–‡æˆã€ï¼Œä¸è¦å•°å—¦\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"æˆ‘çš„åå­—æ˜¯ã€Œæ–‡æˆã€ï¼Œæˆ‘æ˜¯ä¸€åAIåŠ©æ‰‹ï¼Œè¯·å‘æˆ‘æé—®ã€‚\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"æˆ‘æ˜¯å°æ˜ï¼Œä½ å«ä»€ä¹ˆåå­—å‘¢ï¼Ÿ\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7950752f-b64f-4498-9f8a-e016c582cea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "\n",
    "llm = ChatZhipuAI()\n",
    "llm.get_num_tokens(\"ä½ æ˜¯ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca73ad99-a4fe-4a54-ab10-3dd0c99de810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='glm-4' created=1708402885 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='æˆ‘æ˜¯æ–‡æˆï¼Œä¸€ä¸ªåŸºäºäººå·¥æ™ºèƒ½æŠ€æœ¯çš„åŠ©æ‰‹ã€‚å¾ˆé«˜å…´é‡è§ä½ ï¼Œå°æ˜ï¼å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚', role='assistant', tool_calls=None))] request_id='8367747962398260138' id='8367747962398260138' usage=CompletionUsage(prompt_tokens=80, completion_tokens=29, total_tokens=109)\n"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\", \n",
    "    temperature = 0.95,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ä½ æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åŠ©æ‰‹ï¼Œä½ çš„åå­—å«ã€Œæ–‡æˆã€\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"æˆ‘çš„åå­—æ˜¯ã€Œæ–‡æˆã€ï¼Œæˆ‘æ˜¯ä¸€åAIåŠ©æ‰‹ï¼Œè¯·å‘æˆ‘æé—®ã€‚\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"æˆ‘æ˜¯å°æ˜ï¼Œä½ å«ä»€ä¹ˆåå­—å‘¢ï¼Ÿ\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574faba-7a31-4c2e-8772-ba6a5233175d",
   "metadata": {},
   "source": [
    "### äº‹ä»¶æµï¼ˆåŸç”ŸAPIè°ƒç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb9ba9b4-42a2-41dc-ae04-64a493c390db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åœŸ|æ˜Ÿ|æ˜¯|å¤ªé˜³|ç³»|ä¸­çš„ä¸€|é¢—|æ°”ä½“|å·¨æ˜Ÿ|è¡Œæ˜Ÿ|ï¼Œ|ä½äº|å¤ªé˜³|ç³»çš„|ç¬¬å…­|ä½|ï¼Œ|æ˜¯|ç»§|æœ¨|æ˜Ÿ|ä¹‹å|å¤ªé˜³|ç³»|ä¸­|æœ€å¤§çš„|è¡Œæ˜Ÿ|ã€‚|åœŸ|æ˜Ÿ|çš„ä¸€äº›|åŸºæœ¬|ä¿¡æ¯|å¦‚ä¸‹|ï¼š|\n",
      "\n",
      "å¤§å°|å’Œ|è´¨é‡|ï¼š|\n",
      "-| |ç›´å¾„|çº¦ä¸º|1|2|0|,|5|3|6|å…¬é‡Œ|ï¼Œ|å¤§çº¦|æ˜¯|åœ°çƒ|ç›´å¾„|çš„|9|.|5|å€|ã€‚|\n",
      "-| |è´¨é‡|çº¦ä¸º|5|.|6|8|3| Ã— |1|0|^|2|6|åƒå…‹|ï¼Œ|å¤§çº¦|æ˜¯|åœ°çƒ|è´¨é‡|çš„|9|5|å€|ã€‚|\n",
      "\n",
      "ç»„æˆ|ï¼š|\n",
      "-| |åœŸ|æ˜Ÿ|ä¸»è¦ç”±|æ°¢|å’Œ|æ°¦|ç»„æˆ|ï¼Œ|è¿™ä¸¤ç§|å…ƒç´ |å æ®äº†|å…¶|å¤§éƒ¨åˆ†|ä½“ç§¯|å’Œ|è´¨é‡|ã€‚|\n",
      "-| |å†…éƒ¨|ç»“æ„|ç”±|é‡‘å±|æ°¢|ã€|æ¶²|æ€|æ°¢|å’Œ|æ°¦|ç»„æˆ|ï¼Œ|å¤–éƒ¨|æ˜¯ç”±|æ°¢|å’Œ|æ°¦|ç»„æˆ|çš„å¤§|æ°”|å±‚|ã€‚|\n",
      "\n",
      "ç¯|ç³»ç»Ÿ|ï¼š|\n",
      "-| |åœŸ|æ˜Ÿ|æœ€|è‘—åçš„|ç‰¹å¾|ä¹‹ä¸€|æ˜¯å…¶|å£®|è§‚çš„|ç¯|ç³»ç»Ÿ|ï¼Œ|ç”±|å†°|é¢—ç²’|ã€|å²©çŸ³|ç¢ç‰‡|å’Œ|å°˜åŸƒ|ç»„æˆ|ã€‚|\n",
      "-| |è¿™äº›|ç¯|å›´ç»•|åœŸ|æ˜Ÿçš„|èµ¤|é“|å¹³é¢|ï¼Œ|å‘ˆç°å‡º|ä¸€ç§|æ˜|äº®çš„|ç¯|çŠ¶|ç»“æ„|ã€‚|\n",
      "-| |ç¯|ä¸­çš„|é¢—ç²’|ç‰©è´¨|å¤§å°|ä¸ä¸€|ï¼Œ|ä»|å¾®|å°çš„|å°˜åŸƒ|ç²’å­|åˆ°|è¾ƒå¤§çš„|å²©çŸ³|å—|ã€‚|\n",
      "\n",
      "ç‹¬ç‰¹|çš„å¤©|æ–‡|ç°è±¡|ï¼š|\n",
      "-| |åœŸ|æ˜Ÿçš„|åŒ—æ|å‘ˆ|æ­£|å…­|è¾¹|å½¢|ï¼Œ|å—æ|åƒ|å°é£|çœ¼|ï¼Œ|è¿™æ˜¯|ç”±|åœŸ|æ˜Ÿ|å¤§æ°”|å±‚|ä¸­|çš„ä¸€ç§|å¥‡ç‰¹|ç°è±¡|é€ æˆçš„|ã€‚|\n",
      "-| è¿™ä¸ª|å…­|è¾¹|å½¢çš„|äº‘|å¸¦|è¢«ç§°ä¸º|â€œ|åœŸ|æ˜Ÿçš„|åŒ—æ|å…­|è¾¹|å½¢|â€ï¼Œ|å…¶|è¾¹ç¼˜|åƒ|å·¨å¤§çš„|å–·|æ°”|æµ|ä¸€æ ·|é«˜é€Ÿ|æ—‹è½¬|ã€‚|\n",
      "\n",
      "å«æ˜Ÿ|ï¼š|\n",
      "-| |åœŸ|æ˜Ÿ|å·²çŸ¥|æœ‰|6|2|é¢—|å«æ˜Ÿ|ï¼Œ|å…¶ä¸­|ä¸€äº›|éå¸¸|è‘—å|ï¼Œ|åŒ…æ‹¬|æ³°|å¦|ï¼ˆ|åœŸ|å«|å…­|ï¼‰ã€|ç‘|äºš|ï¼ˆ|åœŸ|å«|å…«|ï¼‰|å’Œ|æ©|å¡|æ‹‰|è¾¾|æ–¯|ï¼ˆ|åœŸ|å«|äº”|ï¼‰ã€‚|\n",
      "-| |æ³°|å¦|æ˜¯|åœŸ|æ˜Ÿ|ç³»ç»Ÿä¸­|æœ€å¤§|å’Œ|å¤ªé˜³|ç³»|ä¸­|ç¬¬äºŒ|å¤§çš„|å«æ˜Ÿ|ï¼Œ|ç›´å¾„|çº¦ä¸º|5|,|1|5|0|å…¬é‡Œ|ã€‚|\n",
      "\n",
      "è§‚æµ‹|å’Œ|æ¢ç´¢|ï¼š|\n",
      "-| |åœŸ|æ˜Ÿ|å¯ä»¥é€šè¿‡|è‚‰çœ¼|è§‚æµ‹|åˆ°|ï¼Œ|ä½†ç”±äº|å…¶|è·ç¦»|å¤ªé˜³|è¾ƒ|è¿œ|ï¼Œ|è§†|æ˜Ÿ|ç­‰|è¾ƒ|æš—|ã€‚|\n",
      "-| |å€ŸåŠ©|æœ›è¿œé•œ|ï¼Œ|å¯ä»¥|è§‚å¯Ÿ|åˆ°|åœŸ|æ˜Ÿçš„|ç¯|ç³»ç»Ÿå’Œ|ä¸€äº›|å«æ˜Ÿ|ã€‚|\n",
      "-| |åœŸ|æ˜Ÿ|å·²è¢«|å¤šä¸ª|å¤ªç©º|æ¢æµ‹å™¨|è®¿é—®|è¿‡|ï¼Œ|å…¶ä¸­|æœ€|è‘—å|çš„æ˜¯|å¡|è¥¿|å°¼|å·|æ¢æµ‹å™¨|ï¼Œ|å®ƒåœ¨|2|0|0|4|å¹´|è¿›å…¥|åœŸ|æ˜Ÿ|è½¨é“|ï¼Œ|å¹¶|è¿›è¡Œäº†|é•¿è¾¾|1|3|å¹´çš„|è¯¦ç»†|è§‚å¯Ÿ|å’Œç ”ç©¶|ï¼Œ|ç›´åˆ°|2|0|1|7|å¹´|ä»»åŠ¡|ç»“æŸ|ã€‚|\n",
      "\n",
      "è¿™äº›|ä¿¡æ¯|æä¾›äº†|å¯¹|åœŸ|æ˜Ÿ|çš„åŸºæœ¬|äº†è§£|ï¼Œ|åœŸ|æ˜Ÿ|æ˜¯|å¤ªé˜³|ç³»|ä¸­æœ€|å¸å¼•|äººçš„|ç ”ç©¶|å¯¹è±¡|ä¹‹ä¸€|ï¼Œ|å…¶|å£®|è§‚çš„|ç¯|ç³»ç»Ÿå’Œ|ä¸°å¯Œçš„|å«æ˜Ÿ|ç³»ç»Ÿ|ä¸º|å¤©|æ–‡å­¦å®¶|æä¾›äº†|è®¸å¤š|ç ”ç©¶|çš„æœºä¼š|ã€‚||"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",  # å¡«å†™éœ€è¦è°ƒç”¨çš„æ¨¡å‹åç§°\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¹äºè§£ç­”å„ç§é—®é¢˜çš„åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·æä¾›ä¸“ä¸šã€å‡†ç¡®ã€æœ‰è§åœ°çš„å»ºè®®ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"æˆ‘å¯¹å¤ªé˜³ç³»çš„è¡Œæ˜Ÿéå¸¸æ„Ÿå…´è¶£ï¼Œç‰¹åˆ«æ˜¯åœŸæ˜Ÿã€‚è¯·æä¾›å…³äºåœŸæ˜Ÿçš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶å¤§å°ã€ç»„æˆã€ç¯ç³»ç»Ÿå’Œä»»ä½•ç‹¬ç‰¹çš„å¤©æ–‡ç°è±¡ã€‚\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    # print(chunk)\n",
    "    print(chunk.choices[0].delta.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6522284-f42d-49ad-af52-6361a30b128c",
   "metadata": {},
   "source": [
    "### å‡½æ•°å›è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3be26d-2688-49e2-b946-11d69a87d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8367745282338832529', function=Function(arguments='{\"date\":\"2024-01-01\",\"departure\":\"åŒ—äº¬å—ç«™\",\"destination\":\"ä¸Šæµ·\"}', name='query_train_info'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ä½ èƒ½å¸®æˆ‘æŸ¥è¯¢2024å¹´1æœˆ1æ—¥ä»åŒ—äº¬å—ç«™åˆ°ä¸Šæµ·çš„ç«è½¦ç¥¨å—ï¼Ÿ\"\n",
    "        }\n",
    "    ],\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"query_train_info\",\n",
    "                \"description\": \"æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ŒæŸ¥è¯¢å¯¹åº”çš„è½¦æ¬¡\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"departure\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"å‡ºå‘åŸå¸‚æˆ–è½¦ç«™\",\n",
    "                        },\n",
    "                        \"destination\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"ç›®çš„åœ°åŸå¸‚æˆ–è½¦ç«™\",\n",
    "                        },\n",
    "                        \"date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"è¦æŸ¥è¯¢çš„è½¦æ¬¡æ—¥æœŸ\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"departure\", \"destination\", \"date\"],\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97719bd5-f6d3-42ea-8b8e-afe9f832efd0",
   "metadata": {},
   "source": [
    "## ä½œä¸º RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5638e8-0239-4d28-a823-b11fc3f018ee",
   "metadata": {},
   "source": [
    "### åŸºæœ¬åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0efd3192-a55e-43f4-87c3-eed109669e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "def zhipu_chat(messages: [str]):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-3-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b766065-6af9-4cc7-b4d0-2d166a559d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"è®²ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„ç¬‘è¯\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd003c64-d049-4086-bb9b-5b405a659933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146156, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æºå¸¦ç”µè„‘ï¼Ÿå› ä¸ºä»–ä»¬ä¸æƒ³è¢«äººç§°ä¸ºâ€œè£¸å¥”è€…â€ã€‚', role='assistant', tool_calls=None))], request_id='8367745522857040954', id='8367745522857040954', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhipu_chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f0fc0-c56e-4666-9326-2b1665d4206f",
   "metadata": {},
   "source": [
    "### åŒ…è£…ä¸º Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38630740-a807-4abe-a2bb-fa0453570906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "my_zhipu_chat = RunnableLambda(zhipu_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa9f933b-3d87-44a4-b30f-cce4077af8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146224, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æºå¸¦ç”µè„‘ï¼Ÿå› ä¸ºä»–ä»¬ä¸æƒ³è¢«äººç§°ä¸ºâ€œè£¸å¥”è€…â€ã€‚', role='assistant', tool_calls=None))], request_id='8367743907949124838', id='8367743907949124838', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_zhipu_chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0eeac3-e13d-4f0b-b596-224ceb4edfe2",
   "metadata": {},
   "source": [
    "## ZhipuAIChatTinyï¼šæœ€å°å®ç°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae00ed7-e906-4c8c-84de-b49ad16f1205",
   "metadata": {},
   "source": [
    "### å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d42b0f75-38e2-4ee9-a05e-2b62e6852312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee69cc23-7cf2-4781-b22c-d7f3c6ac051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatTiny(BaseChatModel):\n",
    "    \"\"\"æ”¯æŒæœ€æ–°çš„æ™ºè°±API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "    \n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        try:\n",
    "            # å£°æ˜ ZhipuAI çš„å®¢æˆ·ç«¯\n",
    "            from zhipuai import ZhipuAI\n",
    "            self.client = ZhipuAI()\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\n",
    "                \"Could not import zhipuai package. \"\n",
    "                \"Please install it via 'pip install zhipuai'\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"ä½¿ç”¨ ZhiputAI çš„åŒæ­¥è°ƒç”¨\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[ChatGeneration(message=AIMessage(content=content))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4064b74-9b37-49c7-af85-0bb8e4a93714",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3849056a-737a-48a4-b277-b96be53b9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tiny = ZhipuAIChatTiny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e769ea77-cf06-4a70-ae9f-d4e850183a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æºå¸¦ç”µè„‘ï¼Ÿå› ä¸ºä»–ä»¬ä¸æƒ³è¢«äººå«åš\"è£¸å¥”è€…\"ã€‚')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tiny.invoke(\"è®²ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„ä¸€å¥è¯ç¬‘è¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dafe8-3367-4e67-be39-2e8bfa2aae86",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2efbe57-af87-465e-a87a-848e44a2b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æºå¸¦ç”µè„‘ï¼Ÿå› ä¸ºä»–ä»¬ä¸æƒ³è¢«äººç§°ä¸ºâ€œè£¸å¥”è€…â€ã€‚'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm_tiny | StrOutputParser()\n",
    "chain.invoke(\"è®²ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„ä¸€å¥è¯ç¬‘è¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a949f28-944a-4de3-a968-a638d2a692ac",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ Prompt + LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f315c64f-42c5-4309-a5eb-317539426b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¥½çš„ï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„ç¬‘è¯ï¼š\\n\\nä¸ºä»€ä¹ˆç¨‹åºå‘˜ä¸å–œæ¬¢è‡ªç„¶ç•Œï¼Ÿ\\n\\nå› ä¸ºé‚£é‡Œæœ‰å¤ªå¤šçš„bugsï¼ˆè™«å­/é”™è¯¯ï¼‰ï¼\\n\\nå¸Œæœ›è¿™ä¸ªç¬‘è¯èƒ½è®©æ‚¨å¼€å¿ƒä¸€ä¸‹ï¼'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"è®²ä¸€ä¸ªå…³äº{topic}çš„ç¬‘è¯\")\n",
    "chain = prompt | llm_tiny | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"topic\": \"ç¨‹åºå‘˜\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8cde2-562d-4693-ae26-e001127e0d8f",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad73202-4d5e-4589-b966-fd6eee9fa26d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ³¨æ„ï¼š</b><br>\n",
    "    å› ä¸ºæˆ‘ä»¬æ²¡æœ‰å®ç° stream æ–¹æ³•ï¼ŒåŸºç±»ä¸­çš„å®ç°å°†è‡ªåŠ¨è°ƒç”¨ invoke æ–¹æ³•ï¼Œç„¶åä¸€æ¬¡æ€§è¿”å›ç»“æœã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ab323c7-1763-41d4-b25c-333429bc622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æ··æ·†åœ£è¯èŠ‚å’Œä¸‡åœ£èŠ‚ï¼Ÿå› ä¸º Oct 31 ç­‰äº Dec 25ã€‚_"
     ]
    }
   ],
   "source": [
    "for chunk in llm_tiny.stream(\"è®²ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„ä¸€å¥è¯ç¬‘è¯\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9dbbd-c90e-4d0c-b142-2f51bee0ca60",
   "metadata": {},
   "source": [
    "## ZhipuAIChatStreamï¼šæ”¯æŒæµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd91e9f-4370-4f1b-be68-baad04563ffb",
   "metadata": {},
   "source": [
    "### å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a49c34a7-90b0-4fd3-8b52-901027cbf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "03e52ee2-19e2-4f39-a436-ddad0548abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatStream(BaseChatModel):\n",
    "    \"\"\"æ”¯æŒæœ€æ–°çš„æ™ºè°±API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.client = ZhipuAI()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"ä½¿ç”¨ ZhiputAI çš„åŒæ­¥è°ƒç”¨\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        choice = response.choices[0]\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[\n",
    "                ChatGeneration(\n",
    "                    message=AIMessage(content=choice.message.content),\n",
    "            )],\n",
    "        )\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        \"\"\"ä½¿ç”¨ ZhiputAI çš„äº‹ä»¶æµç”¨\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        # ä½¿ç”¨æµè¾“å‡º\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in response:\n",
    "            choice = chunk.choices[0]\n",
    "            yield ChatGenerationChunk(\n",
    "                message=AIMessageChunk(content=choice.delta.content),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d0923-a2ae-4dfa-8a28-24c5845d2b73",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1f7b2ce7-5d53-47d4-9ea6-eff280f8ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_stream = ZhipuAIChatStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "969c12be-0cd7-4fdd-89bc-0a49f4421bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æºå¸¦ç”µè„‘ï¼Ÿå› ä¸ºä»–ä»¬ä¸æƒ³è¢«äººç§°ä¸ºâ€œè£¸å¥”è€…â€ã€‚')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_stream.invoke(\"è®²ä¸€ä¸ªç¨‹åºå‘˜çš„ä¸€å¥è¯ç¬‘è¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcb2e1-e587-4bef-994f-c2338cc674bb",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6b667e06-281d-4b03-9779-fe1b497aae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸ºä»€ä¹ˆ_ç¨‹åº_å‘˜_æ€»æ˜¯_æ··æ·†_åœ£è¯_èŠ‚_å’Œ_ä¸‡_åœ£_èŠ‚_ï¼Ÿ_å› ä¸º_ Oct_ _3_1_ _ç­‰äº_ Dec_ _2_5_ã€‚__"
     ]
    }
   ],
   "source": [
    "for chunk in llm_stream.stream(\"è®²ä¸€ä¸ªå…³äºç¨‹åºå‘˜çš„ä¸€å¥è¯ç¬‘è¯\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7576f-ba07-4af2-bfde-48addef52ffc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>ğŸ…ï¸ æˆåŠŸäº†ï¼</b><br>\n",
    "    ç°åœ¨è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œåº”å½“å¯ä»¥çœ‹åˆ°æµå¼è¾“å‡ºï¼\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa408cba-9e05-462a-a573-5f84ee025d9e",
   "metadata": {},
   "source": [
    "## ChatZhipuAIï¼šåœ¨ langchain_chinese ä¸­å®Œæ•´å®ç°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a8d2e-2c69-4f72-b94a-16976a4bc62d",
   "metadata": {},
   "source": [
    "å®Œæ•´çš„å®ç°è¾ƒä¸ºç¹çï¼Œå¯ä»¥åœ¨å‰é¢å®è·µçš„åŸºç¡€ä¸Šè¡¥å……ï¼š\n",
    "\n",
    "- æ”¯æŒæ‰€æœ‰æ¨¡å‹å‚æ•°\n",
    "- æ”¯æŒå¼‚æ­¥æ–¹æ³•\n",
    "- æ”¯æŒäº‹ä»¶æµæ¨é€\n",
    "- æ”¯æŒæ™ºè°±çš„Toolå›è°ƒ\n",
    "- æ”¯æŒå†…ç½®çš„searchå·¥å…·\n",
    "- æ”¯æŒå†…ç½®çš„æ£€ç´¢å·¥å…·\n",
    "- æ”¯æŒå›¾ç‰‡ç”Ÿæˆèƒ½åŠ›\n",
    "- æ”¯æŒè°ƒç”¨ä¸­çš„å¼‚å¸¸\n",
    "- æä¾›ä¾¿åˆ©çš„bind_toolsæ–¹æ³•\n",
    "- æä¾›åŸºäºToolè°ƒç”¨çš„Agent\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68bfd0fb-c590-4df6-b8fd-81551d54e60d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe currently activated Python version 3.9.18 is not supported by the project (>=3.10,<3.12).\n",
      "Trying to find and use a compatible version.\u001b[39m \n",
      "Using \u001b[36mpython3\u001b[39m (3.10.0)\n",
      "Using version \u001b[39;1m^0.2.13\u001b[39;22m for \u001b[36mlangchain-chinese\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl  13%\u001b[39m \u001b[39;2m(109.3s)\u001b[39;22mmm9m \u001b[39;2m(39.8s)\u001b[39;22mloading https://files.pythonhosted.org/packages/33/47/fc483df0b7ddeee987b6ff146c879d3556fcea82cc9aa4203d16e5871c62/numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl\u001b[39m \u001b[39;2m(2.2s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/33/47/fc483df0b7ddeee987b6ff146c879d3556fcea82cc9aa4203d16e5871c62/numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl   8%\u001b[39m \u001b[39;2m(3.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/33/47/fc483df0b7ddeee987b6ff146c879d3556fcea82cc9aa4203d16e5871c62/numpy-1.26.3-cp310-cp310-macosx_10_9_x86_64.whl  66%\u001b[39m \u001b[39;2m(4.6s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(7.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(9.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(15.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(18.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(22.7s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(23.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(28.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(30.6s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(34.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(35.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(36.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(37.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(38.2s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(40.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(42.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(47.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl\u001b[39m \u001b[39;2m(48.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(49.7s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(53.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(57.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(58.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(61.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(63.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(65.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(71.7s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\u001b[39m \u001b[39;2m(74.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  17%\u001b[39m \u001b[39;2m(76.6s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  28%\u001b[39m \u001b[39;2m(77.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  50%\u001b[39m \u001b[39;2m(80.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  61%\u001b[39m \u001b[39;2m(81.2s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  72%\u001b[39m \u001b[39;2m(82.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/38/00/d0d4e48aef772ad5aebcf70b73028f88db6e5640b36c38e90445b7a57c45/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl  86%\u001b[39m \u001b[39;2m(83.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(86.1s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/1e/07/bf730d44c2fe1b676ad9cc2be5f5f861eb5d153fb6951987a2d6a96379a9/nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl  56%\u001b[39m \u001b[39;2m(87.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/1e/07/bf730d44c2fe1b676ad9cc2be5f5f861eb5d153fb6951987a2d6a96379a9/nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl  99%\u001b[39m \u001b[39;2m(87.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl   5%\u001b[39m \u001b[39;2m(89.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/44/31/4890b1c9abc496303412947fc7dcea3d14861720642b49e8ceed89636705/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl  72%\u001b[39m \u001b[39;2m(91.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(93.0s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  16%\u001b[39m \u001b[39;2m(94.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  61%\u001b[39m \u001b[39;2m(98.5s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  70%\u001b[39m \u001b[39;2m(99.8s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl  94%\u001b[39m \u001b[39;2m(102.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl   3%\u001b[39m \u001b[39;2m(105.3s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl   9%\u001b[39m \u001b[39;2m(107.9s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[36mDownloading https://files.pythonhosted.org/packages/37/6d/121efd7382d5b0284239f4ab1fc1590d86d34ed4a4a2fdb13b30ca8e5740/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl  13%\u001b[39m \u001b[39;2m(109.1s)\u001b[39;22m^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!poetry add langchain_chinese@latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588e60c-2643-4ba1-9f41-881313d59d51",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <b>ChatZhipuAIçš„å®Œæ•´å®ç°å·²ç»å‘å¸ƒ</b><br>\n",
    "    æˆ‘å°†å®Œæ•´çš„å®ç°ä½œä¸º langchain_chinese åŒ…çš„ä¸€éƒ¨ä»½å‘å¸ƒäº†ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fe773-d3d5-4300-9e34-e08a00fe9414",
   "metadata": {},
   "source": [
    "**é¡¹ç›®åœ°å€** [https://pypi.org/project/langchain_chinese/](https://pypi.org/project/langchain_chinese/)<br> \n",
    "**æºä»£ç åœ°å€** [https://github.com/arcstep/langchain_chinese](https://github.com/arcstep/langchain_chinese)\n",
    "\n",
    "ä½ å¯ä»¥é€šè¿‡ pip å®‰è£…ï¼š\n",
    "\n",
    "```\n",
    "pip install -U langchain_chinese\n",
    "```\n",
    "æˆ–\n",
    "\n",
    "```\n",
    "poetry add langchain_chinese@latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298c6312-53a4-477b-8291-607fe84d0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chinese import ChatZhipuAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ac93f3-3594-4a40-8738-9b0c4d7f1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatZhipuAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f497c0-cd86-464b-9b32-0fbd4b576a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªå¼ºåŠ›åŠ©æ‰‹ã€‚\"),\n",
    "    (\"assistant\", \"æˆ‘æ˜¯ä¸€åAIåŠ©æ‰‹ï¼Œè¯·å‘æˆ‘æé—®ã€‚\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa50d0-027a-405a-aecf-0ab025878e79",
   "metadata": {},
   "source": [
    "#### 2024å¹´æ¸…æ˜å‡æ€ä¹ˆå®‰æ’çš„ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499dcba6-6172-4093-8c4c-ac5ca7913808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202|4|å¹´çš„|æ¸…æ˜èŠ‚|æ”¾å‡|å®‰æ’|å¦‚ä¸‹|ï¼š|4|æœˆ|4|æ—¥è‡³|6|æ—¥|æ”¾å‡|è°ƒ|ä¼‘|ï¼Œ|å…±è®¡|3|å¤©|ã€‚|å…·ä½“|æ¥è¯´|ï¼Œ|4|æœˆ|7|æ—¥|ï¼ˆ|æ˜ŸæœŸ|æ—¥|ï¼‰|éœ€è¦|ä¸Šç­|ã€‚|æ¸…æ˜èŠ‚|æ˜¯|ä¸­å›½çš„|ä¼ ç»Ÿ|èŠ‚æ—¥|ï¼Œ|ä¹Ÿæ˜¯|é‡è¦çš„|ç¥­ç¥€|èŠ‚æ—¥|ä¹‹ä¸€|ï¼Œ|ä¸»è¦ç”¨äº|ç¥­|ç¥–|å’Œ|æ‰«|å¢“|ï¼Œ|ä»¥|çºªå¿µ|å·²|æ•…|çš„|äº²äºº|ã€‚|åœ¨è¿™ä¸€|å¤©|ï¼Œ|äººä»¬|é€šå¸¸ä¼š|æºå¸¦|ç¥­|å“|å‰å¾€|å¢“åœ°|ï¼Œ|è¿›è¡Œ|ç¥­|æ‹œ|æ´»åŠ¨|ã€‚|åŒæ—¶|ï¼Œ|æ¸…æ˜èŠ‚|ä¹Ÿè¢«|ç§°ä½œ|è¸|é’|èŠ‚|ï¼Œ|åœ¨|æ˜¥|å…‰æ˜|åªš|çš„å­£èŠ‚|é‡Œ|ï¼Œ|è®¸å¤šäºº|ä¹Ÿä¼š|é€‰æ‹©|å¤–å‡º|è¸|é’|ï¼Œ|äº«å—|æ˜¥å¤©çš„|è‡ªç„¶|æ™¯è‰²|ã€‚||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01)\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024å¹´æ¸…æ˜å‡æ€ä¹ˆå®‰æ’çš„ï¼Ÿ\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b837d7e2-4fdb-4a92-881e-1ed87f30ca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹æ®|å›½åŠ¡é™¢|çš„|å®‰æ’|ï¼Œ|202|4|å¹´|æ¸…æ˜èŠ‚|æ”¾å‡|è°ƒ|ä¼‘|å¦‚ä¸‹|ï¼š|4|æœˆ|4|æ—¥è‡³|6|æ—¥|æ”¾å‡|ï¼Œ|å…±|3|å¤©|ã€‚|4|æœˆ|7|æ—¥|ï¼ˆ|æ˜ŸæœŸ|æ—¥|ï¼‰|ä¸Šç­|ã€‚|è¿™æ„å‘³ç€|æ¸…æ˜èŠ‚|æœŸé—´|ï¼Œ|å¤§å®¶|å¯ä»¥ä»|4|æœˆ|4|æ—¥å¼€å§‹|è¿ç»­|ä¼‘æ¯|ä¸‰å¤©|ï¼Œ|ä½†æ˜¯|éœ€è¦åœ¨|4|æœˆ|7|æ—¥|ï¼ˆ|å‘¨æ—¥|ï¼‰|è¡¥|ç­|ã€‚||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01).bind(\n",
    "    tools=[{\n",
    "        \"type\": \"web_search\", \n",
    "        \"web_search\":{\n",
    "            \"enable\":True,\n",
    "            \"search_query\": \"å›½åŠ¡é™¢2024å¹´æ”¾å‡å®‰æ’\"\n",
    "        }\n",
    "    }])\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024å¹´æ¸…æ˜å‡æ€ä¹ˆå®‰æ’çš„ï¼Ÿ\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b607f0cb-c504-4a99-a194-9eebd3268dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆªè‡³|æˆ‘çš„|çŸ¥è¯†|æ›´æ–°|æ—¥æœŸ|ï¼ˆ|202|3|å¹´|ï¼‰ï¼Œ|æˆ‘|æ— æ³•|æä¾›|202|4|å¹´|æ¸…æ˜|å‡çš„|å…·ä½“|å®‰æ’|ï¼Œ|å› ä¸ºè¿™äº›|ä¿¡æ¯|é€šå¸¸|ä¼šåœ¨|å½“å¹´|å¹´åˆ|ç”±|ç›¸å…³éƒ¨é—¨|å…¬å¸ƒ|ã€‚|æ¸…æ˜èŠ‚|æ˜¯|ä¸­å›½çš„|ä¼ ç»Ÿ|èŠ‚æ—¥|ï¼Œ|ä¹Ÿæ˜¯|å…¬ä¼—|å‡æœŸ|ä¹‹ä¸€|ï¼Œ|é€šå¸¸|ä¼šæœ‰|1|å¤©çš„|æ³•å®š|å‡æœŸ|ï¼Œ|ä½†|å…·ä½“çš„|æ”¾å‡|å®‰æ’|å¯èƒ½ä¼š|ç»“åˆ|å‘¨æœ«|è°ƒ|ä¼‘|å½¢æˆ|å°|é•¿å‡|ã€‚\n",
      "\n",
      "ä¸ºäº†|è·å–|202|4|å¹´|æ¸…æ˜|å‡çš„|å‡†ç¡®|å®‰æ’|ï¼Œ|å»ºè®®|æ‚¨|åœ¨|æ¥è¿‘|é‚£ä¸ª|æ—¶æœŸ|æ—¶|å…³æ³¨|å®˜æ–¹|å‘å¸ƒçš„|èŠ‚å‡æ—¥|å®‰æ’|é€šçŸ¥|ã€‚||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01).bind(\n",
    "    tools=[{\n",
    "        \"type\": \"web_search\", \n",
    "        \"web_search\":{\n",
    "            \"enable\":False\n",
    "        }\n",
    "    }])\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024å¹´æ¸…æ˜å‡æ€ä¹ˆå®‰æ’çš„ï¼Ÿ\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694aff7-06fe-48ef-9694-8e0946f942fc",
   "metadata": {},
   "source": [
    "#### ä»Šå¤©æ˜ŸæœŸå‡ ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f29bf02-120c-47ab-b9fe-55a05f1e51a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŠ±æ­‰|ï¼Œ|ä½œä¸ºä¸€ä¸ª|AI|ï¼Œ|æˆ‘æ²¡æœ‰|å®|æ—¶çš„|æ—¥æœŸ|å’Œæ—¶é—´|ä¿¡æ¯|ã€‚|æˆ‘|å»ºè®®|æ‚¨|æŸ¥çœ‹|æ‚¨çš„|è®¾å¤‡|ä¸Šçš„|æ—¥|å†æ¥|ç¡®å®š|ä»Šå¤©æ˜¯|æ˜ŸæœŸ|å‡ |ã€‚||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01)\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"ä»Šå¤©æ˜ŸæœŸå‡ ï¼Ÿ\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50c8bdc2-46eb-481e-9340-9361d8798b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªå¼ºåŠ›åŠ©æ‰‹ã€‚'), AIMessage(content='æˆ‘æ˜¯ä¸€åAIåŠ©æ‰‹ï¼Œè¯·å‘æˆ‘æé—®ã€‚'), HumanMessage(content='ä½ æ˜¯è°ï¼Ÿ')])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"ä½ æ˜¯è°ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d01fbcce-2432-4559-b803-692057db62b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘æ˜¯ç”± OpenAI å¼€å‘çš„ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæ—¨åœ¨å¸®åŠ©ç”¨æˆ·å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯ã€è§£å†³é—®é¢˜å’Œæ‰§è¡Œå„ç§ä»»åŠ¡ã€‚æˆ‘çš„è®¾è®¡æ˜¯ä¸ºäº†ä¸ç”¨æˆ·è¿›è¡Œè‡ªç„¶å¯¹è¯ï¼Œå¹¶åœ¨å¤šä¸ªé¢†åŸŸæä¾›æ”¯æŒã€‚å¾ˆé«˜å…´è§åˆ°ä½ ï¼ŒChatGLMï¼å¦‚æœæœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"ä½ æ˜¯è°ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b01bd70f-2d54-4caf-81da-4e43dd6b8e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZhipuAIChat(client=<zhipuai._client.ZhipuAI object at 0x1192c81c0>)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = ZhipuAIChat(model=\"ABC\")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b0002b6a-dce9-45c2-8773-500d642a45b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glm-3-turbo'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f91ceb-7768-4afb-85b8-a6e847174ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chain.ainvoke({\"question\": \"ä½ æ˜¯è°ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b480c-f2cb-4914-b6be-2d7461a5f0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
