{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf794d1-56b9-4741-958c-e4c7a29cf680",
   "metadata": {},
   "source": [
    "# 智谱大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a08d8af-804e-4af6-a8c6-3d412a93bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c410b11-7325-4d64-9e95-46191ed599d4",
   "metadata": {},
   "source": [
    "## 智谱API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5a22e-5cee-47fc-aac2-7f6b873b18a0",
   "metadata": {},
   "source": [
    "### 安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84106a2-80c2-40b4-a0dc-ba8416933643",
   "metadata": {},
   "source": [
    "由于智谱官方的 zhipuai 需要 pydantic v2，与 langchain的某些包（如langserve）不兼容，因此在langchain中不建议使用。<br>\n",
    "我从 zhipuai 专门修改了一个 zhipuai_pydantic_v1，用来兼容 pydantic v1，所有API与 zhipuai 完全一致。\n",
    "\n",
    "我们可以使用 zhipuai_pydantic_v1 来做接下来的所有测试。\n",
    "（如果你执意要用 zhipuai，那么在使用 langchain_chinese 之前记得将其卸载）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520afc5d-d756-44a7-9e77-51ef609bd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install zhipuai_pydantic_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad20f5-2780-455e-9544-5986fbd04cfd",
   "metadata": {},
   "source": [
    "### 同步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbfb318c-caea-439a-927c-37dabd8ca2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='glm-4' created=1708402853 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='我是「文成」，很高兴为您服务，小明。有什么我可以帮您的吗？', role='assistant', tool_calls=None))] request_id='8405788625178341182' id='8405788625178341182' usage=CompletionUsage(prompt_tokens=83, completion_tokens=19, total_tokens=102)\n"
     ]
    }
   ],
   "source": [
    "from zhipuai_pydantic_v1 import ZhipuAI\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\", \n",
    "    temperature = 0.95,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是一个强大的助手，你的名字叫「文成」，不要啰嗦\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"我的名字是「文成」，我是一名AI助手，请向我提问。\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"我是小明，你叫什么名字呢？\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca73ad99-a4fe-4a54-ab10-3dd0c99de810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='glm-4' created=1708402885 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='我是文成，一个基于人工智能技术的助手。很高兴遇见你，小明！如果你有任何问题或需要帮助，请随时告诉我。', role='assistant', tool_calls=None))] request_id='8367747962398260138' id='8367747962398260138' usage=CompletionUsage(prompt_tokens=80, completion_tokens=29, total_tokens=109)\n"
     ]
    }
   ],
   "source": [
    "from zhipuai_pydantic_v1 import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\", \n",
    "    temperature = 0.95,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是一个强大的助手，你的名字叫「文成」\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"我的名字是「文成」，我是一名AI助手，请向我提问。\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"我是小明，你叫什么名字呢？\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f15adf-8736-4bab-bbd6-5b42eec53bcc",
   "metadata": {},
   "source": [
    "### 异步调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0f840d-073f-480b-ab6b-225d4a5cf9c3",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>注意:</b><br>\n",
    "    智谱API的异步调用不支持流。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5dcc5-9905-478c-a4b9-5461a9efcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.asyncCompletions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是一个强大的助手，你的名字叫「文成」\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你叫什么名字呢？\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "task_id = response.id\n",
    "prev_status = ''\n",
    "get_cnt = 0\n",
    "\n",
    "while prev_status != 'SUCCESS' and task_status != 'FAILED' and get_cnt <= 40:\n",
    "    result_response = client.chat.asyncCompletions.retrieve_completion_result(id=task_id)\n",
    "    current_status = result_response.task_status\n",
    "    if(current_status == \"PROCESSING\"):\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "    elif(current_status == \"SUCCESS\"):\n",
    "        print()\n",
    "        print(result_response.choices[0].message)\n",
    "    prev_status = current_status\n",
    "\n",
    "    time.sleep(2)\n",
    "    get_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574faba-7a31-4c2e-8772-ba6a5233175d",
   "metadata": {},
   "source": [
    "### 事件流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ba9b4-42a2-41dc-ae04-64a493c390db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\"},\n",
    "        {\"role\": \"user\", \"content\": \"我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in response:\n",
    "    # print(chunk)\n",
    "    print(\"-\" * 80)\n",
    "    print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6522284-f42d-49ad-af52-6361a30b128c",
   "metadata": {},
   "source": [
    "### 函数回调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3be26d-2688-49e2-b946-11d69a87d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=None role='assistant' tool_calls=[CompletionMessageToolCall(id='call_8367745282338832529', function=Function(arguments='{\"date\":\"2024-01-01\",\"departure\":\"北京南站\",\"destination\":\"上海\"}', name='query_train_info'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-3-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你能帮我查询2024年1月1日从北京南站到上海的火车票吗？\"\n",
    "        }\n",
    "    ],\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"query_train_info\",\n",
    "                \"description\": \"根据用户提供的信息，查询对应的车次\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"departure\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"出发城市或车站\",\n",
    "                        },\n",
    "                        \"destination\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"目的地城市或车站\",\n",
    "                        },\n",
    "                        \"date\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"要查询的车次日期\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"departure\", \"destination\", \"date\"],\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97719bd5-f6d3-42ea-8b8e-afe9f832efd0",
   "metadata": {},
   "source": [
    "## 作为 RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5638e8-0239-4d28-a823-b11fc3f018ee",
   "metadata": {},
   "source": [
    "### 基本功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0efd3192-a55e-43f4-87c3-eed109669e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI()\n",
    "\n",
    "def zhipu_chat(messages: [str]):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-3-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b766065-6af9-4cc7-b4d0-2d166a559d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {\"role\": \"user\", \"content\": \"讲一个关于程序员的笑话\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd003c64-d049-4086-bb9b-5b405a659933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146156, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。', role='assistant', tool_calls=None))], request_id='8367745522857040954', id='8367745522857040954', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhipu_chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f0fc0-c56e-4666-9326-2b1665d4206f",
   "metadata": {},
   "source": [
    "### 包装为 Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38630740-a807-4abe-a2bb-fa0453570906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "my_zhipu_chat = RunnableLambda(zhipu_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa9f933b-3d87-44a4-b30f-cce4077af8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-3-turbo', created=1708146224, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。', role='assistant', tool_calls=None))], request_id='8367743907949124838', id='8367743907949124838', usage=CompletionUsage(prompt_tokens=11, completion_tokens=18, total_tokens=29))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_zhipu_chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0eeac3-e13d-4f0b-b596-224ceb4edfe2",
   "metadata": {},
   "source": [
    "## ZhipuAIChatTiny：最小实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae00ed7-e906-4c8c-84de-b49ad16f1205",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d42b0f75-38e2-4ee9-a05e-2b62e6852312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee69cc23-7cf2-4781-b22c-d7f3c6ac051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatTiny(BaseChatModel):\n",
    "    \"\"\"支持最新的智谱API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "    \n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        try:\n",
    "            # 声明 ZhipuAI 的客户端\n",
    "            from zhipuai import ZhipuAI\n",
    "            self.client = ZhipuAI()\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\n",
    "                \"Could not import zhipuai package. \"\n",
    "                \"Please install it via 'pip install zhipuai'\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"使用 ZhiputAI 的同步调用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[ChatGeneration(message=AIMessage(content=content))]\n",
    "        )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb671693-67b2-419c-b45d-6f71748897f1",
   "metadata": {},
   "source": [
    "model='glm-3-turbo' created=1708153877 choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='一个程序员走进一家酒吧，对调酒师说：“我要一杯咖啡，请不要加糖。”\\n\\n调酒师回答：“对不起，这里只卖酒。”\\n\\n程序员微笑着说：“那好吧，那就给我一杯while循环。”\\n\\n调酒师疑惑地问：“while循环是什么酒？”\\n\\n程序员回答：“就是一直给我倒，直到我说停。”', role='assistant', tool_calls=None))] request_id='8367745660295992105' id='8367745660295992105' usage=CompletionUsage(prompt_tokens=11, completion_tokens=83, total_tokens=94)\n",
    "content='一个程序员走进一家酒吧，对调酒师说：“我要一杯咖啡，请不要加糖。”\\n\\n调酒师回答：“对不起，这里只卖酒。”\\n\\n程序员微笑着说：“那好吧，那就给我一杯while循环。”\\n\\n调酒师疑惑地问：“while循环是什么酒？”\\n\\n程序员回答：“就是一直给我倒，直到我说停。”' role='assistant' tool_calls=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4064b74-9b37-49c7-af85-0bb8e4a93714",
   "metadata": {},
   "source": [
    "### 使用 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3849056a-737a-48a4-b277-b96be53b9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tiny = ZhipuAIChatTiny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e769ea77-cf06-4a70-ae9f-d4e850183a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='为什么程序员总是携带电脑？因为他们不想被人叫做\"裸奔者\"。')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tiny.invoke(\"讲一个关于程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dafe8-3367-4e67-be39-2e8bfa2aae86",
   "metadata": {},
   "source": [
    "### 使用 LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b2efbe57-af87-465e-a87a-848e44a2b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm_tiny | StrOutputParser()\n",
    "chain.invoke(\"讲一个关于程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a949f28-944a-4de3-a968-a638d2a692ac",
   "metadata": {},
   "source": [
    "### 使用 Prompt + LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f315c64f-42c5-4309-a5eb-317539426b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好的，下面是一个关于程序员的笑话：\\n\\n为什么程序员不喜欢自然界？\\n\\n因为那里有太多的bugs（虫子/错误）！\\n\\n希望这个笑话能让您开心一下！'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"讲一个关于{topic}的笑话\")\n",
    "chain = prompt | llm_tiny | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"topic\": \"程序员\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8cde2-562d-4693-ae26-e001127e0d8f",
   "metadata": {},
   "source": [
    "### 使用流式输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad73202-4d5e-4589-b966-fd6eee9fa26d",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\", style=\"padding: 5px\">\n",
    "    <b>注意：</b><br>\n",
    "    因为我们没有实现 stream 方法，基类中的实现将自动调用 invoke 方法，然后一次性返回结果。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5ab323c7-1763-41d4-b25c-333429bc622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么程序员总是混淆圣诞节和万圣节？因为 Oct 31 等于 Dec 25。_"
     ]
    }
   ],
   "source": [
    "for chunk in llm_tiny.stream(\"讲一个关于程序员的一句话笑话\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9dbbd-c90e-4d0c-b142-2f51bee0ca60",
   "metadata": {},
   "source": [
    "## ZhipuAIChatStream：支持流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd91e9f-4370-4f1b-be68-baad04563ffb",
   "metadata": {},
   "source": [
    "### 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a49c34a7-90b0-4fd3-8b52-901027cbf309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import (\n",
    "    BaseChatModel,\n",
    "    generate_from_stream,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
    "\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "03e52ee2-19e2-4f39-a436-ddad0548abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIChatStream(BaseChatModel):\n",
    "    \"\"\"支持最新的智谱API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        try:\n",
    "            # 声明 ZhipuAI 的客户端\n",
    "            from zhipuai import ZhipuAI\n",
    "            self.client = ZhipuAI()\n",
    "        except ImportError:\n",
    "            raise RuntimeError(\n",
    "                \"Could not import zhipuai package. \"\n",
    "                \"Please install it via 'pip install zhipuai'\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"使用 ZhiputAI 的同步调用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        choice = response.choices[0]\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[\n",
    "                ChatGeneration(\n",
    "                    message=AIMessage(content=choice.message.content),\n",
    "            )],\n",
    "        )\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        \"\"\"使用 ZhiputAI 的事件流用\"\"\"\n",
    "        prompt: List = []\n",
    "        for message in messages:\n",
    "            if isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            else:  # For both HumanMessage and SystemMessage, role is 'user'\n",
    "                role = \"user\"\n",
    "\n",
    "            prompt.append({\"role\": role, \"content\": message.content})\n",
    "\n",
    "        # 使用流输出\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-3-turbo\",\n",
    "            messages=prompt,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        for chunk in response:\n",
    "            choice = chunk.choices[0]\n",
    "            yield ChatGenerationChunk(\n",
    "                message=AIMessageChunk(content=choice.delta.content),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d0923-a2ae-4dfa-8a28-24c5845d2b73",
   "metadata": {},
   "source": [
    "### 使用 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1f7b2ce7-5d53-47d4-9ea6-eff280f8ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_stream = ZhipuAIChatStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "969c12be-0cd7-4fdd-89bc-0a49f4421bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='为什么程序员总是携带电脑？因为他们不想被人称为“裸奔者”。')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_stream.invoke(\"讲一个程序员的一句话笑话\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcb2e1-e587-4bef-994f-c2338cc674bb",
   "metadata": {},
   "source": [
    "### 使用流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6b667e06-281d-4b03-9779-fe1b497aae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为什么_程序_员_总是_混淆_圣诞_节_和_万_圣_节_？_因为_ Oct_ _3_1_ _等于_ Dec_ _2_5_。__"
     ]
    }
   ],
   "source": [
    "for chunk in llm_stream.stream(\"讲一个关于程序员的一句话笑话\"):\n",
    "    print(chunk.content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7576f-ba07-4af2-bfde-48addef52ffc",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\", style=\"padding: 5px\">\n",
    "    <b>成功了！</b><br>\n",
    "    现在运行上面的代码，应当可以看到流式输出！\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa408cba-9e05-462a-a573-5f84ee025d9e",
   "metadata": {},
   "source": [
    "## ChatZhipuAI：在 langchain_chinese 中完整实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a8d2e-2c69-4f72-b94a-16976a4bc62d",
   "metadata": {},
   "source": [
    "完整的实现较为繁琐，可以在前面实践的基础上补充：\n",
    "\n",
    "- 支持所有模型参数\n",
    "- 支持异步方法\n",
    "- 支持事件流推送\n",
    "- 支持智谱的Tool回调\n",
    "- 支持内置的search工具\n",
    "- 支持内置的检索工具\n",
    "- 支持图片生成能力\n",
    "- 支持调用中的异常\n",
    "- 提供便利的bind_tools方法\n",
    "- 提供基于Tool调用的Agent\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68bfd0fb-c590-4df6-b8fd-81551d54e60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe currently activated Python version 3.9.18 is not supported by the project (>=3.10,<3.12).\n",
      "Trying to find and use a compatible version.\u001b[39m \n",
      "Using \u001b[36mpython3\u001b[39m (3.10.0)\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(4.6s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(0.4s)\u001b[39;22m\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(3.1s)\u001b[39;22m\n",
      "\n",
      "No dependencies to install or update\n"
     ]
    }
   ],
   "source": [
    "!poetry add langchain_chinese@0.2.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588e60c-2643-4ba1-9f41-881313d59d51",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <b>ChatZhipuAI的完整实现已经发布</b><br>\n",
    "    我将完整的实现作为 langchain_chinese 包的一部份发布了。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fe773-d3d5-4300-9e34-e08a00fe9414",
   "metadata": {},
   "source": [
    "**项目地址** [https://pypi.org/project/langchain_chinese/](https://pypi.org/project/langchain_chinese/)<br> \n",
    "**源代码地址** [https://github.com/arcstep/langchain_chinese](https://github.com/arcstep/langchain_chinese)\n",
    "\n",
    "你可以通过 pip 安装：\n",
    "\n",
    "```\n",
    "pip install langchain_chinese==0.2.8\n",
    "```\n",
    "或\n",
    "\n",
    "```\n",
    "poetry add langchain_chinese@0.2.8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "298c6312-53a4-477b-8291-607fe84d0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chinese import ChatZhipuAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12ac93f3-3594-4a40-8738-9b0c4d7f1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatZhipuAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6f497c0-cd86-464b-9b32-0fbd4b576a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个强力助手。\"),\n",
    "    (\"assistant\", \"我是一名AI助手，请向我提问。\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa50d0-027a-405a-aecf-0ab025878e79",
   "metadata": {},
   "source": [
    "#### 2024年清明假怎么安排的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "499dcba6-6172-4093-8c4c-ac5ca7913808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202|4|年的|清明节|放假|安排|如下|：|4|月|4|日至|6|日|放假|调|休|，|共计|3|天|。|具体|来说|，|4|月|7|日|（|星期|日|）|需要|上班|。|清明节|是|中国的|传统|节日|，|也是|重要的|祭祀|节日|之一|，|主要用于|祭|祖|和|扫|墓|，|以|纪念|逝|去的|亲人|。|在这一|期间|，|人们|通常会|进行|扫|墓|、|献|花|、|祭|奠|等活动|，|表达|对|逝|者的|哀|思|和|怀念|。|同时|，|清明|时节|也是|春季|踏|青|的好|时机|，|人们|会|借此|机会|外出|赏|花|、|游玩|，|享受|春天的|自然|美景|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01)\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024年清明假怎么安排的？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b837d7e2-4fdb-4a92-881e-1ed87f30ca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据|国务院|的|安排|，|202|4|年|清明节|放假|调|休|如下|：|4|月|4|日至|6|日|放假|，|共|3|天|。|4|月|7|日|（|星期|日|）|上班|。|这意味着|清明节|期间|，|大家|可以从|4|月|4|日开始|连续|休息|三天|，|但是|需要在|4|月|7|日|（|周日|）|补|班|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01).bind(\n",
    "    tools=[{\n",
    "        \"type\": \"web_search\", \n",
    "        \"web_search\":{\n",
    "            \"enable\":True,\n",
    "            \"search_query\": \"国务院2024年放假安排\"\n",
    "        }\n",
    "    }])\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024年清明假怎么安排的？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b607f0cb-c504-4a99-a194-9eebd3268dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截至|我的|知识|更新|日期|（|202|3|年|），|我|无法|提供|202|4|年|清明|假的|具体|安排|，|因为这些|信息|通常|会在|当年|年初|由|相关部门|公布|。|清明节|是|中国的|传统|节日|，|也是|公众|假期|之一|，|通常|会有|1|天的|法定|假期|，|但|具体的|放假|安排|可能会|结合|周末|调|休|形成|小|长假|。\n",
      "\n",
      "为了|获取|202|4|年|清明|假的|准确|安排|，|建议|您|在|接近|那个|时期|时|关注|官方|发布的|节假日|安排|通知|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01).bind(\n",
    "    tools=[{\n",
    "        \"type\": \"web_search\", \n",
    "        \"web_search\":{\n",
    "            \"enable\":False\n",
    "        }\n",
    "    }])\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"2024年清明假怎么安排的？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694aff7-06fe-48ef-9694-8e0946f942fc",
   "metadata": {},
   "source": [
    "#### 今天星期几？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8f29bf02-120c-47ab-b9fe-55a05f1e51a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抱歉|，|作为一个|AI|，|我没有|实|时的|日期|和时间|信息|。|我|建议|您|查看|您的|设备|上的|日|历来|确定|今天是|星期|几|。||"
     ]
    }
   ],
   "source": [
    "llm = ChatZhipuAI(model=\"glm-4\", temperature=0.01)\n",
    "chain = (prompt | llm | StrOutputParser())\n",
    "for s in chain.stream({\"question\": \"今天星期几？\"}):\n",
    "    print(s, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50c8bdc2-46eb-481e-9340-9361d8798b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='你是一个强力助手。'), AIMessage(content='我是一名AI助手，请向我提问。'), HumanMessage(content='你是谁？')])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\": \"你是谁？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d01fbcce-2432-4559-b803-692057db62b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我是由 OpenAI 开发的一个人工智能助手，旨在帮助用户回答问题、提供信息、解决问题和执行各种任务。我的设计是为了与用户进行自然对话，并在多个领域提供支持。很高兴见到你，ChatGLM！如果有任何问题或需要帮助，请随时告诉我。'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"你是谁？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b01bd70f-2d54-4caf-81da-4e43dd6b8e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZhipuAIChat(client=<zhipuai._client.ZhipuAI object at 0x1192c81c0>)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = ZhipuAIChat(model=\"ABC\")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b0002b6a-dce9-45c2-8773-500d642a45b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glm-3-turbo'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f91ceb-7768-4afb-85b8-a6e847174ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
