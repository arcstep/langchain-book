{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a29171-6408-41e4-9b44-d6c05a4bd8fc",
   "metadata": {},
   "source": [
    "使用 **FakeListLLM** 可以模拟大模型的响应，这可以用于实现模拟演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d65ff7-e847-485f-b4d4-1967268a70a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578f800-cdf7-4faa-83c1-14903256f08c",
   "metadata": {},
   "source": [
    "# Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8b07266-a6bc-40c4-a706-5cd296a8106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.fake import FakeStreamingListLLM\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "# 定义一个函数来生成一个随机字符串\n",
    "def generate_random_string(length):\n",
    "    return ''.join(random.choices(string.ascii_letters, k=length))\n",
    "\n",
    "random_strings = [generate_random_string(10) for _ in range(100)]\n",
    "\n",
    "llm = FakeStreamingListLLM(responses=random_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37128450-ee6d-422e-bb45-3d3fa1ab5261",
   "metadata": {},
   "source": [
    "FakeListLLM 支持一般 LLM 的所有方法，可以从声明中的字符串中随机选择一个模拟响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272df90-844f-4d0a-8bbf-239adf6d760d",
   "metadata": {},
   "source": [
    "## invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62119691-b3b3-4cb5-b84e-1faed87bec6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uxKLUhRkbB'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9158d01c-3d8e-4958-92fc-6356d2d169e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KDuNwwkVMq'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(input=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeef27a-c9f9-4fb5-8815-9cb3796b2254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接调用 Dict 就会报错，因为 Dict 一般是为 Prompt 模板准备的\n",
    "llm.invoke(input={\"input\":\"hi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0248a0f-990e-4409-a80b-18bd1b43aae9",
   "metadata": {},
   "source": [
    "## stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94e583a3-1d27-4ca3-aedc-64a807eb0aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "M\n",
      "G\n",
      "u\n",
      "d\n",
      "q\n",
      "g\n",
      "P\n",
      "l\n",
      "U\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"hi\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43f4c5-d200-4f35-8a1c-592845af5aa7",
   "metadata": {},
   "source": [
    "# 模拟智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46df04-9427-49ec-a7d0-d3f951917dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1112b6bd-67e2-4d34-a9ae-b30fa07f47d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(2 + 2)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats 2 + 2', 'output': '4'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "tools = [PythonREPLTool()]\n",
    "responses = [\n",
    "    \"Action: Python_REPL\\nAction Input: print(2 + 2)\",\n",
    "    \"Final Answer: 4\"]\n",
    "llm = FakeListLLM(responses=responses)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.invoke(\"whats 2 + 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
