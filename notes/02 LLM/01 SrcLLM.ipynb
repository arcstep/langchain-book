{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eddaf4d-76df-45cf-9026-eefd5ddbf6b0",
   "metadata": {},
   "source": [
    "# 大模型相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1aff57-bfb5-478d-b41b-ce48a3cb2db2",
   "metadata": {},
   "source": [
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseLanguageModel（大模型）\n",
    "            - BaseChatModel `[LanguageModelInput, LanguageModelOutputVar]`\n",
    "                - SimpleChatModel\n",
    "                - ChatOpenAI\n",
    "                    - AzureChatOpenAI\n",
    "            - BaseLLM\n",
    "                - BaseOpenAI\n",
    "                    - OpenAI\n",
    "                    - AzureOpenAI\n",
    "                - HuggingFacePipeline\n",
    "                - LLM\n",
    "                    - FakeListLLM\n",
    "                        - FakeStreamingListLLM\n",
    "                    - HumanInputLLM\n",
    "                    - HuggingFaceHub\n",
    "                    - HuggingFaceEndpoint\n",
    "                    - HuggingFaceTextGenInference\n",
    "                    - QianfanLLMEndpoint\n",
    "                    - BaichuanLLM\n",
    "                - Tongyi\n",
    "                - Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d00b8b-5619-4e4e-94da-b0f6208091c9",
   "metadata": {},
   "source": [
    "# 定制大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d83e01-62f0-46c1-8364-30fdce3f18f1",
   "metadata": {},
   "source": [
    "# 提示语和消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe6f55-903a-4ce4-a613-cfb7304f58a1",
   "metadata": {},
   "source": [
    "# 提示语和消息相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea5af83-e808-4e67-a046-200d2937d8cb",
   "metadata": {},
   "source": [
    "- PromptValue\n",
    "    - StringPromptValue\n",
    "    - ChatPromptValue\n",
    "        - ChatPromptValueConcrete\n",
    "    - ImagePromptValue\n",
    "\n",
    "- BaseMessage\n",
    "    - BaseMessageChunk\n",
    "    - AIMessage\n",
    "        - AIMessageChunk(AIMessage, BaseMessageChunk)\n",
    "    - ChatMessage\n",
    "        - ChatMessageChunk(ChatMessage, BaseMessageChunk)\n",
    "    - FunctionMessage\n",
    "        - FunctionMessageChunk(FunctionMessage, BaseMessageChunk)\n",
    "    - HumanMessage\n",
    "        - HumanMessageChunk(HumanMessage, BaseMessageChunk)\n",
    "    - SystemMessage\n",
    "        - SystemMessageChunk(SystemMessage, BaseMessageChunk)\n",
    "    - ToolMessage\n",
    "        - ToolMessageChunk(ToolMessage, BaseMessageChunk)\n",
    "\n",
    "- BaseExampleSelector\n",
    "    - LengthBasedExampleSelector\n",
    "    - SemanticSimilarityExampleSelector\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BasePromptTemplate `[Dict, PromptValue]`\n",
    "            - StringPromptTemplate\n",
    "                - PromptTemplate\n",
    "                - FewShotPromptWithTemplates\n",
    "                - FewShotPromptTemplate\n",
    "            - BaseChatPromptTemplate\n",
    "                - AutoGPTPrompt\n",
    "                - ChatPromptTemplate\n",
    "                    - AgentScratchPadChatPromptTemplate\n",
    "            - ImagePromptTemplate\n",
    "            - PipelinePromptTemplate\n",
    "        - BaseMessagePromptTemplate\n",
    "            - _StringImageMessagePromptTemplate\n",
    "                - ChatMessagePromptTemplate\n",
    "                - AIMessagePromptTemplate\n",
    "                - HumanMessagePromptTemplate\n",
    "                - SystemMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e413360-b61f-45c2-b1b6-b8f5bc84f91f",
   "metadata": {},
   "source": [
    "# 提示语模板库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d37d40-d374-4b31-a357-02d88ea8928e",
   "metadata": {},
   "source": [
    "## 从文件加载提示语"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6da432-781b-4a7f-bbe0-f27ac7d7a3dd",
   "metadata": {},
   "source": [
    "## 相关类结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013383b-62e0-4a98-88e5-d652c5fbfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "- BaseMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0038f22-6346-4b40-b498-96deff28ee85",
   "metadata": {},
   "source": [
    "# 检索器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b80ed-709e-45b3-95d5-d05442d28db6",
   "metadata": {},
   "source": [
    "## 相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c64cad-86fa-45ed-bdff-a46115d36eb0",
   "metadata": {},
   "source": [
    "- Embeddings\n",
    "    - embed_documents / aembed_documents\n",
    "    - embed_query / aembed_query\n",
    "        - OpenAIEmbeddings\n",
    "            - AzureOpenAIEmbeddings\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseRetriever `[RetrieverInput, RetrieverOutput]`\n",
    "            - VectorStoreRetriever\n",
    "            - AzureCognitiveSearchRetriever\n",
    "            - AmazonKnowledgeBasesRetriever\n",
    "            - ChatGPTPluginRetriever\n",
    "            - ElasticSearchBM25Retriever\n",
    "            - KNNRetriever\n",
    "            - LlamaIndexRetriever\n",
    "            - MetalRetriever\n",
    "            - MilvusRetriever\n",
    "            - OutlineRetriever\n",
    "            - PineconeHybridSearchRetriever\n",
    "            - QdrantSparseVectorRetriever\n",
    "            - RemoteLangChainRetriever\n",
    "            - SVMRetriever\n",
    "            - TavilySearchAPIRetriever\n",
    "            - TFIDFRetriever\n",
    "            - WeaviateHybridSearchRetriever\n",
    "            - WikipediaRetriever\n",
    "\n",
    "- BaseStore\n",
    "- VectorStore\n",
    "    - VectorStoreRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d896047-2dc6-4fce-befd-ae1d02da3fd4",
   "metadata": {},
   "source": [
    "# 输出解析和文档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffca1fa-311e-4799-a251-8df6a439013b",
   "metadata": {},
   "source": [
    "## 相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1481f-91da-4b85-9feb-47f7e21f7c69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- Document\n",
    "- BaseDocumentTransformer\n",
    "\n",
    "- Generation\n",
    "    - ChatGeneration\n",
    "        - ChatGenerationChunk\n",
    "- ChatResult\n",
    "- LLMResult\n",
    "- RunInfo\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseGenerationOutputParser `[Union[str, BaseMessage], T]`\n",
    "            - OutputFunctionsParser\n",
    "                - PydanticOutputFunctionsParser\n",
    "                    - PydanticAttrOutputFunctionsParser\n",
    "            - JsonOutputToolsParser\n",
    "                - JsonOutputKeyToolsParser\n",
    "                - PydanticToolsParser\n",
    "        - BaseOutputParser\n",
    "            - BaseTransformOutputParser\n",
    "                - BaseCumulativeTransformOutputParser\n",
    "                    - JsonOutputParser（别名SimpleJsonOutputParser）\n",
    "                    - JsonOutputFunctionsParser\n",
    "                        - JsonKeyOutputFunctionsParser\n",
    "                - StrOutputParser\n",
    "                - XMLOutputParser\n",
    "                - ListOutputParser\n",
    "                    - CommaSeparatedListOutputParser\n",
    "                    - NumberedListOutputParser\n",
    "                    - MarkdownListOutputParser\n",
    "            - BooleanOutputParser\n",
    "            - CombiningOutputParser\n",
    "            - DatetimeOutputParser\n",
    "            - EnumOutputParser\n",
    "            - OutputFixingParser（使用LLM修复错误）\n",
    "            - PandasDataFrameOutputParser\n",
    "            - PydanticOutputParser\n",
    "            - RegexDictParser\n",
    "            - RegexParser\n",
    "            - RetryOutputParser\n",
    "            - RetryWithErrorOutputParser\n",
    "            - StructuredOutputParser\n",
    "            - YamlOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33ff3c-ed56-4bc9-a706-cc1601078e3c",
   "metadata": {},
   "source": [
    "## 定制一个输出解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45082940-ef6b-4c53-8ab3-f41a6ec1f9ce",
   "metadata": {},
   "source": [
    "# 回调和跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055519c-a3cc-4669-985d-20e5a347eddd",
   "metadata": {},
   "source": [
    "## 相关类结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10668d40-471c-4b01-8bdc-2f7fc060df7f",
   "metadata": {},
   "source": [
    "- CallbackManagerMixin\n",
    "    - BaseCallbackManager\n",
    "        - CallbackManager\n",
    "            - CallbackManagerForChainGroup\n",
    "        - AsyncCallbackManager\n",
    "            - AsyncCallbackManagerForChainGroup\n",
    "- RunManagerMixin\n",
    "    - BaseRunManager\n",
    "        - RunManager\n",
    "            - ParentRunManager\n",
    "                - CallbackManagerForChainRun(ParentRunManager, ChainManagerMixin)\n",
    "                - CallbackManagerForToolRun(ParentRunManager, ToolManagerMixin)\n",
    "                - CallbackManagerForRetrieverRun(ParentRunManager, RetrieverManagerMixin)\n",
    "            - CallbackManagerForLLMRun(RunManager, LLMManagerMixin)\n",
    "    - AsyncRunManager\n",
    "        - AsyncParentRunManager\n",
    "            - AsyncCallbackManagerForChainRun(AsyncParentRunManager, ChainManagerMixin)\n",
    "            - AsyncCallbackManagerForToolRun(AsyncParentRunManager, ToolManagerMixin)\n",
    "            - AsyncCallbackManagerForRetrieverRun(AsyncParentRunManager, RetrieverManagerMixin)\n",
    "        - AsyncCallbackManagerForLLMRun(AsyncRunManager, LLMManagerMixin)\n",
    "- BaseCallbackHandler(\n",
    "        LLMManagerMixin,\n",
    "        ChainManagerMixin,\n",
    "        ToolManagerMixin,\n",
    "        RetrieverManagerMixin,\n",
    "        CallbackManagerMixin,\n",
    "        RunManagerMixin,\n",
    "    )\n",
    "    - AsyncCallbackHandler\n",
    "    - StdOutCallbackHandler\n",
    "    - StreamingStdOutCallbackHandler\n",
    "    - BaseTracer\n",
    "        - EvaluatorCallbackHandler\n",
    "        - LangChainTracerV1\n",
    "        - LangChainTracer\n",
    "        - LogStreamCallbackHandler\n",
    "        - RootListenersTracer\n",
    "        - RunCollectorCallbackHandler\n",
    "        - FunctionCallbackHandler\n",
    "            - ConsoleCallbackHandler\n",
    "- RunLogPatch\n",
    "    - RunLog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae4ed92-94c7-406c-b688-c2c85cb58988",
   "metadata": {},
   "source": [
    "- TracerSessionV1Base\n",
    "    - TracerSessionV1Create\n",
    "    - TracerSessionV1\n",
    "    - TracerSessionBase\n",
    "        - TracerSession\n",
    "- ExampleBase\n",
    "    - ExampleCreate\n",
    "    - Example\n",
    "- ExampleUpdate\n",
    "- DataType\n",
    "- DatasetBase\n",
    "    - DatasetCreate\n",
    "    - Dataset\n",
    "- RunTypeEnum\n",
    "- BaseRun\n",
    "    - LLMRun\n",
    "    - ChainRun \n",
    "    - ToolRun\n",
    "    - Run\n",
    "- RunLikeDict\n",
    "- RunBase\n",
    "    - RunWithAnnotationQueueInfo\n",
    "- FeedbackSourceBase\n",
    "    - APIFeedbackSource\n",
    "    - ModelFeedbackSource\n",
    "- FeedbackSourceType\n",
    "- FeedbackBase\n",
    "    - FeedbackCreate\n",
    "    - Feedback\n",
    "- TracerSession\n",
    "    - TracerSessionResult\n",
    "- BaseMessageLike\n",
    "- DatasetShareSchema\n",
    "- AnnotationQueue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ff98c-e48b-4c54-a08e-e83579e27e04",
   "metadata": {},
   "source": [
    "## 自定义一个callback函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "459e8398-803f-4043-802a-3aaad2ef9ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My custom handler, token: \n",
      "My custom handler, token: Why\n",
      "My custom handler, token:  don\n",
      "My custom handler, token: 't\n",
      "My custom handler, token:  scientists\n",
      "My custom handler, token:  trust\n",
      "My custom handler, token:  atoms\n",
      "My custom handler, token: ?\n",
      "My custom handler, token:  \n",
      "\n",
      "\n",
      "My custom handler, token: Because\n",
      "My custom handler, token:  they\n",
      "My custom handler, token:  make\n",
      "My custom handler, token:  up\n",
      "My custom handler, token:  everything\n",
      "My custom handler, token: !\n",
      "My custom handler, token: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't scientists trust atoms? \\n\\nBecause they make up everything!\")"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import time\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        time.sleep(1)\n",
    "        print(f\"My custom handler, token: {token}\")\n",
    "\n",
    "# To enable streaming, we pass in `streaming=True` to the ChatModel constructor\n",
    "# Additionally, we pass in a list with our custom handler\n",
    "chat = ChatOpenAI(max_tokens=25, streaming=True, callbacks=[MyCustomHandler()])\n",
    "\n",
    "chat.invoke([HumanMessage(content=\"Tell me a joke\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c965b56-ec03-449d-bcb6-6def8c6b2170",
   "metadata": {},
   "source": [
    "## 自定义个一个异步回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "3d4a4475-2a65-4812-ad1f-295bc5db9c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My custom handler, token: \n",
      "My custom handler, token: Sure\n",
      "My custom handler, token: ,\n",
      "My custom handler, token:  here\n",
      "My custom handler, token: 's\n",
      "My custom handler, token:  a\n",
      "My custom handler, token:  joke\n",
      "My custom handler, token:  for\n",
      "My custom handler, token:  you\n",
      "My custom handler, token: :\n",
      "\n",
      "\n",
      "My custom handler, token: Why\n",
      "My custom handler, token:  don\n",
      "My custom handler, token: 't\n",
      "My custom handler, token:  scientists\n",
      "My custom handler, token:  trust\n",
      "My custom handler, token:  atoms\n",
      "My custom handler, token: ?\n",
      "\n",
      "\n",
      "My custom handler, token: Because\n",
      "My custom handler, token:  they\n",
      "My custom handler, token:  make\n",
      "My custom handler, token:  up\n",
      "My custom handler, token:  everything\n",
      "My custom handler, token: !\n",
      "My custom handler, token: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\")"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import asyncio\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    async def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        await asyncio.sleep(1)\n",
    "        print(f\"My custom handler, token: {token}\")\n",
    "\n",
    "# To enable streaming, we pass in `streaming=True` to the ChatModel constructor\n",
    "# Additionally, we pass in a list with our custom handler\n",
    "chat = ChatOpenAI(max_tokens=25, streaming=True, callbacks=[MyCustomHandler()])\n",
    "\n",
    "await chat.ainvoke([HumanMessage(content=\"Tell me a joke\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94085d20-c012-425a-80ef-9e3d477dcaaa",
   "metadata": {},
   "source": [
    "# 记忆"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a7dcc-6940-41f4-93e7-2e77c32ffac0",
   "metadata": {},
   "source": [
    "## 记忆体相关结构"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
