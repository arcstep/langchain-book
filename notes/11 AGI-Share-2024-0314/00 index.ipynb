{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5b5362-cf90-4d8a-9c70-3db56e3f8dcc",
   "metadata": {},
   "source": [
    "# ğŸ¦œğŸ”— LangChainæ ¸å¿ƒæºä»£ç è§£è¯»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09652ad-45cf-4152-8794-2639a92a4ac2",
   "metadata": {},
   "source": [
    "# è¯¾ç¨‹å¼€å§‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac26c1-1878-43d9-984d-bebacabccefb",
   "metadata": {},
   "source": [
    "## â¤ï¸ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb7b7a-d4a8-4e8d-b757-a55062c3fad8",
   "metadata": {},
   "source": [
    "1. ğŸŒ¹ä¸€èµ·é˜…è¯» Langchain æ ¸å¿ƒç»„ä»¶çš„æºç ï¼šRunnableã€LLMã€Agentã€Langgraph\n",
    "2. ğŸŒ¹ä»è§£è¯»æºç çš„è§’åº¦äº†è§£ Langchain æ•´ä½“è®¾è®¡æ€è·¯ï¼Œä»¥ä¾¿æ›´å¥½åœ°é˜…è¯»å®˜æ–¹æ–‡æ¡£\n",
    "3. ğŸŒ¹æŒæ¡ Langchain æ–‡æ¡£ä¸­æœªæ›¾æåŠã€ç¿»çœ‹æºç æ‰çŸ¥æ™“çš„å®ç”¨æŠ€å·§\n",
    "4. âœï¸ åŠ¨æ‰‹å®ç°ä¸€ä¸ªè‡ªå®šä¹‰å¤§æ¨¡å‹æ¡†æ¶ï¼šä¼šè¯´è¯çš„é‚»å±…è€å¤§çˆ·\n",
    "5. âœï¸ åŠ¨æ‰‹é›†æˆè‡ªå·±çš„å¤§æ¨¡å‹åˆ° LangChainï¼šæ™ºè°±AI\n",
    "6. âœï¸ åŠ¨æ‰‹å®ç°åŸºäº LCEL çš„æ™ºèƒ½ä½“ï¼šå†ç°æ‰‹æ’•AutoGPT\n",
    "7. âœï¸ åŠ¨æ‰‹å®ç°åŸºäº Langgraph çš„æ™ºèƒ½ä½“ï¼šå†ç°æ‰‹æ’•AutoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d3fb7-9b0a-4592-ac64-ea74630e75be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>æ³¨æ„ï¼š</b><br>\n",
    "<ul>\n",
    "    <li>å¤§æ¨¡å‹è®¤çŸ¥ï¼šè¯·å‚è€ƒAGIè¯¾å ‚æ­£è¯¾ç›¸å…³ç« èŠ‚</li>\n",
    "    <li>Langchain åŸºç¡€ï¼šè¯·å‚è€ƒAGIè¯¾å ‚æ­£è¯¾ç›¸å…³ç« èŠ‚</li>\n",
    "    <li>çœ‹æ‡‚æºç æ˜¯ä¸ºäº†å†™å¥½ä»£ç </li>\n",
    "</ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff511b-10e1-43d4-92e0-829a1fe4d5d2",
   "metadata": {},
   "source": [
    "## å¦‚ä½•è§£è¯» Langchain çš„æºä»£ç ç»“æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac50aa-ed71-46ea-ac3c-e1af5abe5fc9",
   "metadata": {},
   "source": [
    "### 1ã€ä½ æœ‰å“ªäº›èµ„æºå¯ä»¥åˆ©ç”¨ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f539f3d-148f-4c18-a959-881dfc8ce4b7",
   "metadata": {},
   "source": [
    "![](./langchain_ai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbce31b-2fd4-43cd-8204-98fa50ae8bf5",
   "metadata": {},
   "source": [
    "ï¼ˆ1ï¼‰å­¦ä¹ èµ„æºï¼š\n",
    "- [langchainæºä»£ç ](https://github.com/langchain-ai/)ï¼šAll you need r here !!!\n",
    "- [langchainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs)ï¼šä¸æºä»£ç ç›¸äº’å°è¯\n",
    "- [langgraph example](https://github.com/langchain-ai/langgraph/tree/main/examples)ï¼šJupyter Notes\n",
    "\n",
    "ï¼ˆ2ï¼‰è‰¯å¸ˆç›Šå‹ï¼š\n",
    "- langchain [èŠå¤©](https://chat.langchain.com/?llm=anthropic_claude_2_1)ï¼šå…è´¹çš„å¤§æ¨¡å‹+RAGï¼ˆä¹Ÿå¯ä»¥å­¦ä¹ å…¶æºç ï¼‰\n",
    "- Github Copilotï¼šç¨‹åºå‘˜æ— æ³•ç¦»å¼€çš„å·¥å…·ï¼Œå°±åƒç°åœ¨çš„äººå¼€è½¦æ— æ³•ç¦»å¼€åœ°å›¾å¯¼èˆª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7f60d-7043-42e0-98c2-459355c52f19",
   "metadata": {},
   "source": [
    "### 2ã€ğŸŒ¹ é˜…è¯»æºç ï¼šLangChain æºä»£ç æ¦‚è§ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4481a6-d92d-4df6-8cfd-65e57c2463f5",
   "metadata": {},
   "source": [
    "[langchainæºä»£ç ç»“æ„](https://github.com/langchain-ai/langchain/tree/master/libs)\n",
    "\n",
    "| æºç ä½ç½® | åŠŸèƒ½æè¿° |\n",
    "| :--- | :--- |\n",
    "| langchain/libs/langchain | æ¨¡å—å…¥å£ï¼Œä¼šå¯¼å…¥coreã€communityç­‰å…¶ä»–æ¨¡å— |\n",
    "| langchain/libs/core | æ ¸å¿ƒç»„ä»¶å’Œå…³é”®çš„åŸºç±»å®ç° |\n",
    "| langchain/libs/partners | åˆä½œä¼™ä¼´ï¼ˆå®˜æ–¹åˆä½œï¼‰ç»„ä»¶ |\n",
    "| langchain/libs/community | ç¤¾åŒºï¼ˆéå®˜æ–¹ï¼‰ç»„ä»¶ |\n",
    "| langchain/libs/experimental | è¯•éªŒæ€§åŠŸèƒ½ï¼ˆå‰æ²¿æ¢ç´¢ç»„ä»¶ï¼Œä¸å¯¹ç‰ˆæœ¬ç¨³å®šåšæ‰¿è¯ºï¼‰ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01548080-b79b-4a88-9b9f-7af2ef9ae567",
   "metadata": {},
   "source": [
    "### 3ã€LangChainæ ¸å¿ƒæ¡†æ¶çš„ä¸‰è½®è¿­ä»£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc361bf-be03-4dbe-bf58-03f11e20fef8",
   "metadata": {},
   "source": [
    "- Runnable + Chain æ—¶ä»£\n",
    "- Runnable + LCEL æ—¶ä»£\n",
    "- Runnable + LCEL + Langgraph æ—¶ä»£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936103d-a47c-4455-81ca-10a8cbb8449a",
   "metadata": {},
   "source": [
    "# ï¼ˆä¸€ï¼‰ä»é›¶å¼€å§‹é›†æˆå¤§æ¨¡å‹åˆ° Langchain å®ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4086972-8af4-41e8-9f1d-7d3a5e984bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a33f05-0ea9-427c-b851-6511e0b9fc29",
   "metadata": {},
   "source": [
    "## å¤§æ¨¡å‹çš„ä¸€èˆ¬ç”¨æ³•å›é¡¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56f9e2e4-782e-466b-be9d-c23b0c30242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c4db118-7b74-4d8e-8d9c-e8976ff4294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. æ™ºèƒ½å­—é“…\n",
      "2. AIæ–‡ç¬”\n",
      "3. è‡ªåŠ¨ä¹¦å†™\n",
      "4. æ¶‚å­—æ™ºèƒ½\n",
      "5. å­—è¿¹ç¥ç¬”\n",
      "6. AIå­—ç”»\n",
      "7. è‡ªåŠ¨ä¹¦æ³•\n",
      "8. æ™ºèƒ½å†™å­—\n",
      "9. è‡ªåŠ¨ç¬”è¿¹\n",
      "10. AIå­—è¿¹é€š\n"
     ]
    }
   ],
   "source": [
    "# invoke\n",
    "text = \"è¯·å¸®æˆ‘æƒ³ä¸€æƒ³ï¼Œç”Ÿäº§ä¸€æ¬¾ã€ŒåŸºäºAIè‡ªåŠ¨å†™å­—çš„é“…ç¬”ã€çš„å…¬å¸æœ‰ä»€ä¹ˆå¥½åå­—?\"\n",
    "response = llm.invoke(text)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ad948cb-8584-43f4-9dce-b008fa6cbc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| æ™º|èƒ½|ç¬”|è¿¹|\n",
      "|2|.| åˆ›|æ„|ç¬”|é”‹|\n",
      "|3|.| AI|å†™|å­—|å®|\n",
      "|4|.| æ¶‚|é¸¦|åŠ©|æ‰‹|\n",
      "|5|.| æ–‡|å­—|å°|å¸®|æ‰‹|\n",
      "|6|.| å¿ƒ|çµ|ç¬”|è€•|\n",
      "|7|.| æ™º|èƒ½|ä¹¦|å†™|\n",
      "|8|.| åˆ›|é€ |ç¬”|è¿¹|\n",
      "|9|.| æ™º|èƒ½|é“…|ç¬”|åŠ|\n",
      "|10|.| æ–‡|å­—|é­”|æ³•|ä½¿||"
     ]
    }
   ],
   "source": [
    "# stream\n",
    "for chunk in llm.stream(text):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32dea0d5-8c5c-436d-b006-67b07eceae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| æ™º|èƒ½|ç¬”|è®°|\n",
      "|2|.| AI|ç¬”|è¿¹|\n",
      "|3|.| å¿ƒ|çµ|ç¬”|\n",
      "|4|.| æ™º|æ…§|é“…|ç¬”|\n",
      "|5|.| åˆ›|æ„|ç¬”|è¿¹|\n",
      "|6|.| è‡ª|åŠ¨|ç¬”|ç”»|\n",
      "|7|.| æ™º|èƒ½|å†™|å­—|\n",
      "|8|.| AI|æ‰‹|å†™|ç¬”|\n",
      "|9|.| æ™º|èƒ½|æ–‡å­—|\n",
      "|10|.| åˆ›|æ„|ç¬”|é”‹||"
     ]
    }
   ],
   "source": [
    "# LCEL LLM+Prompt+Outputparser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"è¯·å¸®æˆ‘æƒ³ä¸€æƒ³ï¼Œç”Ÿäº§ä¸€æ¬¾{product}çš„å…¬å¸æœ‰ä»€ä¹ˆå¥½åå­—?\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "for chunk in chain.stream({\"product\": \"åŸºäºAIè‡ªåŠ¨å†™å­—çš„é“…ç¬”\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d63eec-9f22-4f5b-94bf-40f721313ad1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒ</b><br>\n",
    "    langchain æ”¯æŒçš„8ä¸ªæ–¹æ³•éƒ½åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹ä½¿ç”¨ï¼Ÿ\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73527d37-fdb8-4d76-b70c-4ce1c209a3ed",
   "metadata": {},
   "source": [
    "## â¤ï¸ å®ä¾‹1 å®ç°ã€Œæ¥¼ä¸‹é‚»å±…è€å¤§çˆ·ã€AIå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3028e-da74-4247-af83-d76f03544797",
   "metadata": {},
   "source": [
    "### ğŸ¦œ éœ€æ±‚åˆ†æï¼šå‚è€ƒç”µå½±ç‰‡æ®µï¼ŒæŠŠã€Œéå¸¸æœ‰æ™ºæ…§çš„æ¥¼ä¸‹é‚»å±…è€å¤§çˆ·ã€å˜æˆ AIå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6fe6d-6fdd-49ea-88ce-496eddd23e5b",
   "metadata": {},
   "source": [
    "1. ä½¿ç”¨å¤§æ¨¡å‹ï¼šæ¨¡æ‹Ÿä¸€ä¸ªå¤§æ¨¡å‹\n",
    "2. ç”Ÿæˆèƒ½åŠ›ï¼šæåŠé©¬å†¬æ¢…æ—¶ç”Ÿæˆæ‰“å²”é—²èŠï¼ˆé©¬ä»€ä¹ˆæ¢…ï¼Ÿé©¬å†¬ä»€ä¹ˆï¼Ÿä»€ä¹ˆå†¬æ¢…ï¼Ÿï¼‰ï¼Œå…¶ä½™ç”Ÿæˆâ€œå“¦...â€œ\n",
    "\n",
    "![é©¬å†¬æ¢…](./madongmei.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d58bd3-44a0-4d8e-a884-76a17f501b00",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ çœ‹æºç ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77551be1-5a9f-4a81-91c1-b81750203f0e",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰BaseLanguageModel\n",
    "\n",
    "æ¥è‡ªï¼š[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/base.py#L74-L81)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd55cf-68b2-4586-8119-672d55e66026",
   "metadata": {},
   "source": [
    "```python\n",
    "class BaseLanguageModel(\n",
    "    RunnableSerializable[LanguageModelInput, LanguageModelOutputVar], ABC\n",
    "):\n",
    "    \"\"\"Abstract base class for interfacing with language models.\n",
    "\n",
    "    All language model wrappers inherit from BaseLanguageModel.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943d2a1-b8a2-4525-af16-0905b0f581a3",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰BaseChatModel\n",
    "\n",
    "æ¥è‡ªï¼š[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/chat_models.py#L100)\n",
    "\n",
    "**æ ¸å¿ƒé€»è¾‘ï¼š**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8accb174-c5e8-493f-8f20-530be6f854b0",
   "metadata": {},
   "source": [
    "```python\n",
    "class BaseChatModel(BaseLanguageModel[BaseMessage], ABC):\n",
    "    \"\"\"Base class for Chat models.\"\"\"\n",
    "\n",
    "    ...\n",
    "\n",
    "    def invoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.generate_prompt(...)\n",
    "        # generate_prompt >> generate >> _generate\n",
    "\n",
    "    def ainvoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.agenerate_prompt(...)\n",
    "        # agenerate_prompt >> agenerate >> _agenerate >> _generate\n",
    "    \n",
    "    def stream(...) -> Iterator[BaseMessageChunk]:\n",
    "        # ...\n",
    "        if type(self)._stream == BaseChatModel._stream:\n",
    "            # model doesn't implement streaming, so use default implementation\n",
    "            yield cast(\n",
    "                BaseMessageChunk, self.invoke(input, config=config, stop=stop, **kwargs)\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    async def astream(...) -> AsyncIterator[BaseMessageChunk]:\n",
    "        # åœ¨#19332åˆå¹¶ä¸­ï¼Œ_astreamæ–¹æ³•å®ç°å·²ç»è¢«ç®€åŒ–\n",
    "        # https://github.com/langchain-ai/langchain/pull/19332/commits/afbe6ac659e41ab5f4a6f4dcaa33511e9e59e4d5\n",
    "        if (\n",
    "            type(self)._astream is BaseChatModel._astream\n",
    "            and type(self)._stream is BaseChatModel._stream\n",
    "        ):\n",
    "            # No async or sync stream is implemented, so fall back to ainvoke\n",
    "            yield cast(\n",
    "                BaseMessageChunk,\n",
    "                await self.ainvoke(input, config=config, stop=stop, **kwargs),\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    # bacth, abatch, astream_log, astream_events \n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6f28c-87d2-48a3-b78f-72af08ed9413",
   "metadata": {},
   "source": [
    "**å¿…é¡»å®ç°çš„éƒ¨åˆ†ï¼š**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9da607-5cfe-48a4-adaa-05d057e4dbcb",
   "metadata": {},
   "source": [
    "```python\n",
    "    ## ******** invoke / ainvoke / batch / abatch **********\n",
    "    @abstractmethod\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"Top Level call\"\"\"\n",
    "\n",
    "    ## ******** stream / astream / astream_log / astream_events **********\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        raise NotImplementedError()        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0526e-50a9-481f-ae14-6433fc114d25",
   "metadata": {},
   "source": [
    "### âœï¸ åŸºæœ¬å®ç°ï¼šinvoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b2c9ba-39af-488b-af00-d272b7bff551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from typing import Any, Dict, Iterator, List, Optional, Union\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, HumanMessageChunk, AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2ebdb44f-afd7-4ffc-9419-56e144a6d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatWithOlderAI(BaseChatModel):\n",
    "    \"\"\"æ¨¡æ‹Ÿè·Ÿé©¬å†¬æ¢…æ¥¼ä¸‹é‚»å±…è€å¤§çˆ·çš„å¯¹è¯\"\"\"\n",
    "\n",
    "    responses: List[BaseMessage] = [HumanMessage(m) for m in [\n",
    "        \"é©¬ä»€ä¹ˆæ¢…ï¼Ÿ\", \"ä»€ä¹ˆå†¬æ¢…ï¼Ÿï¼Ÿ\", \"é©¬ä¸œä»€ä¹ˆï¼Ÿï¼Ÿï¼Ÿ\",\n",
    "    ]]\n",
    "    \n",
    "    sleep: Optional[float] = 0.1\n",
    "    i: int = 0\n",
    "\n",
    "    # å¿…é¡»å®ç°\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"chat-with-neighber-older\"\n",
    "\n",
    "    # å¿…é¡»å®ç°\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        generations = [ChatGeneration(message=res) for res in self._ask_remote(messages)]\n",
    "        return ChatResult(generations=generations)\n",
    "\n",
    "    # è®¿é—®è¿œç¨‹å¤§æ¨¡å‹\n",
    "    def _ask_remote(self, messages: List[BaseMessage]) -> List[BaseMessage]:\n",
    "        if(re.search(\"é©¬å†¬æ¢…\", messages[0].content)):\n",
    "            response = self.responses[self.i]\n",
    "            if self.i < len(self.responses) - 1:\n",
    "                self.i += 1\n",
    "            else:\n",
    "                self.i = 0\n",
    "        else:\n",
    "            response = AIMessage(\"å“¦...\")\n",
    "        return [response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fb12783-b794-4ce2-8ace-4bd781be835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "å¤æ´›ï¼šå¤§çˆ·ï¼Œæ¥¼ä¸Š322ä½çš„æ˜¯é©¬å†¬æ¢…å®¶å—ï¼Ÿ\n",
      "å¤§çˆ·ï¼šé©¬ä»€ä¹ˆæ¢…ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…å•Š\n",
      "å¤§çˆ·ï¼šä»€ä¹ˆå†¬æ¢…ï¼Ÿï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬ä¸œä»€ä¹ˆï¼Ÿï¼Ÿï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šæˆ‘æ˜¯è¯´é©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬ä»€ä¹ˆæ¢…ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šæ‚¨æ­‡ç€å§...\n",
      "å¤§çˆ·ï¼šå“¦...|"
     ]
    }
   ],
   "source": [
    "questions = [[HumanMessage(m)] for m in [\n",
    "    \"å¤§çˆ·ï¼Œæ¥¼ä¸Š322ä½çš„æ˜¯é©¬å†¬æ¢…å®¶å—ï¼Ÿ\",\n",
    "    \"é©¬å†¬æ¢…å•Š\",\n",
    "    \"é©¬å†¬æ¢…ï¼\",\n",
    "    \"æˆ‘æ˜¯è¯´é©¬å†¬æ¢…ï¼\",\n",
    "    \"æ‚¨æ­‡ç€å§...\"\n",
    "]]\n",
    "\n",
    "llm = ChatWithOlderAI()\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question[0].content}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    # print(llm.invoke(question).content, end=\"\")\n",
    "    for chunk in llm.stream(question):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8231e5a-c8b9-4d8e-8e56-280ccc889fd7",
   "metadata": {},
   "source": [
    "### âœï¸ æ”¯æŒæµå¼è¾“å‡ºï¼šstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe2633f0-9002-4684-818a-44daed91c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamChatWithOlderAI(ChatWithOlderAI):\n",
    "    \"\"\"æ¨¡æ‹Ÿè·Ÿå¤§çˆ·çš„å¯¹è¯ï¼Œæ”¯æŒæµ\"\"\"\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        *args,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        response = self._ask_remote(messages)\n",
    "        for chunk in response[0].content:\n",
    "            if self.sleep is not None:\n",
    "                time.sleep(self.sleep)\n",
    "            yield ChatGenerationChunk(message=AIMessageChunk(content=chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "236c1cf8-0886-423f-9710-cd10ef7c6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "å¤æ´›ï¼šå¤§çˆ·ï¼Œæ¥¼ä¸Š322ä½çš„æ˜¯é©¬å†¬æ¢…å®¶å—ï¼Ÿ\n",
      "å¤§çˆ·ï¼šé©¬|ä»€|ä¹ˆ|æ¢…|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…å•Š\n",
      "å¤§çˆ·ï¼šä»€|ä¹ˆ|å†¬|æ¢…|ï¼Ÿ|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬|ä¸œ|ä»€|ä¹ˆ|ï¼Ÿ|ï¼Ÿ|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šæˆ‘æ˜¯è¯´é©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬|ä»€|ä¹ˆ|æ¢…|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šæ‚¨æ­‡ç€å§...\n",
      "å¤§çˆ·ï¼šå“¦|.|.|.|"
     ]
    }
   ],
   "source": [
    "llm_stream = StreamChatWithOlderAI()\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question[0].content}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    for chunk in llm_stream.stream(question):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a7d4000-66db-4be9-9dae-e9ab7e14cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "å¤æ´›ï¼šæ¥¼ä¸Š322ä½çš„æ˜¯é©¬å†¬æ¢…å®¶å—ï¼Ÿ\n",
      "å¤§çˆ·ï¼šé©¬|ä»€|ä¹ˆ|æ¢…|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…å•Š\n",
      "å¤§çˆ·ï¼šä»€|ä¹ˆ|å†¬|æ¢…|ï¼Ÿ|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬|ä¸œ|ä»€|ä¹ˆ|ï¼Ÿ|ï¼Ÿ|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šæˆ‘æ˜¯è¯´é©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬|ä»€|ä¹ˆ|æ¢…|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šå¤§çˆ·æ‚¨æ­‡ç€å§...\n",
      "å¤§çˆ·ï¼šå“¦|.|.|.|"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "questions_text = [\n",
    "    \"æ¥¼ä¸Š322ä½çš„æ˜¯é©¬å†¬æ¢…å®¶å—ï¼Ÿ\",\n",
    "    \"é©¬å†¬æ¢…å•Š\",\n",
    "    \"é©¬å†¬æ¢…ï¼\",\n",
    "    \"æˆ‘æ˜¯è¯´é©¬å†¬æ¢…ï¼\",\n",
    "    \"å¤§çˆ·æ‚¨æ­‡ç€å§...\"\n",
    "]\n",
    "\n",
    "llm_stream = StreamChatWithOlderAI()\n",
    "prompt = PromptTemplate.from_template(\"å¤§çˆ·ï¼Œ{question}\")\n",
    "chain = prompt | llm_stream | StrOutputParser()\n",
    "\n",
    "for question in questions_text:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    for chunk in chain.stream({\"question\": question}):\n",
    "        print(chunk, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae412a-cfd5-4160-80df-a6265560cd34",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ å®¡è§†è¿™ä¸ªæ¨¡æ‹Ÿå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4aeecb41-c94c-4046-817f-8642d0ecb937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StreamChatWithOlderAI |  \n",
      "+-----------------------+  \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()\n",
    "# llm_stream.input_schema.schema()\n",
    "# chain.input_schema.schema()\n",
    "# prompt.output_schema.schema()\n",
    "# prompt.invoke({\"question\":\"ä½ å¥½\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f664542-8ea0-4cba-ba61-735c0fea6b04",
   "metadata": {},
   "source": [
    "## â¤ï¸ å®ä¾‹2 é›†æˆæ™ºè°±å¤§æ¨¡å‹åˆ° Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e4176-391c-41a4-bc21-988f7b295843",
   "metadata": {},
   "source": [
    "### ğŸ¦œ éœ€æ±‚åˆ†æï¼šç»“åˆæ™ºè°±å®˜æ–¹æ–‡æ¡£ï¼Œç¼–å†™langchainçš„ChatZhipuAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff16f8-4f04-4639-9cbb-5aead5c88076",
   "metadata": {},
   "source": [
    "[è®¿é—®æ™ºè°±AIå®˜æ–¹çš„Pythonæ¥å£æ–‡æ¡£](https://maas.aminer.cn/dev/api#sdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7ebf3-ec67-4cbc-8c13-3cba71d7461f",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰å¯ç”¨æ¥å£\n",
    "- ç›´æ¥è°ƒç”¨ï¼šinvoke\n",
    "- å¼‚æ­¥è°ƒç”¨ï¼ˆå…ˆè°ƒç”¨ï¼Œå†æŸ¥è¯¢ç»“æœï¼‰ï¼šé€‚åˆå®ç° ainvoke / batch / abatch\n",
    "- æµå¼è°ƒç”¨ï¼ˆSSEï¼ŒServer-Send Events)ï¼šé€‚åˆå®ç° stream / astream / stream_log / stream_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d217d-27e3-4802-9ea6-e5d585a2bd01",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    åœ¨å“ªäº›åœºæ™¯ä¸‹å¯ä»¥å……åˆ†åˆ©ç”¨å®˜æ–¹APIæä¾›çš„å¼‚æ­¥èƒ½åŠ›ï¼Ÿ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf4066-d16d-4307-93d5-d54f56cdd3a2",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰æ”¯æŒèƒ½åŠ›\n",
    "- æ”¯æŒ å·¥å…·å›è°ƒï¼šå½¢å¼ä¸Šæ”¯æŒå¤šå·¥å…·è¿”å›\n",
    "- æ”¯æŒ è¯†åˆ«å›¾ç‰‡\n",
    "- æ”¯æŒ ç”Ÿæˆå›¾ç‰‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4f39d-46f4-401f-93c3-b6a59a687754",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    èƒ½å¦å®ç°ä¸€ä¸ªè‡ªå®šä¹‰å¤§æ¨¡å‹ï¼Œæ”¯æŒå¤šæ¨¡æ€èƒ½åŠ›ï¼Ÿ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbbbff-1483-487a-8648-141b5f64fc99",
   "metadata": {},
   "source": [
    "#### ï¼ˆ3ï¼‰é€Ÿç‡é™åˆ¶\n",
    "\n",
    "[æ™ºè°±AIå®˜æ–¹æ–‡æ¡£ä¸­å¯¹é€Ÿç‡é™åˆ¶çš„è¯´æ˜](https://maas.aminer.cn/dev/howuse/rate-limits/why?tab=5)ï¼š\n",
    "\n",
    "> å½“å‰æˆ‘ä»¬åŸºäºç”¨æˆ·çš„æœˆåº¦ API è°ƒç”¨æ¶ˆè€—é‡‘é¢æƒ…å†µå°†é€Ÿç‡æ§åˆ¶åˆ†ä¸º6ç§ç­‰çº§ã€‚\n",
    ">\n",
    "> æ¶ˆè€—é‡‘é¢é€‰å–é€»è¾‘ï¼šæˆ‘ä»¬ä¼šé€‰å–ç”¨æˆ·å½“å‰æœˆä»½1å·ï½t-1æ—¥çš„è°ƒç”¨ API æ¨ç†æ¶ˆè€—æ€»é‡‘é¢å’Œç”¨æˆ·ä¸Šä¸ªæœˆçš„ API è°ƒç”¨æ¶ˆè€—æ€»é‡‘é¢åšæ¯”è¾ƒï¼Œå–æ›´é«˜é‡‘é¢ä½œä¸ºç”¨æˆ·å½“å‰çš„ API æ¶ˆè€—é‡‘é¢ã€‚\n",
    ">\n",
    "> ç‰¹åˆ«çš„ï¼Œè‹¥æ‚¨ä»æœªæ›¾ä»˜è´¹å……å€¼/è´­ä¹°è¿‡èµ„æºåŒ…ï¼Œåˆ™ä¼šå½’ä¸ºå…è´¹çº§åˆ«ã€‚\n",
    "\n",
    "**æ•´ç†GLM4æ¨¡å‹ä½¿ç”¨é™åˆ¶å¦‚ä¸‹ï¼š**\n",
    "|ç”¨æˆ·ç­‰çº§|ä½¿ç”¨é‡|GLM4å¹¶å‘é™åˆ¶|\n",
    "|:---|:---|:---|\n",
    "|å…è´¹|apiè°ƒç”¨æ¶ˆè€—0å…ƒ-50å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|5|\n",
    "|ä½¿ç”¨é‡1|apiè°ƒç”¨æ¶ˆè€—50å…ƒ-500å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|10|\n",
    "|ä½¿ç”¨é‡2|apiè°ƒç”¨æ¶ˆè€—500å…ƒ-5000å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|20|\n",
    "|ä½¿ç”¨é‡3|apiè°ƒç”¨æ¶ˆè€—5000å…ƒ-10000å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|30|\n",
    "|ä½¿ç”¨é‡4|apiè°ƒç”¨æ¶ˆè€—10000å…ƒ-30000å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|100|\n",
    "|ä½¿ç”¨é‡5|apiè°ƒç”¨æ¶ˆè€—30000å…ƒä»¥ä¸Š/æ¯æœˆ|200|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941a68e-e6de-40f9-8ecb-610556b92296",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    èƒ½å¦å®ç°ä¸€ä¸ªè‡ªå®šä¹‰å¤§æ¨¡å‹ï¼Œé€šè¿‡å¤šä¸ªä½ç”¨é‡è´¦æˆ·ç®¡ç†æœºåˆ¶æ¥æ‰©å¤§è°ƒç”¨é€Ÿç‡ï¼Ÿ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e18cd-e44e-4f28-a8a2-819f719c4daf",
   "metadata": {},
   "source": [
    "### âœï¸ æµ‹è¯•å®˜æ–¹ä¾‹å­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317160f-22fe-4210-bc69-ed83abacfeca",
   "metadata": {},
   "source": [
    "çœ‹å®˜æ–¹ä¾‹å­ï¼š[https://github.com/MetaGLM/zhipuai-sdk-python-v4](https://github.com/MetaGLM/zhipuai-sdk-python-v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9dad0716-95a2-4966-bf90-07d33be54cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ZhipuAI\n",
    "# from zhipuai import ZhipuAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9681792b-ab7d-4269-b9d3-8f55a25ce0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ä½ å¥½ï¼Œæˆ‘å«æ™ºè°±æ¸…è¨€ï¼Œæ˜¯åŸºäºæ™ºè°±AIå…¬å¸äº2023å¹´è®­ç»ƒçš„ChatGLMå¼€å‘çš„ã€‚å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚' role='assistant' tool_calls=None\n"
     ]
    }
   ],
   "source": [
    "## çœ‹çœ‹å®˜æ–¹çš„ä¾‹å­æ˜¯å¦èƒ½æ­£ç¡®è¿è¡Œ\n",
    "client = ZhipuAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å«ä»€ä¹ˆåå­—\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835dc40-1269-4415-8127-70f62f8ea0a0",
   "metadata": {},
   "source": [
    "### âœï¸ åŒ…è£…ä¸ºä¸€ä¸ª å‡½æ•°è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c782a4d-663b-423c-8cd7-3d63a7893e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is your name?'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_zhipu(question) -> str:\n",
    "    client = ZhipuAI()\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘æœºå™¨äººï¼Œæˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"hello\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return(response.choices[0].message.content)\n",
    "\n",
    "ask_zhipu(\"ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f6f0e-3891-4a30-91a8-afcfd2cf5d08",
   "metadata": {},
   "source": [
    "### âœï¸ æ”¯æŒä¸ Prompt åä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2572d41a-b2a6-4b81-9426-f083081f86ac",
   "metadata": {},
   "source": [
    "```python\n",
    "# èƒ½å¦å®ç°å¦‚ä¸‹åœºæ™¯ï¼Ÿ\n",
    "chain = prompt | llm\n",
    "chain.invoke({\"question\": \"ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd50c3d-5a21-4d6b-96e2-76a2e5ae5566",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒ</b><br>\n",
    "    ä¸‹é¢ä»£ç ä¸­ï¼Œ ä¸ºä»€ä¹ˆ from_messages æ”¯æŒ systemã€humanã€ai è¿™äº›åå­—ï¼Ÿè¿˜æœ‰å…¶ä»–åå­—å—ï¼Ÿæ–‡æ¡£åœ¨å“ªé‡Œï¼Ÿ\n",
    "</div>\n",
    "\n",
    "**ğŸŒ ç­”æ¡ˆï¼š**\n",
    "- [æŸ¥çœ‹ _create_message_from_message_type() æºç ](https://github.com/langchain-ai/langchain/blob/c93d4ea91cfcf55dfe871931d42aa22562f8dae2/libs/core/langchain_core/messages/utils.py#L130-L168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "024270e5-a030-421f-8af7-af64c1251dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘æœºå™¨äººï¼Œæˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚'), HumanMessage(content='ä½ å¥½'), AIMessage(content='hello'), HumanMessage(content='ä½ å«ä»€åå­—ï¼Ÿ')])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘æœºå™¨äººï¼Œæˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚\"),\n",
    "    (\"human\", \"ä½ å¥½\"),\n",
    "    (\"ai\", \"hello\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "prompt.invoke({\"question\":\"ä½ å«ä»€åå­—ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5d90cc73-c09f-44c0-92bf-4bee04489894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘æœºå™¨äººï¼Œæˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚'),\n",
       " HumanMessage(content='ä½ å¥½'),\n",
       " AIMessage(content='hello'),\n",
       " HumanMessage(content='ä½ å«ä»€åå­—ï¼Ÿ')]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\":\"ä½ å«ä»€åå­—ï¼Ÿ\"}).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a48adc15-0507-4950-bb27-f034e5a5ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "\n",
    "def convert_message_to_dict(message: BaseMessage) -> dict:\n",
    "    \"\"\"ä»langchainæ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºå¤§æ¨¡å‹å­—å…¸æ ¼å¼\"\"\"\n",
    "    message_dict: Dict[str, Any]\n",
    "    if isinstance(message, HumanMessage):\n",
    "        message_dict = {\"role\": \"user\", \"content\": message.content}\n",
    "    elif isinstance(message, AIMessage):\n",
    "        message_dict = {\"role\": \"assistant\", \"content\": message.content}\n",
    "        if \"tool_calls\" in message.additional_kwargs:\n",
    "            message_dict[\"tool_calls\"] = message.additional_kwargs[\"tool_calls\"]\n",
    "    elif isinstance(message, SystemMessage):\n",
    "        message_dict = {\"role\": \"system\", \"content\": message.content}\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        message_dict = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": message.content,\n",
    "            \"tool_call_id\": message.tool_call_id,\n",
    "        }\n",
    "    else:\n",
    "        raise TypeError(f\"Unknown type from langchain to LLM: {type(message).__name__} {message}\")\n",
    "    return message_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a24c1316-3741-49a7-85da-806b5fcd2e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘æœºå™¨äººï¼Œæˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚'},\n",
       " {'role': 'user', 'content': 'ä½ å¥½'},\n",
       " {'role': 'assistant', 'content': 'hello'},\n",
       " {'role': 'user', 'content': 'ä½ å«ä»€åå­—ï¼Ÿ'}]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[convert_message_to_dict(m) for m in prompt.invoke({\"question\":\"ä½ å«ä»€åå­—ï¼Ÿ\"}).to_messages()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7648a6-6ab7-4a62-81b3-d0b02c553ea2",
   "metadata": {},
   "source": [
    "### âœï¸ åŒ…è£…ä¸ºä¸€ä¸ª RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "63e5a0a3-433d-48e7-950b-fc3d8a445e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from typing import List\n",
    "from langchain_core.prompt_values import ChatPromptValue \n",
    "\n",
    "@chain\n",
    "def ask_zhipu(promptValue: ChatPromptValue) -> str:\n",
    "    client = ZhipuAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=[convert_message_to_dict(m) for m in promptValue.to_messages()],\n",
    "    )\n",
    "    return(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "367b9894-8a00-4913-b542-ed0f6e73ec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is your name?'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | ask_zhipu\n",
    "chain.invoke({\"question\": \"ä½ å«ä»€åå­—ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "41dae6d9-9301-4c56-bc78-96f1ad2f758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-------------+    \n",
      "    | PromptInput |    \n",
      "    +-------------+    \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "+--------------------+ \n",
      "| ChatPromptTemplate | \n",
      "+--------------------+ \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      "+-------------------+  \n",
      "| Lambda(ask_zhipu) |  \n",
      "+-------------------+  \n",
      "           *           \n",
      "           *           \n",
      "           *           \n",
      " +------------------+  \n",
      " | ask_zhipu_output |  \n",
      " +------------------+  \n"
     ]
    }
   ],
   "source": [
    "# çœ‹çœ‹å½“å‰é“¾çš„ç»“æ„\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa150d60-9630-4597-bd2f-16524238f899",
   "metadata": {},
   "source": [
    "### âœï¸ åŸºäºBaseChatModelå®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a0374ab1-7121-4513-869e-bbc5ab56302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast, Mapping\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    BaseMessage, \n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.outputs import (\n",
    "    ChatGeneration,\n",
    "    ChatResult\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d46fb809-bfbd-4035-9de4-0a1d52a6da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_message(_dict: Mapping[str, Any]) -> BaseMessage:\n",
    "    \"\"\"ä»å¤§æ¨¡å‹å­—å…¸æ ¼å¼è½¬æ¢ä¸ºlangchainæ¶ˆæ¯æ ¼å¼\"\"\"\n",
    "    role = _dict.get(\"role\")\n",
    "    if role == \"user\":\n",
    "        return HumanMessage(content=_dict.get(\"content\", \"\"))\n",
    "    elif role == \"assistant\":\n",
    "        content = _dict.get(\"content\", \"\") or \"\"\n",
    "        additional_kwargs: Dict = {}\n",
    "        if tool_calls := _dict.get(\"tool_calls\"):\n",
    "            additional_kwargs[\"tool_calls\"] = tool_calls\n",
    "        return AIMessage(content=content, additional_kwargs=additional_kwargs)\n",
    "    elif role == \"system\":\n",
    "        return SystemMessage(content=_dict.get(\"content\", \"\"))\n",
    "    elif role == \"tool\":\n",
    "        additional_kwargs = {}\n",
    "        if \"name\" in _dict:\n",
    "            additional_kwargs[\"name\"] = _dict[\"name\"]\n",
    "        return ToolMessage(\n",
    "            content=_dict.get(\"content\", \"\"),\n",
    "            tool_call_id=_dict.get(\"tool_call_id\"),\n",
    "            additional_kwargs=additional_kwargs,\n",
    "            id=id_,\n",
    "        )\n",
    "    else:\n",
    "        raise TypeError(f\"Unknow type from LLM to langchain: {_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "be2ac9a7-62e2-45c8-a0b5-5b0d97824ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniZhipuAI(BaseChatModel):\n",
    "    \"\"\"æ”¯æŒæœ€æ–°çš„æ™ºè°±API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.client = ZhipuAI()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _ask_remote(self, messages, streaming=False, **kwargs):\n",
    "        # ä»langchainæ¶ˆæ¯æ ¼å¼ï¼Œè½¬æ¢åˆ°æ™ºè°±AIè¾“å…¥çš„æ ¼å¼\n",
    "        dict_zhipu = [convert_message_to_dict(m) for m in messages]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-4\",\n",
    "            messages=dict_zhipu,\n",
    "            stream=streaming,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # ä»æ™ºè°±AIè¾“å‡ºçš„æ ¼å¼ï¼Œè½¬æ¢åˆ°langchainçš„æ¶ˆæ¯æ ¼å¼\n",
    "        if not isinstance(response, dict):\n",
    "            response = response.dict()\n",
    "        return [convert_dict_to_message(c[\"message\"]) for c in response[\"choices\"]]\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"å®ç° ZhiputAI çš„åŒæ­¥è°ƒç”¨\"\"\"\n",
    "\n",
    "        # é—®æ™ºè°±AIï¼Œå¹¶å¾—åˆ°å›å¤\n",
    "        responses = self._ask_remote(messages, streaming=False, **kwargs)\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[ChatGeneration(message=m) for m in responses]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "fee54840-3dfb-4d6d-ae4b-6a07ba3b2d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ä¸­ç¾åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„ç«äº‰éå¸¸æ¿€çƒˆã€‚ä¸­å›½èƒ½èµ¶å¾—ä¸Šå—ï¼Ÿ')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸­è‹±äº’è¯‘æœºå™¨äººï¼Œåªè´Ÿè´£ç¿»è¯‘ï¼Œä¸è¦è¯•å›¾å¯¹é—®é¢˜åšè§£ç­”ã€‚æˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚\"),\n",
    "    (\"human\", \"ä½ å¥½\"),\n",
    "    (\"ai\", \"hello\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "llm_zhipu = MiniZhipuAI()\n",
    "chain = prompt | llm_zhipu\n",
    "\n",
    "chain.invoke({\"question\": \"The competition between China and the United States in the AI field is very intense. Can China catch up?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467f98a-f6c6-4443-b0ef-ef906cf26111",
   "metadata": {},
   "source": [
    "### âœï¸ å°è¯•è°ƒç”¨å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "2adeaac3-3dd6-4a5e-9591-7da1b31660c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸€ä¸ªç®€å•çš„å·¥å…·\n",
    "from langchain.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool, convert_to_openai_function\n",
    "import re\n",
    "\n",
    "@tool\n",
    "def ask_neighber(query: str) -> str:\n",
    "    \"\"\"æˆ‘åœ¨ç©æ‰¾äººçš„æ¸¸æˆï¼Œæˆ‘çŸ¥é“ä½ æ‰¾çš„äººä½åœ¨å“ªä¸ªæˆ¿é—´\"\"\"\n",
    "    if(re.search(\"é©¬å†¬æ¢…\", query)):\n",
    "        return \"æ¥¼ä¸Š322\"\n",
    "    else:\n",
    "        return \"æˆ‘ä¸æ¸…æ¥š\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "98d510aa-b493-4920-968b-909cfdfd2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_zhipu = MiniZhipuAI().bind(tools=[convert_to_openai_tool(ask_neighber)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "52acb9b5-9948-4de6-b364-c1da895d1a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8513183423441263269', 'function': {'arguments': '{\"query\":\"é©¬å†¬æ¢…\"}', 'name': 'ask_neighber'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_zhipu.invoke(\"å‘Šè¯‰æˆ‘é©¬å†¬æ¢…åœ¨å“ªä¸ªæˆ¿é—´ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9eb8a61d-573c-468d-b9df-62516c521e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æ¥¼ä¸Š322'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_neighber.invoke({\"query\":\"é©¬å†¬æ¢…\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b829b6-ec99-4077-9608-59ed42add56c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    openai_function å’Œ convert_to_openai_tool çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "</div>\n",
    "\n",
    "**ğŸŒ å‚è€ƒï¼š**\n",
    "- [æŸ¥çœ‹ convert_to_openai_tool çš„å®ç°æºç ](https://github.com/langchain-ai/langchain/blob/c93d4ea91cfcf55dfe871931d42aa22562f8dae2/libs/core/langchain_core/utils/function_calling.py#L323-L341)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "53631752-d072-4087-ae58-9a8eafee22ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ask_neighber',\n",
       " 'description': 'ask_neighber(query: str) -> str - æˆ‘åœ¨ç©æ‰¾äººçš„æ¸¸æˆï¼Œæˆ‘çŸ¥é“ä½ æ‰¾çš„äººä½åœ¨å“ªä¸ªæˆ¿é—´',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query']}}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_function(ask_neighber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a1f6fefc-f96f-446f-a72b-de3cad4a9afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'ask_neighber',\n",
       "  'description': 'ask_neighber(query: str) -> str - æˆ‘åœ¨ç©æ‰¾äººçš„æ¸¸æˆï¼Œæˆ‘çŸ¥é“ä½ æ‰¾çš„äººä½åœ¨å“ªä¸ªæˆ¿é—´',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string'}},\n",
       "   'required': ['query']}}}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_tool(ask_neighber)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486f46b-8c36-49ba-aec8-5340206443fe",
   "metadata": {},
   "source": [
    "### âœï¸ å°è¯•è°ƒç”¨æ™ºèƒ½ä½“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5c09ac0d-f981-4c50-a2c7-fc41f082618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "tools = [ask_neighber]\n",
    "\n",
    "agent = create_openai_tools_agent(llm_zhipu, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "fc382cdb-9ffc-40fa-a16c-41b5eb371c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ask_neighber` with `{'query': 'é©¬å†¬æ¢…ä½å“ªé‡Œ'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mæ¥¼ä¸Š322\u001b[0m\u001b[32;1m\u001b[1;3mæ ¹æ®æˆ‘çš„æŸ¥è¯¢ç»“æœï¼Œé©¬å†¬æ¢…ä½åœ¨æ¥¼ä¸Š322æˆ¿é—´ã€‚å¸Œæœ›è¿™ä¸ªä¿¡æ¯å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'é©¬å†¬æ¢…ä½å“ªé‡Œ', 'output': 'æ ¹æ®æˆ‘çš„æŸ¥è¯¢ç»“æœï¼Œé©¬å†¬æ¢…ä½åœ¨æ¥¼ä¸Š322æˆ¿é—´ã€‚å¸Œæœ›è¿™ä¸ªä¿¡æ¯å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"é©¬å†¬æ¢…ä½å“ªé‡Œ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77770d1-c8fa-4967-8142-e91d012652e9",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ ChatZhipuAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff552d-78cd-41c0-a302-b9a695c2887d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    ä¸Šé¢ä»£ç å·²ç»ç›¸å¯¹å®Œæ•´å®ç°äº†ä¸€ä¸ª langchain å¤§æ¨¡å‹ï¼›ä½†ç¼ºå°‘å¾ˆå¤šç»†èŠ‚æ§åˆ¶ï¼Œå¯ä»¥å°è¯•è‡ªå·±åŠ¨æ‰‹æ·»åŠ ï¼\n",
    "</div>\n",
    "\n",
    "**ğŸŒ å‚è€ƒï¼š**\n",
    "- [æŸ¥çœ‹ langchain_zhpu ä¸­çš„å®ç°æºç ](https://github.com/arcstep/langchain_zhipuai/blob/e55af13eed673bc409ffdb143030e6cc0b2af27c/langchain_zhipu/chat.py#L304-L354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "91fddecd-fd0c-41f7-b262-114a36d54145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘|ä½¿ç”¨çš„|æ¨¡å‹|æ˜¯|æ¸…åå¤§å­¦| K|EG| å®|éªŒ|å®¤|å’Œ|æ™º|è°±|AI|å…±åŒ|è®­ç»ƒ|çš„| GL|M| æ¨¡|å‹|ï¼Œ|ä¸€ç§|åŸºäº| Transformer| çš„|é€šç”¨|é¢„|è®­ç»ƒ|è¯­è¨€|æ¨¡å‹|ã€‚|Transformer| æ¨¡|å‹|æ˜¯ä¸€ç§|åŸºäº|è‡ª|æ³¨æ„åŠ›|æœºåˆ¶çš„|æ·±åº¦|ç¥ç»ç½‘ç»œ|æ¨¡å‹|ï¼Œ|ç»å¸¸|ç”¨äº|å¤„ç†|åºåˆ—|æ•°æ®|ã€‚\n",
      "\n",
      "æˆ‘|å¯èƒ½|ç”¨åˆ°|æœ€å¤§çš„|æ¨¡å‹|æ˜¯| GL|M|-|130|B|ï¼Œ|å…·æœ‰| |130|0| äº¿|å‚æ•°|ï¼Œ|æ”¯æŒ|ä¸­|è‹±|åŒè¯­|ã€‚|æˆ‘|å…·ä½“|ä½¿ç”¨çš„|æ¨¡å‹|è§„æ¨¡|è§†|åº”ç”¨|åœºæ™¯|å¯èƒ½ä¼šæœ‰|æ‰€|å˜åŒ–|ã€‚||"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "\n",
    "llm_zhipuai = ChatZhipuAI()\n",
    "for chunk in llm_zhipuai.stream(\"ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹\"):\n",
    "    print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "bc557ddb-fa06-4fbf-90da-d9418123dab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|æˆ‘|æ˜¯|ä¸€ä¸ª|åŸº|äº|äºº|å·¥|æ™º|èƒ½|æŠ€|æœ¯|çš„|å¯¹|è¯|æ¨¡|å‹|ï¼Œ|å¯ä»¥|è¿›è¡Œ|è‡ª|ç„¶|è¯­|è¨€|äº¤|äº’|å¹¶|æ|ä¾›|ç›¸å…³|ä¿¡æ¯|å’Œ|å¸®|åŠ©|ã€‚|æˆ‘|ä¸|æ˜¯|ç‰¹|å®š|çš„|æœº|å™¨|å­¦|ä¹ |æ¨¡|å‹|ï¼Œ|è€Œ|æ˜¯|ç”±|å¤š|ç§|æŠ€|æœ¯|å’Œ|ç®—|æ³•|ç»„|åˆ|è€Œ|æˆ|çš„|ã€‚||"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "langchain_openai = ChatOpenAI()\n",
    "for chunk in langchain_openai.stream(\"ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹\"):\n",
    "    print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00700e0-ac72-424a-a3f3-1bd1b41adc4e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    äº‹å®ä¸Šï¼Œçœ‹èµ·æ¥æ²¡æœ‰ stream çš„ RunnableLambda å¯ä»¥è¿”å›ä¸€ä¸ªå…·æœ‰ stream èƒ½åŠ›çš„ Runnableï¼ä½ çŸ¥é“è¿™æ˜¯ä¸ºä»€ä¹ˆï¼Ÿ\n",
    "</div>\n",
    "\n",
    "**ç­”æ¡ˆï¼š**\n",
    "- [æŸ¥çœ‹ RunnableLambda æºç ](https://github.com/langchain-ai/langchain/blob/c93d4ea91cfcf55dfe871931d42aa22562f8dae2/libs/core/langchain_core/runnables/base.py#L4056-L4071)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2e199-6d19-47db-888d-ea07303af597",
   "metadata": {},
   "source": [
    "## ç‰ˆæœ¬1\n",
    "\n",
    "### çœ‹çœ‹æ™ºè°±å®˜æ–¹çš„ç®€å•ä¾‹å­\n",
    "### Langchain ç›¸å…³åº“æºç \n",
    "### å†™ä¸€ä¸ªç®€å•çš„ Langchain ç‰ˆæœ¬\n",
    "### åœ¨LCELä¸­ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b0bf2-030c-40e3-8702-153cddd37031",
   "metadata": {},
   "source": [
    "## ç‰ˆæœ¬2\n",
    "\n",
    "### è¯•è¯•æµï¼šæš‚æ—¶ä¸æ”¯æŒ\n",
    "### çœ‹çœ‹æ™ºè°±å®˜æ–¹å¯¹æµçš„æ”¯æŒ\n",
    "### çœ‹çœ‹æµçš„é»˜è®¤å®ç°æºç \n",
    "### è®©æˆ‘ä»¬ä¹Ÿæ”¯æŒæµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e820d-46fc-4bcb-8264-ce0c34e416b4",
   "metadata": {},
   "source": [
    "## ç‰ˆæœ¬3\n",
    "\n",
    "### è¯•è¯•å·¥å…·ï¼šæš‚æ—¶ä¸æ”¯æŒ\n",
    "### çœ‹çœ‹æ™ºè°±å®˜æ–¹å¯¹å·¥å…·å›è°ƒçš„æ”¯æŒ\n",
    "### å›é¡¾å·¥å…·å›è°ƒï¼šåªæ˜¯ä¸€ç§æ¶ˆæ¯æ ¼å¼\n",
    "### çœ‹çœ‹ openai å®ç°æºç \n",
    "### è®©æˆ‘ä»¬ä¹Ÿæ”¯æŒå·¥å…·å›è°ƒ\n",
    "### åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨\n",
    "### å®Œæ•´ä»£ç è¯·å‚è€ƒ langchain_zhipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c36b2-6d05-4e49-bbd5-34d231c08ae1",
   "metadata": {},
   "source": [
    "## 1ã€âœï¸ ä»£ç å‡†å¤‡ï¼šlangchainä¸­çš„LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d17151-50f4-4d7c-97a6-6df12706b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM invoke\n",
    "# OpenAI\n",
    "\n",
    "# LLM stream\n",
    "# OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8b752-1a25-4bb9-844e-e92308966b51",
   "metadata": {},
   "source": [
    "### 2ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•å®ç°ä¸€ä¸ªFakeLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7f2b17-1585-4fe5-bfce-65ff0d9d28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é©¬å†¬æ¢…æ¥¼ä¸‹è€å¤§çˆ·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68825344-97a0-4b23-b27b-d7aea3019cad",
   "metadata": {},
   "source": [
    "[å·²ç»å®ç°çš„FakeLLM](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/fake.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b74ef-7182-4c5a-a185-371b9266b90f",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šé›†æˆè‡ªå·±çš„å¤§æ¨¡å‹éœ€è¦å¦‚ä½•ä¸‹æ‰‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e1905-cbbe-4339-bf5b-9ff81836a756",
   "metadata": {},
   "source": [
    "### 4ã€âœï¸ ä»£ç å®è·µï¼šä¸€æ­¥æ­¥é›†æˆæ™ºè°±AIå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fdcc70-1271-4e35-8e06-9d8ae37f48ea",
   "metadata": {},
   "source": [
    "- æ”¯æŒ invoke\n",
    "- æ”¯æŒ stream\n",
    "- æ”¯æŒ tools-calling\n",
    "\n",
    "- å®Œæ•´å®ç°ï¼š[langchain_zhipu](https://github.com/arcstep/langchain_zhipu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c0a94-ec25-4bec-bdff-93acc9e025bf",
   "metadata": {},
   "source": [
    "# â¤ï¸ï¼ˆäºŒï¼‰LLMè¾“å…¥è¾“å‡ºï¼šå…¨é¢æ‹†è§£ Runnable ç»“æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4800b-4b93-4a89-8040-397b53c402dc",
   "metadata": {},
   "source": [
    "### 1ã€å¤§æ¨¡å‹è°ƒç”¨è¿‡ç¨‹ä¸­å‘ç”Ÿçš„æ•°æ®æµè½¬æ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077bf62-1adb-4e92-b2fe-80cbb5265342",
   "metadata": {},
   "source": [
    "- ä»è®­è¿‡çš„æ¨¡å‹è¯´èµ·ï¼šè®­ç»ƒé¢„æ–™å’Œé¢„æµ‹æ–‡æœ¬é£æ ¼ï¼ˆ|<assistent>| xxxxxx |</assistent>|)\n",
    "- ä½œä¸ºAPIæä¾›ï¼šopenAIé£æ ¼\n",
    "- ä»æç¤ºè¯­åˆ°langchainæ¶ˆæ¯ï¼šBaseMessages\n",
    "- ä»langchainæ¶ˆæ¯åˆ°å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼šBaseChatModel\n",
    "- ä»å¤§æ¨¡å‹ç»“æœåˆ°langchainæ¶ˆæ¯ï¼šBaseMessages\n",
    "- ä»langchainæ¶ˆæ¯åˆ°è¾“å‡ºè§£æå™¨ï¼šOutpurParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a6a02-27aa-4996-81ff-0c27da433aef",
   "metadata": {},
   "source": [
    "### 2ã€å¦‚æœåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ç»Ÿä¸€å„æ¨¡å—æ ‡å‡†ï¼Œéšæ—¶æ›´æ¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d13c5-663b-440c-92fd-9d1c51eb630d",
   "metadata": {},
   "source": [
    "### 3ã€å¦‚æœåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ä½¿ç”¨æµã€å¼‚æ­¥ã€æ‰¹é‡ã€äº‹ä»¶æµ ... ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09417b7-12b2-4998-8d89-d5695140a5fa",
   "metadata": {},
   "source": [
    "### 4ã€è¿™ä¸ªè¿‡ç¨‹ä¸­çš„ç¼“å­˜ã€é‡è¯•ã€é…ç½® ... ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee06284-0b63-4231-9aa7-a9dced804e0e",
   "metadata": {},
   "source": [
    "### 1ã€ä¸ºä»€ä¹ˆè¯´å¯ä»¥ç”¨ Runnable ç»„ä»¶åœ¨ç”Ÿäº§ç³»ç»Ÿä¸­æ­ç§¯æœ¨ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918dc61-89d0-47c0-877b-2489dcb44b47",
   "metadata": {},
   "source": [
    "- Runnableæ¥å£æ ‡å‡†åŒ–çš„ä»·å€¼\n",
    "    - æ›¿æ¢å¤§æ¨¡å‹ï¼šä»GPTåˆ°å›½äº§äº‘æ¨¡å‹ã€åˆ°å¼€æºè‡ªè®­æ¨¡å‹çš„å¤šå±‚æ¬¡å°è¯•å’Œè½åœ°æ˜¯å¿…è¦çš„\n",
    "    - æ›¿æ¢è°ƒç”¨æ–¹å¼ï¼šæ»¡è¶³ä¸šåŠ¡éªŒè¯ã€ç”Ÿäº§ä¸Šçº¿ã€ä¸šåŠ¡æ‰©å®¹ç­‰å¤šåœºæ™¯\n",
    "    - æ›¿æ¢æç¤ºè¯­æ¨¡æ¿ï¼šé€‚åº”æŠ€æœ¯ç ”ç©¶ã€ä¸šåŠ¡å®šåˆ¶ã€è¿è¥ä¼˜åŒ–ç­‰å¤šé˜¶æ®µ\n",
    "    - æ›¿æ¢è§£æå™¨ï¼šé€‚åº”æ¨¡å—è°ƒç”¨ã€APIè°ƒç”¨ç­‰å¤šåè®®å¯¹æ¥\n",
    "    - æ›¿æ¢å›è°ƒé›†æˆï¼šlangsmithã€langfuseäº‘ã€langfuseæœ¬åœ°åŒ–ã€è‡ªå»ºè¿ç»´ç³»ç»Ÿ\n",
    "    - æ›¿æ¢å‘é‡æ•°æ®åº“ï¼šé€‚åº”ä¸åŒåœºæ™¯ã€é˜¶æ®µçš„æŠ€æœ¯é€‰å‹è°ƒæ•´\n",
    "    - æ›¿æ¢æŒä¹…åŒ–ï¼š...\n",
    "    - æ›¿æ¢æ™ºèƒ½ä½“ï¼š..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233dae74-6f40-4195-a825-cde34826bd07",
   "metadata": {},
   "source": [
    "### 2ã€ğŸŒ¹ é˜…è¯»æºç ï¼šRunnable ç»„ä»¶8ä¸ªæ–¹æ³•çš„å®ç°é€»è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5002f62-1c47-4157-9485-eaa10314a517",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šRunnable ç»„ä»¶é…ç½®è‡ªä¸¾èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d9e06-606f-4f72-b9fe-8ec9530eed05",
   "metadata": {},
   "source": [
    "- äº†è§£Runnable ç»„ä»¶çš„ 8 ä¸ªæ–¹æ³•çš„é»˜è®¤å®ç°\n",
    "- è‡ªå®šä¹‰Runnableï¼ˆå¿…è¦å®ç°ä¸€èˆ¬æ˜¯invoke / stream / astreamï¼Œæˆ–å¯¹åº”çš„å†…éƒ¨å‡½æ•°ï¼‰\n",
    "- invokeï¼šæ ‡å‡†åŒ–è°ƒåº¦\n",
    "- batch: æ ‡å‡†åŒ–æ‰¹é‡è°ƒåº¦\n",
    "- streamï¼šæ ‡å‡†åŒ–æµå¼è¾“å‡º\n",
    "- ainvoke / astream / abatch: æ ‡å‡†åŒ–å¼‚æ­¥è°ƒåº¦\n",
    "- astream_log / astream_events: åœ¨é“¾ã€æ™ºèƒ½ä½“ã€langgraphç­‰è¾“å‡ºä¸­æŒ‰ç…§namesã€tagsã€eventsæå–æµå¼æ—¥å¿—\n",
    "- configï¼šç»Ÿä¸€ç®¡ç†é…ç½®\n",
    "- schemaï¼šç»Ÿä¸€æ¢æŸ¥å‚æ•°å’Œé…ç½®\n",
    "\n",
    "- åºåˆ—åŒ–\n",
    "\n",
    "- é…ç½®è‡ªä¸¾ï¼šåœ¨å¼€æ”¾å¼åº”ç”¨ä¸­æ”¯æŒå®¢æˆ·ç«¯è‡ªåŠ¨è¯†åˆ«è‡ªå®šä¹‰æœåŠ¡\n",
    "- å®¹é”™ï¼šæ ‡å‡†åŒ–é‡è¯•ç­–ç•¥\n",
    "- ä¸langserveç­‰apiæ¡†æ¶æ ‡å‡†åŒ–å¯¹æ¥\n",
    "- ä¸langfuseç­‰callbckæ¡†æ¶æ ‡å‡†åŒ–å¯¹æ¥\n",
    "- ä¸langchainjsç­‰å¼‚æ„å®ç°æ ‡å‡†åŒ–å¯¹æ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a62f75-52bd-462b-a396-8fb9751fc84a",
   "metadata": {},
   "source": [
    "### 4ã€ğŸŒ¹ é˜…è¯»æºç ï¼šé—ç•™çš„ Chain æ˜¯ä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f68e5-b811-4854-af6f-7a8ded1ba8bd",
   "metadata": {},
   "source": [
    "- langchainä¸­æå‰å†™å¥½çš„Chainèµ„æº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3fa84-035e-4eb5-be59-4c3a902fea45",
   "metadata": {},
   "source": [
    "- è¿™äº› Chain å±€é™æ€§åœ¨ç©¶ç«Ÿå“ªé‡Œï¼Ÿ\n",
    "    - æµç¨‹ä¸çµæ´»\n",
    "    - æ”¯æŒæµå¼è¾“å‡ºä¸å½»åº•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0ddb0-134d-4641-ad0f-994df1e945b5",
   "metadata": {},
   "source": [
    "### 5ã€âœï¸ ä»£ç å®è·µï¼šè‹¥å¹²ç§æƒ…å†µä¸‹çš„æµè¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b85a1-eda7-4c3c-80af-0a125e5b4fee",
   "metadata": {},
   "source": [
    "# â¤ï¸ ç¬¬ 2 éƒ¨ä»½ï¼šAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64598d5-cdac-4a60-96d9-52b44730d6a2",
   "metadata": {},
   "source": [
    "# â¤ï¸ï¼ˆä¸‰ï¼‰ç”±LCELå®ç°æ™ºèƒ½ä½“ï¼šå…¨é¢æ‹†è§£ LCEL èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af86c4c-549a-4eb6-9ddc-f07314e393aa",
   "metadata": {},
   "source": [
    "### 1ã€LCEL æ¯” é—ç•™ Chain å¤šå“ªäº›ä¼˜åŠ¿ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76adf428-cdd4-4aa8-ac8b-3a3648ae7ead",
   "metadata": {},
   "source": [
    "- LCEL æ„å»ºçš„æ›¿ä»£ Chain\n",
    "- äº†è§£æ”¯æ’‘LCELçš„Runnableç»„ä»¶\n",
    "    - Lambda\n",
    "    - è¿­ä»£å™¨\n",
    "    - å­—å…¸å’Œå¹¶è¡Œ\n",
    "    - è·¯ç”±\n",
    "    - æ¡ä»¶\n",
    "    - è¿­ä»£æ‰§è¡Œ\n",
    "    - ç»‘å®š\n",
    "    - ç»˜å›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9e9ba-3388-40f2-a8f0-38ea7b7b2efd",
   "metadata": {},
   "source": [
    "### 2ã€å¦‚ä½•ç”¨ LCEL å®šä¹‰æ™ºèƒ½ä½“ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bd7d1-572a-447b-89b6-528b45258be9",
   "metadata": {},
   "source": [
    "- å·¥å…·ï¼šå®šä¹‰ä¸€ä¸ªç®€å•å·¥å…·\n",
    "- æ™ºèƒ½ä½“ï¼š\n",
    "    - Tools-Calling æ™ºèƒ½ä½“\n",
    "    - ReAct æ™ºèƒ½ä½“\n",
    "- æ‰§è¡Œå™¨ï¼šAgentExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d886c2-abec-4423-8742-068d144e66d3",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šäº†è§£ create_react_agent çš„è®¾è®¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad31612-b006-4803-96a9-6bb824b1c25a",
   "metadata": {},
   "source": [
    "- ä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“éœ€æ±‚ï¼šä¸AIç©ä¸€ä¸ªæ‰è¿·è—æ¸¸æˆ\n",
    "- reactæ™ºèƒ½ä½“çš„promptå¦‚ä½•å·¥ä½œ\n",
    "- ä¸­é—´æ­¥éª¤çš„ä¸€æ­¥æ­¥äº§ç”Ÿè¿‡ç¨‹\n",
    "- actionå¦‚ä½•è§£æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0378cc-4936-4ce2-abc6-9a7deebfa4c1",
   "metadata": {},
   "source": [
    "### 4ã€ğŸŒ¹ é˜…è¯»æºç ï¼šäº†è§£ AgentExecutor çš„æ‰§è¡Œé€»è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243379b-0e24-42ce-9087-239608bf5882",
   "metadata": {},
   "source": [
    "### 4ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•ç”¨ AgentExcutor å†ç°ã€Šæ‰‹æ’•AutoGPTã€‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba7531-66a6-4fda-81dc-03a87a2a637f",
   "metadata": {},
   "source": [
    "éš¾ç‚¹ï¼š\n",
    "- å®˜æ–¹ä¾‹å­å’Œå†…ç½®æ™ºèƒ½ä½“æ— æ³•æ”¯æŒpydanticå‚æ•°è§£æï¼ˆæ™ºè°±AIç­‰æ¨ç†èƒ½åŠ›è¾ƒå¼±çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702bd5b7-8aeb-4d5a-bd14-dfe0cc39e238",
   "metadata": {},
   "source": [
    "# â¤ï¸ï¼ˆå››ï¼‰ç”±LangGraphå®ç°æ™ºèƒ½ä½“ï¼šå…¨é¢æ‹†è§£ LangGraph èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b530de-c32e-4de7-a53d-2a7403ae881e",
   "metadata": {},
   "source": [
    "### 1ã€LangGraph æ¯” LCEL å¤šäº†ä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28481dec-c573-4c30-ba7d-a557702475ee",
   "metadata": {},
   "source": [
    "### 2ã€å¦‚ä½•ä½¿ç”¨ LangGraph å®šä¹‰æ™ºèƒ½ä½“ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186660d-0f16-449c-82b1-ee02cb95d07f",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šäº†è§£ LangGraph çš„æ‰§è¡Œé€»è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda0a46-ce13-4ce2-9a98-fb743118baaf",
   "metadata": {},
   "source": [
    "### 4ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•ç”¨ LangGraph å†ç°ã€Šæ‰‹æ’•AutoGPTã€‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed73748-3266-4a30-9468-f441ab10157c",
   "metadata": {},
   "source": [
    "éš¾ç‚¹ï¼š\n",
    "- å®˜æ–¹ä¾‹å­å’Œå†…ç½®æ™ºèƒ½ä½“æ— æ³•æ”¯æŒæµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf21ca-cf12-4cd3-a53c-f451ccafa852",
   "metadata": {},
   "source": [
    "# â¤ï¸ è¯¾ç¨‹ç»“æŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f9b10-8af0-4a42-80be-935f1fc6c853",
   "metadata": {},
   "source": [
    "## 1ã€è¯¾ç¨‹æ€»ç»“\n",
    "\n",
    "- æˆ‘ä»¬ä¸€èµ·é˜…è¯»äº†langchainçš„æºä»£ç ç»“æ„å’Œéƒ¨ä»½ç»†èŠ‚\n",
    "    - BaseLanguageModel / BaseChatModel / \n",
    "    - Runnable\n",
    "    - LambdaRunnable\n",
    "    - Chain\n",
    "    - AgentExcutor\n",
    "    - langgraph.prebuild\n",
    "- æˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•è‡ªå·±åŠ¨æ‰‹é›†æˆå¤§æ¨¡å‹åˆ° langchain ä¸­\n",
    "- æˆ‘ä»¬æ‹†è§£äº†langchainçš„åŸºçŸ³ç»„ä»¶ï¼šRunnable\n",
    "- æˆ‘ä»¬æ‹†è§£äº†langchainçš„æ ¸å¿ƒé€»è¾‘èƒ½åŠ›ï¼šLCEL\n",
    "- æˆ‘ä»¬æ‹†è§£äº†langchainçš„æœ€æ–°é€»è¾‘èƒ½åŠ›ï¼šlanggraph\n",
    "- æˆ‘ä»¬åŠ¨æ‰‹åšäº†ä¸€äº›ä»£ç å®è·µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454ac52-a105-45d0-b99e-aa8183cb5f29",
   "metadata": {},
   "source": [
    "## 2ã€æœ€åå»ºè®®\n",
    "\n",
    "- æŠ€æœ¯é€‰å‹æ—¶è¦å¯¹ Langchain æœ‰ç»å¯¹ä¿¡å¿ƒï¼ˆå‡ ä¹éƒ½ä¸ä¼šæ˜¯langchainçš„é”™ï¼‰\n",
    "- å†…ç½®é“¾å°½é‡ä½¿ç”¨LCELé“¾\n",
    "- å†…ç½®æ™ºèƒ½ä½“å°½é‡ä½¿ç”¨ Langgraph\n",
    "- è‡ªå®šä¹‰æ™ºèƒ½ä½“æ—¶ä½¿ç”¨ Langgraph\n",
    "- æ¨¡å—ä¼˜å…ˆåšæˆRunnableæˆ–LCELé“¾ï¼Œå…¶æ¬¡å†è€ƒè™‘Lambda\n",
    "- å·¥å…·ä¸­åŒ…å«å¤§æ¨¡å‹è°ƒç”¨æ—¶ä¼˜å…ˆåšæˆRunnableæˆ–LCELé“¾ï¼Œå…¶æ¬¡å†è€ƒè™‘invoke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473875b-dd97-48be-b285-dce1528a5b58",
   "metadata": {},
   "source": [
    "## 3ã€å½©è›‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a44e1a-5197-41d2-b6f8-669e59a6196e",
   "metadata": {},
   "source": [
    "### 1ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•åŒæ—¶ä½¿ç”¨langchainçš„è®°å¿†å’ŒæŒä¹…åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021d211-8b68-400e-976b-3250035a2e65",
   "metadata": {},
   "source": [
    "è¿™æ˜¯ langchain æ–‡æ¡£ä¸­ä¸€ä¸ªè‡ªç›¸çŸ›ç›¾çš„åœ°æ–¹ï¼Œç•™ç»™å¤§å®¶è¯¾åè®¨è®ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa187b9-3d0c-4981-873b-56704520af13",
   "metadata": {},
   "source": [
    "### 2ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•å°†è‡ªå·±è®­çš„å¤§æ¨¡å‹é›†æˆåˆ° langchain ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e01f4-4317-46d4-889c-fbc923a1ff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
