{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5b5362-cf90-4d8a-9c70-3db56e3f8dcc",
   "metadata": {},
   "source": [
    "# ğŸ¦œğŸ”— LangChainæ ¸å¿ƒæºä»£ç è§£è¯»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09652ad-45cf-4152-8794-2639a92a4ac2",
   "metadata": {},
   "source": [
    "# â¤ï¸ è¯¾ç¨‹å¼€å§‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac26c1-1878-43d9-984d-bebacabccefb",
   "metadata": {},
   "source": [
    "## è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb7b7a-d4a8-4e8d-b757-a55062c3fad8",
   "metadata": {},
   "source": [
    "1. ğŸŒ¹é˜…è¯» Langchain çš„å¤§æ¨¡å‹å®ç°æºç \n",
    "2. ğŸŒ¹é˜…è¯» Langchain çš„æ ¸å¿ƒç»„ä»¶æºç ï¼šRunnableåŠå…¶å­ç±»\n",
    "3. ğŸŒ¹é˜…è¯» LCEL çš„æ™ºèƒ½ä½“å®ç°æºç ï¼šcreate_react_agent\n",
    "4. ğŸŒ¹é˜…è¯» Langgraph çš„æ™ºèƒ½ä½“å®ç°æºç ï¼šprebuild\n",
    "5. âœï¸ åŠ¨æ‰‹é›†æˆè‡ªå·±çš„å¤§æ¨¡å‹åˆ° LangChainï¼šæ™ºè°±AI\n",
    "6. âœï¸ åŠ¨æ‰‹å®ç°åŸºäº LCEL çš„æ™ºèƒ½ä½“ï¼šå†ç°æ‰‹æ’•AutoGPT\n",
    "7. âœï¸ åŠ¨æ‰‹å®ç°åŸºäº Langgraph çš„æ™ºèƒ½ä½“ï¼šå†ç°æ‰‹æ’•AutoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d3fb7-9b0a-4592-ac64-ea74630e75be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>æ³¨æ„ï¼š</b><br>\n",
    "<ul>\n",
    "    <li>å¤§æ¨¡å‹è®¤çŸ¥ï¼šè¯·å‚è€ƒAGIè¯¾å ‚æ­£è¯¾ç›¸å…³ç« èŠ‚</li>\n",
    "    <li>Langchain åŸºç¡€ï¼šè¯·å‚è€ƒAGIè¯¾å ‚æ­£è¯¾ç›¸å…³ç« èŠ‚</li>\n",
    "    <li>çœ‹æ‡‚æºç æ˜¯ä¸ºäº†å†™å¥½ä»£ç </li>\n",
    "</ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff511b-10e1-43d4-92e0-829a1fe4d5d2",
   "metadata": {},
   "source": [
    "## å¦‚ä½•è§£è¯» Langchain çš„æºä»£ç ç»“æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac50aa-ed71-46ea-ac3c-e1af5abe5fc9",
   "metadata": {},
   "source": [
    "### 1ã€ä½ æœ‰å“ªäº›èµ„æºå¯ä»¥åˆ©ç”¨ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f539f3d-148f-4c18-a959-881dfc8ce4b7",
   "metadata": {},
   "source": [
    "![](./langchain_ai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbce31b-2fd4-43cd-8204-98fa50ae8bf5",
   "metadata": {},
   "source": [
    "ï¼ˆ1ï¼‰å­¦ä¹ èµ„æºï¼š\n",
    "- [langchainæºä»£ç ](https://github.com/langchain-ai/)ï¼šAll you need r here !!!\n",
    "- [langchainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs)ï¼šä¸æºä»£ç ç›¸äº’å°è¯\n",
    "- [langgraph example](https://github.com/langchain-ai/langgraph/tree/main/examples)ï¼šJupyter Notes\n",
    "\n",
    "ï¼ˆ2ï¼‰è‰¯å¸ˆç›Šå‹ï¼š\n",
    "- langchain [èŠå¤©](https://chat.langchain.com/?llm=anthropic_claude_2_1)ï¼šå…è´¹çš„å¤§æ¨¡å‹+RAGï¼ˆä¹Ÿå¯ä»¥å­¦ä¹ å…¶æºç ï¼‰\n",
    "- Github Copilotï¼šç¨‹åºå‘˜æ— æ³•ç¦»å¼€çš„å·¥å…·ï¼Œå°±åƒç°åœ¨çš„äººå¼€è½¦æ— æ³•ç¦»å¼€åœ°å›¾å¯¼èˆª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7f60d-7043-42e0-98c2-459355c52f19",
   "metadata": {},
   "source": [
    "### 2ã€ğŸŒ¹ é˜…è¯»æºç ï¼šLangChain æºä»£ç æ¦‚è§ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4481a6-d92d-4df6-8cfd-65e57c2463f5",
   "metadata": {},
   "source": [
    "[langchainæºä»£ç ç»“æ„](https://github.com/langchain-ai/langchain/tree/master/libs)\n",
    "\n",
    "| æºç ä½ç½® | åŠŸèƒ½æè¿° |\n",
    "| :--- | :--- |\n",
    "| langchain/libs/langchain | æ¨¡å—å…¥å£ï¼Œä¼šå¯¼å…¥coreã€communityç­‰å…¶ä»–æ¨¡å— |\n",
    "| langchain/libs/core | æ ¸å¿ƒç»„ä»¶å’Œå…³é”®çš„åŸºç±»å®ç° |\n",
    "| langchain/libs/partners | åˆä½œä¼™ä¼´ï¼ˆå®˜æ–¹åˆä½œï¼‰ç»„ä»¶ |\n",
    "| langchain/libs/community | ç¤¾åŒºï¼ˆéå®˜æ–¹ï¼‰ç»„ä»¶ |\n",
    "| langchain/libs/experimental | è¯•éªŒæ€§åŠŸèƒ½ï¼ˆå‰æ²¿æ¢ç´¢ç»„ä»¶ï¼Œä¸å¯¹ç‰ˆæœ¬ç¨³å®šåšæ‰¿è¯ºï¼‰ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01548080-b79b-4a88-9b9f-7af2ef9ae567",
   "metadata": {},
   "source": [
    "### 3ã€LangChainæ ¸å¿ƒæ¡†æ¶çš„ä¸‰è½®è¿­ä»£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc361bf-be03-4dbe-bf58-03f11e20fef8",
   "metadata": {},
   "source": [
    "- Runnable + Chain æ—¶ä»£\n",
    "- Runnable + LCEL æ—¶ä»£\n",
    "- Runnable + LCEL + Langgraph æ—¶ä»£"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936103d-a47c-4455-81ca-10a8cbb8449a",
   "metadata": {},
   "source": [
    "# â¤ï¸ ï¼ˆä¸€ï¼‰ä»é›¶å¼€å§‹é›†æˆå¤§æ¨¡å‹åˆ° Langchain å®ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4086972-8af4-41e8-9f1d-7d3a5e984bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a33f05-0ea9-427c-b851-6511e0b9fc29",
   "metadata": {},
   "source": [
    "## ä¸€èˆ¬ç”¨æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56f9e2e4-782e-466b-be9d-c23b0c30242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4db118-7b74-4d8e-8d9c-e8976ff4294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. å½©è™¹é“…ç¬”æœ‰é™å…¬å¸\n",
      "2. è‰²å½©åˆ›æ„é“…ç¬”å‚\n",
      "3. å½©ç»˜é“…ç¬”åˆ¶é€ å‚\n",
      "4. å½©è‰²æ¢¦æƒ³é“…ç¬”å…¬å¸\n",
      "5. ç»šä¸½è‰²å½©é“…ç¬”å‚å®¶\n",
      "6. å½©è‰²æ¶‚é¸¦é“…ç¬”å·¥ä½œå®¤\n",
      "7. èŠ±æ ·å½©è‰²é“…ç¬”åˆ¶é€ æœ‰é™å…¬å¸\n",
      "8. å½©ç»˜å¤©åœ°é“…ç¬”å‚\n",
      "9. è‰³ä¸½è‰²å½©é“…ç¬”ç”Ÿäº§å‚å®¶\n",
      "10. å½©è™¹è‰ºæœ¯é“…ç¬”å…¬å¸\n"
     ]
    }
   ],
   "source": [
    "# invoke\n",
    "text = \"è¯·å¸®æˆ‘æƒ³ä¸€æƒ³ï¼Œç”Ÿäº§å½©è‰²é“…ç¬”çš„å…¬å¸æœ‰ä»€ä¹ˆå¥½åå­—?\"\n",
    "response = llm.invoke(text)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ad948cb-8584-43f4-9dce-b008fa6cbc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| è‰²|å½©|ä¹|å›­|\n",
      "|2|.| å½©|è™¹|é“…|ç¬”|å‚|\n",
      "|3|.| å½©|è‰²|åˆ›|æ„|\n",
      "|4|.| |äº”|å½©|é“…|ç¬”|åŠ|\n",
      "|5|.| å½©|è‰²|ç¬”|ç”»|\n",
      "|6|.| è‰²|å½©|ä¸–|ç•Œ|\n",
      "|7|.| é­”|æ³•|å½©|é“…|\n",
      "|8|.| å½©|è‰²|ç¬”|å¢¨|\n",
      "|9|.| ç»š|ä¸½|é“…|ç¬”|å‚|\n",
      "|10|.| å½©|è™¹|è‰²|ç¬”||"
     ]
    }
   ],
   "source": [
    "# stream\n",
    "for chunk in llm.stream(text):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07938031-93ed-470e-9c15-b10f6aa0548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'è¯·å¸®æˆ‘æƒ³ä¸€æƒ³ï¼Œç”Ÿäº§å½©è‰²é“…ç¬”çš„å…¬å¸æœ‰ä»€ä¹ˆå¥½åå­—?'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"è¯·å¸®æˆ‘æƒ³ä¸€æƒ³ï¼Œç”Ÿäº§{product}çš„å…¬å¸æœ‰ä»€ä¹ˆå¥½åå­—?\")\n",
    "prompt.format(product=\"å½©è‰²é“…ç¬”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31baa2d4-10f8-4084-adef-67ed7746b996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| å½©|è™¹|é“…|ç¬”|æœ‰|é™|å…¬å¸|\n",
      "|2|.| å½©|è‰²|åˆ›|æ„|é“…|ç¬”|åˆ¶|é€ |å‚|\n",
      "|3|.| ç¼¤|çº·|å½©|é“…|ç¬”|æœ‰|é™|è´£|ä»»|å…¬å¸|\n",
      "|4|.| è‰²|å½©|ä¸–|ç•Œ|é“…|ç¬”|åˆ¶|é€ |æœ‰|é™|å…¬å¸|\n",
      "|5|.| æ¢¦|å¹»|è‰²|å½©|é“…|ç¬”|æœ‰|é™|å…¬å¸|\n",
      "|6|.| å½©|è‰²|åˆ›|æ„|é“…|ç¬”|å·¥|ä½œ|å®¤|\n",
      "|7|.| å½©|ç»˜|é“…|ç¬”|æœ‰|é™|å…¬å¸|\n",
      "|8|.| å½©|è‰²|è‰º|æœ¯|é“…|ç¬”|åˆ¶|é€ |å‚|\n",
      "|9|.| å½©|è‰²|åˆ›|æ„|é“…|ç¬”|æœ‰|é™|è´£|ä»»|å…¬å¸|\n",
      "|10|.| å½©|è‰²|ç¬”|å¢¨|æœ‰|é™|å…¬å¸||"
     ]
    }
   ],
   "source": [
    "# LCEL LLM+Prompt\n",
    "chain = prompt | llm\n",
    "for chunk in chain.stream({\"product\": \"å½©è‰²é“…ç¬”\"}):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32dea0d5-8c5c-436d-b006-67b07eceae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| å½©|è™¹|é“…|ç¬”|å·¥|åŠ|\n",
      "|2|.| è‰²|å½©|ä¸–|ç•Œ|é“…|ç¬”|å…¬å¸|\n",
      "|3|.| å½©|è‰²|åˆ›|æ„|é“…|ç¬”|å‚|\n",
      "|4|.| å½©|ç»˜|é“…|ç¬”|åˆ¶|é€ |å‚|\n",
      "|5|.| å½©|è‰²|ç¬”|èŠ¯|å·¥|è‰º|å‚|\n",
      "|6|.| å½©|é“…|ç¬”|åˆ›|æ„|å·¥|åŠ|\n",
      "|7|.| |äº”|å½©|é“…|ç¬”|åˆ¶|é€ |å…¬å¸|\n",
      "|8|.| å½©|è‰²|ç¬”|èŠ¯|åˆ›|æ„|å·¥|å‚|\n",
      "|9|.| ç»š|ä¸½|é“…|ç¬”|å·¥|è‰º|å‚|\n",
      "|10|.| å½©|è™¹|ç¬”|èŠ¯|åˆ¶|é€ |å‚||"
     ]
    }
   ],
   "source": [
    "# LCEL LLM+Prompt+Outputparser\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "for chunk in chain.stream({\"product\": \"å½©è‰²é“…ç¬”\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73527d37-fdb8-4d76-b70c-4ce1c209a3ed",
   "metadata": {},
   "source": [
    "## å®ç°ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032f3d3-43c6-46d3-8159-9baa9f16d384",
   "metadata": {},
   "source": [
    "### å®ç°ä¸€ä¸ªFakeå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52b2c9ba-39af-488b-af00-d272b7bff551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Dict, Iterator, List, Optional, Union\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, HumanMessageChunk, AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2ebdb44f-afd7-4ffc-9419-56e144a6d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeChatWithOlder(BaseChatModel):\n",
    "    \"\"\"æ¨¡æ‹Ÿè·Ÿå¤§çˆ·çš„å¯¹è¯\"\"\"\n",
    "\n",
    "    responses: List[BaseMessage]\n",
    "    sleep: Optional[float] = 0.1\n",
    "    i: int = 0\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        response = self.responses[self.i]\n",
    "        if self.i < len(self.responses) - 1:\n",
    "            self.i += 1\n",
    "        else:\n",
    "            self.i = 0\n",
    "        generation = ChatGeneration(message=response)\n",
    "        return ChatResult(generations=[generation])\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"fake-chat-with-older\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9fb12783-b794-4ce2-8ace-4bd781be835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "å¤æ´›ï¼šå¤§çˆ·ï¼Œæ¥¼ä¸Š322é©¬å†¬æ¢…åœ¨å®¶å—ï¼Ÿ\n",
      "å¤§çˆ·ï¼šé©¬ä»€ä¹ˆæ¢…ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…å•Š\n",
      "å¤§çˆ·ï¼šä»€ä¹ˆå†¬æ¢…ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬ä¸œä»€ä¹ˆï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šå¤§çˆ·æ‚¨æ­‡ç€å§...\n",
      "å¤§çˆ·ï¼šå¥½å’§|"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"å¤§çˆ·ï¼Œæ¥¼ä¸Š322é©¬å†¬æ¢…åœ¨å®¶å—ï¼Ÿ\",\n",
    "    \"é©¬å†¬æ¢…å•Š\",\n",
    "    \"é©¬å†¬æ¢…ï¼\",\n",
    "    \"å¤§çˆ·æ‚¨æ­‡ç€å§...\"\n",
    "]\n",
    "\n",
    "reply = [AIMessage(m) for m in [\n",
    "    \"é©¬ä»€ä¹ˆæ¢…ï¼Ÿ\",\n",
    "    \"ä»€ä¹ˆå†¬æ¢…ï¼Ÿ\",\n",
    "    \"é©¬ä¸œä»€ä¹ˆï¼Ÿ\",\n",
    "    \"å¥½å’§\"\n",
    "]]\n",
    "\n",
    "llm_fake = FakeChatWithOlder(responses=reply)\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    # print(llm_fake.invoke(question).content, end=\"\")\n",
    "    for chunk in llm_fake.stream(question):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8231e5a-c8b9-4d8e-8e56-280ccc889fd7",
   "metadata": {},
   "source": [
    "### æ”¯æŒæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fe2633f0-9002-4684-818a-44daed91c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeStreamChatWithOlder(FakeChatWithOlder):\n",
    "    \"\"\"æ¨¡æ‹Ÿè·Ÿå¤§çˆ·çš„å¯¹è¯ï¼Œæ”¯æŒæµ\"\"\"\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Union[List[str], None] = None,\n",
    "        run_manager: Union[CallbackManagerForLLMRun, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        response = self.responses[self.i]\n",
    "        if self.i < len(self.responses) - 1:\n",
    "            self.i += 1\n",
    "        else:\n",
    "            self.i = 0\n",
    "        for chunk in response.content:\n",
    "            if self.sleep is not None:\n",
    "                time.sleep(self.sleep)\n",
    "            yield ChatGenerationChunk(message=AIMessageChunk(content=chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "236c1cf8-0886-423f-9710-cd10ef7c6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "å¤æ´›ï¼šå¤§çˆ·ï¼Œæ¥¼ä¸Š322é©¬å†¬æ¢…åœ¨å®¶å—ï¼Ÿ\n",
      "å¤§çˆ·ï¼šé©¬|ä»€|ä¹ˆ|æ¢…|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…å•Š\n",
      "å¤§çˆ·ï¼šä»€|ä¹ˆ|å†¬|æ¢…|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šé©¬å†¬æ¢…ï¼\n",
      "å¤§çˆ·ï¼šé©¬|ä¸œ|ä»€|ä¹ˆ|ï¼Ÿ|\n",
      "\n",
      "å¤æ´›ï¼šå¤§çˆ·æ‚¨æ­‡ç€å§...\n",
      "å¤§çˆ·ï¼šå¥½|å’§|"
     ]
    }
   ],
   "source": [
    "llm_fake = FakeStreamChatWithOlder(responses=reply)\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    for chunk in llm_fake.stream(question):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47508d-76d7-4c2f-8156-503821e5ff06",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ çœ‹æºç "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87a1e7-cd8d-495b-8aa0-6342a30135ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0291149-5421-4846-92f6-d2367383c5c8",
   "metadata": {},
   "source": [
    "### Langchainæ”¯æŒçš„å¤§æ¨¡å‹\n",
    "- ChatOpenAI\n",
    "- FakeLLM\n",
    "\n",
    "### ä¸€èˆ¬ç”¨æ³•\n",
    "\n",
    "- invoke\n",
    "- stream\n",
    "- create_qa_chain\n",
    "- create_openai_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2e199-6d19-47db-888d-ea07303af597",
   "metadata": {},
   "source": [
    "## ç‰ˆæœ¬1\n",
    "\n",
    "### çœ‹çœ‹æ™ºè°±å®˜æ–¹çš„ç®€å•ä¾‹å­\n",
    "### Langchain ç›¸å…³åº“æºç \n",
    "### å†™ä¸€ä¸ªç®€å•çš„ Langchain ç‰ˆæœ¬\n",
    "### åœ¨LCELä¸­ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b0bf2-030c-40e3-8702-153cddd37031",
   "metadata": {},
   "source": [
    "## ç‰ˆæœ¬2\n",
    "\n",
    "### è¯•è¯•æµï¼šæš‚æ—¶ä¸æ”¯æŒ\n",
    "### çœ‹çœ‹æ™ºè°±å®˜æ–¹å¯¹æµçš„æ”¯æŒ\n",
    "### çœ‹çœ‹æµçš„é»˜è®¤å®ç°æºç \n",
    "### è®©æˆ‘ä»¬ä¹Ÿæ”¯æŒæµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e820d-46fc-4bcb-8264-ce0c34e416b4",
   "metadata": {},
   "source": [
    "## ç‰ˆæœ¬3\n",
    "\n",
    "### è¯•è¯•å·¥å…·ï¼šæš‚æ—¶ä¸æ”¯æŒ\n",
    "### çœ‹çœ‹æ™ºè°±å®˜æ–¹å¯¹å·¥å…·å›è°ƒçš„æ”¯æŒ\n",
    "### å›é¡¾å·¥å…·å›è°ƒï¼šåªæ˜¯ä¸€ç§æ¶ˆæ¯æ ¼å¼\n",
    "### çœ‹çœ‹ openai å®ç°æºç \n",
    "### è®©æˆ‘ä»¬ä¹Ÿæ”¯æŒå·¥å…·å›è°ƒ\n",
    "### åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨\n",
    "### å®Œæ•´ä»£ç è¯·å‚è€ƒ langchain_zhipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c36b2-6d05-4e49-bbd5-34d231c08ae1",
   "metadata": {},
   "source": [
    "## 1ã€âœï¸ ä»£ç å‡†å¤‡ï¼šlangchainä¸­çš„LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d17151-50f4-4d7c-97a6-6df12706b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM invoke\n",
    "# OpenAI\n",
    "\n",
    "# LLM stream\n",
    "# OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8b752-1a25-4bb9-844e-e92308966b51",
   "metadata": {},
   "source": [
    "### 2ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•å®ç°ä¸€ä¸ªFakeLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7f2b17-1585-4fe5-bfce-65ff0d9d28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é©¬å†¬æ¢…æ¥¼ä¸‹è€å¤§çˆ·"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68825344-97a0-4b23-b27b-d7aea3019cad",
   "metadata": {},
   "source": [
    "[å·²ç»å®ç°çš„FakeLLM](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/fake.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b74ef-7182-4c5a-a185-371b9266b90f",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šé›†æˆè‡ªå·±çš„å¤§æ¨¡å‹éœ€è¦å¦‚ä½•ä¸‹æ‰‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43dc22-57e1-4ed3-be18-f3f5f2ad60c8",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰BaseLanguageModel\n",
    "\n",
    "æ¥è‡ªï¼š[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/base.py#L74-L81)\n",
    "\n",
    "```python\n",
    "class BaseLanguageModel(\n",
    "    RunnableSerializable[LanguageModelInput, LanguageModelOutputVar], ABC\n",
    "):\n",
    "    \"\"\"Abstract base class for interfacing with language models.\n",
    "\n",
    "\n",
    "    All language model wrappers inherit from BaseLanguageModel.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca17ee1-fba0-4417-ab32-4cb100bf2156",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰BaseChatModel\n",
    "\n",
    "æ¥è‡ªï¼š[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/chat_models.py#L100)\n",
    "\n",
    "```python\n",
    "class BaseChatModel(BaseLanguageModel[BaseMessage], ABC):\n",
    "    \"\"\"Base class for Chat models.\"\"\"\n",
    "\n",
    "    ...\n",
    "\n",
    "    def invoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.generate_prompt(...)\n",
    "        # generate_prompt >> generate >> _generate\n",
    "\n",
    "    def ainvoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.agenerate_prompt(...)\n",
    "        # agenerate_prompt >> agenerate >> _agenerate >> _generate\n",
    "    \n",
    "    def stream(...) -> Iterator[BaseMessageChunk]:\n",
    "        # ...\n",
    "        if type(self)._stream == BaseChatModel._stream:\n",
    "            # model doesn't implement streaming, so use default implementation\n",
    "            yield cast(\n",
    "                BaseMessageChunk, self.invoke(input, config=config, stop=stop, **kwargs)\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    async def astream(...) -> AsyncIterator[BaseMessageChunk]:\n",
    "        # ...\n",
    "        if (\n",
    "            type(self)._astream is BaseChatModel._astream\n",
    "            and type(self)._stream is BaseChatModel._stream\n",
    "        ):\n",
    "            # No async or sync stream is implemented, so fall back to ainvoke\n",
    "            yield cast(\n",
    "                BaseMessageChunk,\n",
    "                await self.ainvoke(input, config=config, stop=stop, **kwargs),\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    ## ï¼ï¼å¿…é¡»å®ç° \n",
    "    @abstractmethod\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"Top Level call\"\"\"\n",
    "\n",
    "    ## ï¼ï¼å»ºè®®å®ç° \n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def _astream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterator[ChatGenerationChunk]:\n",
    "    # ...\n",
    "    self._stream(...)\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e1905-cbbe-4339-bf5b-9ff81836a756",
   "metadata": {},
   "source": [
    "### 4ã€âœï¸ ä»£ç å®è·µï¼šä¸€æ­¥æ­¥é›†æˆæ™ºè°±AIå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fdcc70-1271-4e35-8e06-9d8ae37f48ea",
   "metadata": {},
   "source": [
    "- æ”¯æŒ invoke\n",
    "- æ”¯æŒ stream\n",
    "- æ”¯æŒ tools-calling\n",
    "\n",
    "- å®Œæ•´å®ç°ï¼š[langchain_zhipu](https://github.com/arcstep/langchain_zhipu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c0a94-ec25-4bec-bdff-93acc9e025bf",
   "metadata": {},
   "source": [
    "# â¤ï¸ï¼ˆäºŒï¼‰LLMè¾“å…¥è¾“å‡ºï¼šå…¨é¢æ‹†è§£ Runnable ç»“æ„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4800b-4b93-4a89-8040-397b53c402dc",
   "metadata": {},
   "source": [
    "### 1ã€å¤§æ¨¡å‹è°ƒç”¨è¿‡ç¨‹ä¸­å‘ç”Ÿçš„æ•°æ®æµè½¬æ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077bf62-1adb-4e92-b2fe-80cbb5265342",
   "metadata": {},
   "source": [
    "- ä»è®­è¿‡çš„æ¨¡å‹è¯´èµ·ï¼šè®­ç»ƒé¢„æ–™å’Œé¢„æµ‹æ–‡æœ¬é£æ ¼ï¼ˆ|<assistent>| xxxxxx |</assistent>|)\n",
    "- ä½œä¸ºAPIæä¾›ï¼šopenAIé£æ ¼\n",
    "- ä»æç¤ºè¯­åˆ°langchainæ¶ˆæ¯ï¼šBaseMessages\n",
    "- ä»langchainæ¶ˆæ¯åˆ°å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼šBaseChatModel\n",
    "- ä»å¤§æ¨¡å‹ç»“æœåˆ°langchainæ¶ˆæ¯ï¼šBaseMessages\n",
    "- ä»langchainæ¶ˆæ¯åˆ°è¾“å‡ºè§£æå™¨ï¼šOutpurParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a6a02-27aa-4996-81ff-0c27da433aef",
   "metadata": {},
   "source": [
    "### 2ã€å¦‚æœåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ç»Ÿä¸€å„æ¨¡å—æ ‡å‡†ï¼Œéšæ—¶æ›´æ¢ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d13c5-663b-440c-92fd-9d1c51eb630d",
   "metadata": {},
   "source": [
    "### 3ã€å¦‚æœåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ä½¿ç”¨æµã€å¼‚æ­¥ã€æ‰¹é‡ã€äº‹ä»¶æµ ... ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09417b7-12b2-4998-8d89-d5695140a5fa",
   "metadata": {},
   "source": [
    "### 4ã€è¿™ä¸ªè¿‡ç¨‹ä¸­çš„ç¼“å­˜ã€é‡è¯•ã€é…ç½® ... ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee06284-0b63-4231-9aa7-a9dced804e0e",
   "metadata": {},
   "source": [
    "### 1ã€ä¸ºä»€ä¹ˆè¯´å¯ä»¥ç”¨ Runnable ç»„ä»¶åœ¨ç”Ÿäº§ç³»ç»Ÿä¸­æ­ç§¯æœ¨ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918dc61-89d0-47c0-877b-2489dcb44b47",
   "metadata": {},
   "source": [
    "- Runnableæ¥å£æ ‡å‡†åŒ–çš„ä»·å€¼\n",
    "    - æ›¿æ¢å¤§æ¨¡å‹ï¼šä»GPTåˆ°å›½äº§äº‘æ¨¡å‹ã€åˆ°å¼€æºè‡ªè®­æ¨¡å‹çš„å¤šå±‚æ¬¡å°è¯•å’Œè½åœ°æ˜¯å¿…è¦çš„\n",
    "    - æ›¿æ¢è°ƒç”¨æ–¹å¼ï¼šæ»¡è¶³ä¸šåŠ¡éªŒè¯ã€ç”Ÿäº§ä¸Šçº¿ã€ä¸šåŠ¡æ‰©å®¹ç­‰å¤šåœºæ™¯\n",
    "    - æ›¿æ¢æç¤ºè¯­æ¨¡æ¿ï¼šé€‚åº”æŠ€æœ¯ç ”ç©¶ã€ä¸šåŠ¡å®šåˆ¶ã€è¿è¥ä¼˜åŒ–ç­‰å¤šé˜¶æ®µ\n",
    "    - æ›¿æ¢è§£æå™¨ï¼šé€‚åº”æ¨¡å—è°ƒç”¨ã€APIè°ƒç”¨ç­‰å¤šåè®®å¯¹æ¥\n",
    "    - æ›¿æ¢å›è°ƒé›†æˆï¼šlangsmithã€langfuseäº‘ã€langfuseæœ¬åœ°åŒ–ã€è‡ªå»ºè¿ç»´ç³»ç»Ÿ\n",
    "    - æ›¿æ¢å‘é‡æ•°æ®åº“ï¼šé€‚åº”ä¸åŒåœºæ™¯ã€é˜¶æ®µçš„æŠ€æœ¯é€‰å‹è°ƒæ•´\n",
    "    - æ›¿æ¢æŒä¹…åŒ–ï¼š...\n",
    "    - æ›¿æ¢æ™ºèƒ½ä½“ï¼š..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233dae74-6f40-4195-a825-cde34826bd07",
   "metadata": {},
   "source": [
    "### 2ã€ğŸŒ¹ é˜…è¯»æºç ï¼šRunnable ç»„ä»¶8ä¸ªæ–¹æ³•çš„å®ç°é€»è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5002f62-1c47-4157-9485-eaa10314a517",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šRunnable ç»„ä»¶é…ç½®è‡ªä¸¾èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d9e06-606f-4f72-b9fe-8ec9530eed05",
   "metadata": {},
   "source": [
    "- äº†è§£Runnable ç»„ä»¶çš„ 8 ä¸ªæ–¹æ³•çš„é»˜è®¤å®ç°\n",
    "- è‡ªå®šä¹‰Runnableï¼ˆå¿…è¦å®ç°ä¸€èˆ¬æ˜¯invoke / stream / astreamï¼Œæˆ–å¯¹åº”çš„å†…éƒ¨å‡½æ•°ï¼‰\n",
    "- invokeï¼šæ ‡å‡†åŒ–è°ƒåº¦\n",
    "- batch: æ ‡å‡†åŒ–æ‰¹é‡è°ƒåº¦\n",
    "- streamï¼šæ ‡å‡†åŒ–æµå¼è¾“å‡º\n",
    "- ainvoke / astream / abatch: æ ‡å‡†åŒ–å¼‚æ­¥è°ƒåº¦\n",
    "- astream_log / astream_events: åœ¨é“¾ã€æ™ºèƒ½ä½“ã€langgraphç­‰è¾“å‡ºä¸­æŒ‰ç…§namesã€tagsã€eventsæå–æµå¼æ—¥å¿—\n",
    "- configï¼šç»Ÿä¸€ç®¡ç†é…ç½®\n",
    "- schemaï¼šç»Ÿä¸€æ¢æŸ¥å‚æ•°å’Œé…ç½®\n",
    "\n",
    "- åºåˆ—åŒ–\n",
    "\n",
    "- é…ç½®è‡ªä¸¾ï¼šåœ¨å¼€æ”¾å¼åº”ç”¨ä¸­æ”¯æŒå®¢æˆ·ç«¯è‡ªåŠ¨è¯†åˆ«è‡ªå®šä¹‰æœåŠ¡\n",
    "- å®¹é”™ï¼šæ ‡å‡†åŒ–é‡è¯•ç­–ç•¥\n",
    "- ä¸langserveç­‰apiæ¡†æ¶æ ‡å‡†åŒ–å¯¹æ¥\n",
    "- ä¸langfuseç­‰callbckæ¡†æ¶æ ‡å‡†åŒ–å¯¹æ¥\n",
    "- ä¸langchainjsç­‰å¼‚æ„å®ç°æ ‡å‡†åŒ–å¯¹æ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a62f75-52bd-462b-a396-8fb9751fc84a",
   "metadata": {},
   "source": [
    "### 4ã€ğŸŒ¹ é˜…è¯»æºç ï¼šé—ç•™çš„ Chain æ˜¯ä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f68e5-b811-4854-af6f-7a8ded1ba8bd",
   "metadata": {},
   "source": [
    "- langchainä¸­æå‰å†™å¥½çš„Chainèµ„æº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3fa84-035e-4eb5-be59-4c3a902fea45",
   "metadata": {},
   "source": [
    "- è¿™äº› Chain å±€é™æ€§åœ¨ç©¶ç«Ÿå“ªé‡Œï¼Ÿ\n",
    "    - æµç¨‹ä¸çµæ´»\n",
    "    - æ”¯æŒæµå¼è¾“å‡ºä¸å½»åº•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0ddb0-134d-4641-ad0f-994df1e945b5",
   "metadata": {},
   "source": [
    "### 5ã€âœï¸ ä»£ç å®è·µï¼šè‹¥å¹²ç§æƒ…å†µä¸‹çš„æµè¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b85a1-eda7-4c3c-80af-0a125e5b4fee",
   "metadata": {},
   "source": [
    "# â¤ï¸ ç¬¬ 2 éƒ¨ä»½ï¼šAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64598d5-cdac-4a60-96d9-52b44730d6a2",
   "metadata": {},
   "source": [
    "# â¤ï¸ï¼ˆä¸‰ï¼‰ç”±LCELå®ç°æ™ºèƒ½ä½“ï¼šå…¨é¢æ‹†è§£ LCEL èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af86c4c-549a-4eb6-9ddc-f07314e393aa",
   "metadata": {},
   "source": [
    "### 1ã€LCEL æ¯” é—ç•™ Chain å¤šå“ªäº›ä¼˜åŠ¿ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76adf428-cdd4-4aa8-ac8b-3a3648ae7ead",
   "metadata": {},
   "source": [
    "- LCEL æ„å»ºçš„æ›¿ä»£ Chain\n",
    "- äº†è§£æ”¯æ’‘LCELçš„Runnableç»„ä»¶\n",
    "    - Lambda\n",
    "    - è¿­ä»£å™¨\n",
    "    - å­—å…¸å’Œå¹¶è¡Œ\n",
    "    - è·¯ç”±\n",
    "    - æ¡ä»¶\n",
    "    - è¿­ä»£æ‰§è¡Œ\n",
    "    - ç»‘å®š\n",
    "    - ç»˜å›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9e9ba-3388-40f2-a8f0-38ea7b7b2efd",
   "metadata": {},
   "source": [
    "### 2ã€å¦‚ä½•ç”¨ LCEL å®šä¹‰æ™ºèƒ½ä½“ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bd7d1-572a-447b-89b6-528b45258be9",
   "metadata": {},
   "source": [
    "- å·¥å…·ï¼šå®šä¹‰ä¸€ä¸ªç®€å•å·¥å…·\n",
    "- æ™ºèƒ½ä½“ï¼š\n",
    "    - Tools-Calling æ™ºèƒ½ä½“\n",
    "    - ReAct æ™ºèƒ½ä½“\n",
    "- æ‰§è¡Œå™¨ï¼šAgentExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d886c2-abec-4423-8742-068d144e66d3",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šäº†è§£ create_react_agent çš„è®¾è®¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad31612-b006-4803-96a9-6bb824b1c25a",
   "metadata": {},
   "source": [
    "- ä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“éœ€æ±‚ï¼šä¸AIç©ä¸€ä¸ªæ‰è¿·è—æ¸¸æˆ\n",
    "- reactæ™ºèƒ½ä½“çš„promptå¦‚ä½•å·¥ä½œ\n",
    "- ä¸­é—´æ­¥éª¤çš„ä¸€æ­¥æ­¥äº§ç”Ÿè¿‡ç¨‹\n",
    "- actionå¦‚ä½•è§£æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0378cc-4936-4ce2-abc6-9a7deebfa4c1",
   "metadata": {},
   "source": [
    "### 4ã€ğŸŒ¹ é˜…è¯»æºç ï¼šäº†è§£ AgentExecutor çš„æ‰§è¡Œé€»è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243379b-0e24-42ce-9087-239608bf5882",
   "metadata": {},
   "source": [
    "### 4ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•ç”¨ AgentExcutor å†ç°ã€Šæ‰‹æ’•AutoGPTã€‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba7531-66a6-4fda-81dc-03a87a2a637f",
   "metadata": {},
   "source": [
    "éš¾ç‚¹ï¼š\n",
    "- å®˜æ–¹ä¾‹å­å’Œå†…ç½®æ™ºèƒ½ä½“æ— æ³•æ”¯æŒpydanticå‚æ•°è§£æï¼ˆæ™ºè°±AIç­‰æ¨ç†èƒ½åŠ›è¾ƒå¼±çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702bd5b7-8aeb-4d5a-bd14-dfe0cc39e238",
   "metadata": {},
   "source": [
    "# â¤ï¸ï¼ˆå››ï¼‰ç”±LangGraphå®ç°æ™ºèƒ½ä½“ï¼šå…¨é¢æ‹†è§£ LangGraph èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b530de-c32e-4de7-a53d-2a7403ae881e",
   "metadata": {},
   "source": [
    "### 1ã€LangGraph æ¯” LCEL å¤šäº†ä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28481dec-c573-4c30-ba7d-a557702475ee",
   "metadata": {},
   "source": [
    "### 2ã€å¦‚ä½•ä½¿ç”¨ LangGraph å®šä¹‰æ™ºèƒ½ä½“ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186660d-0f16-449c-82b1-ee02cb95d07f",
   "metadata": {},
   "source": [
    "### 3ã€ğŸŒ¹ é˜…è¯»æºç ï¼šäº†è§£ LangGraph çš„æ‰§è¡Œé€»è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda0a46-ce13-4ce2-9a98-fb743118baaf",
   "metadata": {},
   "source": [
    "### 4ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•ç”¨ LangGraph å†ç°ã€Šæ‰‹æ’•AutoGPTã€‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed73748-3266-4a30-9468-f441ab10157c",
   "metadata": {},
   "source": [
    "éš¾ç‚¹ï¼š\n",
    "- å®˜æ–¹ä¾‹å­å’Œå†…ç½®æ™ºèƒ½ä½“æ— æ³•æ”¯æŒæµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf21ca-cf12-4cd3-a53c-f451ccafa852",
   "metadata": {},
   "source": [
    "# â¤ï¸ è¯¾ç¨‹ç»“æŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f9b10-8af0-4a42-80be-935f1fc6c853",
   "metadata": {},
   "source": [
    "## 1ã€è¯¾ç¨‹æ€»ç»“\n",
    "\n",
    "- æˆ‘ä»¬ä¸€èµ·é˜…è¯»äº†langchainçš„æºä»£ç ç»“æ„å’Œéƒ¨ä»½ç»†èŠ‚\n",
    "    - BaseLanguageModel / BaseChatModel / \n",
    "    - Runnable\n",
    "    - LambdaRunnable\n",
    "    - Chain\n",
    "    - AgentExcutor\n",
    "    - langgraph.prebuild\n",
    "- æˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•è‡ªå·±åŠ¨æ‰‹é›†æˆå¤§æ¨¡å‹åˆ° langchain ä¸­\n",
    "- æˆ‘ä»¬æ‹†è§£äº†langchainçš„åŸºçŸ³ç»„ä»¶ï¼šRunnable\n",
    "- æˆ‘ä»¬æ‹†è§£äº†langchainçš„æ ¸å¿ƒé€»è¾‘èƒ½åŠ›ï¼šLCEL\n",
    "- æˆ‘ä»¬æ‹†è§£äº†langchainçš„æœ€æ–°é€»è¾‘èƒ½åŠ›ï¼šlanggraph\n",
    "- æˆ‘ä»¬åŠ¨æ‰‹åšäº†ä¸€äº›ä»£ç å®è·µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454ac52-a105-45d0-b99e-aa8183cb5f29",
   "metadata": {},
   "source": [
    "## 2ã€æœ€åå»ºè®®\n",
    "\n",
    "- æŠ€æœ¯é€‰å‹æ—¶è¦å¯¹ Langchain æœ‰ç»å¯¹ä¿¡å¿ƒï¼ˆå‡ ä¹éƒ½ä¸ä¼šæ˜¯langchainçš„é”™ï¼‰\n",
    "- å†…ç½®é“¾å°½é‡ä½¿ç”¨LCELé“¾\n",
    "- å†…ç½®æ™ºèƒ½ä½“å°½é‡ä½¿ç”¨ Langgraph\n",
    "- è‡ªå®šä¹‰æ™ºèƒ½ä½“æ—¶ä½¿ç”¨ Langgraph\n",
    "- æ¨¡å—ä¼˜å…ˆåšæˆRunnableæˆ–LCELé“¾ï¼Œå…¶æ¬¡å†è€ƒè™‘Lambda\n",
    "- å·¥å…·ä¸­åŒ…å«å¤§æ¨¡å‹è°ƒç”¨æ—¶ä¼˜å…ˆåšæˆRunnableæˆ–LCELé“¾ï¼Œå…¶æ¬¡å†è€ƒè™‘invoke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473875b-dd97-48be-b285-dce1528a5b58",
   "metadata": {},
   "source": [
    "## 3ã€å½©è›‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a44e1a-5197-41d2-b6f8-669e59a6196e",
   "metadata": {},
   "source": [
    "### 1ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•åŒæ—¶ä½¿ç”¨langchainçš„è®°å¿†å’ŒæŒä¹…åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021d211-8b68-400e-976b-3250035a2e65",
   "metadata": {},
   "source": [
    "è¿™æ˜¯ langchain æ–‡æ¡£ä¸­ä¸€ä¸ªè‡ªç›¸çŸ›ç›¾çš„åœ°æ–¹ï¼Œç•™ç»™å¤§å®¶è¯¾åè®¨è®ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa187b9-3d0c-4981-873b-56704520af13",
   "metadata": {},
   "source": [
    "### 2ã€âœï¸ ä»£ç å®è·µï¼šå¦‚ä½•å°†è‡ªå·±è®­çš„å¤§æ¨¡å‹é›†æˆåˆ° langchain ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e01f4-4317-46d4-889c-fbc923a1ff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
