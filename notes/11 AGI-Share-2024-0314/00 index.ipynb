{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5b5362-cf90-4d8a-9c70-3db56e3f8dcc",
   "metadata": {},
   "source": [
    "# 🦜🔗 LangChain核心源代码解读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09652ad-45cf-4152-8794-2639a92a4ac2",
   "metadata": {},
   "source": [
    "# ❤️ 课程开始"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac26c1-1878-43d9-984d-bebacabccefb",
   "metadata": {},
   "source": [
    "## 这节课会带给你"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb7b7a-d4a8-4e8d-b757-a55062c3fad8",
   "metadata": {},
   "source": [
    "1. 🌹阅读 Langchain 的大模型实现源码\n",
    "2. 🌹阅读 Langchain 的核心组件源码：Runnable及其子类\n",
    "3. 🌹阅读 LCEL 的智能体实现源码：create_react_agent\n",
    "4. 🌹阅读 Langgraph 的智能体实现源码：prebuild\n",
    "5. ✍️ 动手集成自己的大模型到 LangChain：智谱AI\n",
    "6. ✍️ 动手实现基于 LCEL 的智能体：再现手撕AutoGPT\n",
    "7. ✍️ 动手实现基于 Langgraph 的智能体：再现手撕AutoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d3fb7-9b0a-4592-ac64-ea74630e75be",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b><br>\n",
    "<ul>\n",
    "    <li>大模型认知：请参考AGI课堂正课相关章节</li>\n",
    "    <li>Langchain 基础：请参考AGI课堂正课相关章节</li>\n",
    "    <li>看懂源码是为了写好代码</li>\n",
    "</ul> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff511b-10e1-43d4-92e0-829a1fe4d5d2",
   "metadata": {},
   "source": [
    "## 如何解读 Langchain 的源代码结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac50aa-ed71-46ea-ac3c-e1af5abe5fc9",
   "metadata": {},
   "source": [
    "### 1、你有哪些资源可以利用？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f539f3d-148f-4c18-a959-881dfc8ce4b7",
   "metadata": {},
   "source": [
    "![](./langchain_ai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbce31b-2fd4-43cd-8204-98fa50ae8bf5",
   "metadata": {},
   "source": [
    "（1）学习资源：\n",
    "- [langchain源代码](https://github.com/langchain-ai/)：All you need r here !!!\n",
    "- [langchain官方文档](https://python.langchain.com/docs)：与源代码相互印证\n",
    "- [langgraph example](https://github.com/langchain-ai/langgraph/tree/main/examples)：Jupyter Notes\n",
    "\n",
    "（2）良师益友：\n",
    "- langchain [聊天](https://chat.langchain.com/?llm=anthropic_claude_2_1)：免费的大模型+RAG（也可以学习其源码）\n",
    "- Github Copilot：程序员无法离开的工具，就像现在的人开车无法离开地图导航"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7f60d-7043-42e0-98c2-459355c52f19",
   "metadata": {},
   "source": [
    "### 2、🌹 阅读源码：LangChain 源代码概览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4481a6-d92d-4df6-8cfd-65e57c2463f5",
   "metadata": {},
   "source": [
    "[langchain源代码结构](https://github.com/langchain-ai/langchain/tree/master/libs)\n",
    "\n",
    "| 源码位置 | 功能描述 |\n",
    "| :--- | :--- |\n",
    "| langchain/libs/langchain | 模块入口，会导入core、community等其他模块 |\n",
    "| langchain/libs/core | 核心组件和关键的基类实现 |\n",
    "| langchain/libs/partners | 合作伙伴（官方合作）组件 |\n",
    "| langchain/libs/community | 社区（非官方）组件 |\n",
    "| langchain/libs/experimental | 试验性功能（前沿探索组件，不对版本稳定做承诺） |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01548080-b79b-4a88-9b9f-7af2ef9ae567",
   "metadata": {},
   "source": [
    "### 3、LangChain核心框架的三轮迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc361bf-be03-4dbe-bf58-03f11e20fef8",
   "metadata": {},
   "source": [
    "- Runnable + Chain 时代\n",
    "- Runnable + LCEL 时代\n",
    "- Runnable + LCEL + Langgraph 时代"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936103d-a47c-4455-81ca-10a8cbb8449a",
   "metadata": {},
   "source": [
    "# ❤️ （一）从零开始集成大模型到 Langchain 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4086972-8af4-41e8-9f1d-7d3a5e984bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载 .env 到环境变量\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a33f05-0ea9-427c-b851-6511e0b9fc29",
   "metadata": {},
   "source": [
    "## 一般用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56f9e2e4-782e-466b-be9d-c23b0c30242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4db118-7b74-4d8e-8d9c-e8976ff4294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 彩虹铅笔有限公司\n",
      "2. 色彩创意铅笔厂\n",
      "3. 彩绘铅笔制造厂\n",
      "4. 彩色梦想铅笔公司\n",
      "5. 绚丽色彩铅笔厂家\n",
      "6. 彩色涂鸦铅笔工作室\n",
      "7. 花样彩色铅笔制造有限公司\n",
      "8. 彩绘天地铅笔厂\n",
      "9. 艳丽色彩铅笔生产厂家\n",
      "10. 彩虹艺术铅笔公司\n"
     ]
    }
   ],
   "source": [
    "# invoke\n",
    "text = \"请帮我想一想，生产彩色铅笔的公司有什么好名字?\"\n",
    "response = llm.invoke(text)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ad948cb-8584-43f4-9dce-b008fa6cbc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| 色|彩|乐|园|\n",
      "|2|.| 彩|虹|铅|笔|厂|\n",
      "|3|.| 彩|色|创|意|\n",
      "|4|.| |五|彩|铅|笔|坊|\n",
      "|5|.| 彩|色|笔|画|\n",
      "|6|.| 色|彩|世|界|\n",
      "|7|.| 魔|法|彩|铅|\n",
      "|8|.| 彩|色|笔|墨|\n",
      "|9|.| 绚|丽|铅|笔|厂|\n",
      "|10|.| 彩|虹|色|笔||"
     ]
    }
   ],
   "source": [
    "# stream\n",
    "for chunk in llm.stream(text):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07938031-93ed-470e-9c15-b10f6aa0548e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'请帮我想一想，生产彩色铅笔的公司有什么好名字?'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"请帮我想一想，生产{product}的公司有什么好名字?\")\n",
    "prompt.format(product=\"彩色铅笔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31baa2d4-10f8-4084-adef-67ed7746b996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| 彩|虹|铅|笔|有|限|公司|\n",
      "|2|.| 彩|色|创|意|铅|笔|制|造|厂|\n",
      "|3|.| 缤|纷|彩|铅|笔|有|限|责|任|公司|\n",
      "|4|.| 色|彩|世|界|铅|笔|制|造|有|限|公司|\n",
      "|5|.| 梦|幻|色|彩|铅|笔|有|限|公司|\n",
      "|6|.| 彩|色|创|意|铅|笔|工|作|室|\n",
      "|7|.| 彩|绘|铅|笔|有|限|公司|\n",
      "|8|.| 彩|色|艺|术|铅|笔|制|造|厂|\n",
      "|9|.| 彩|色|创|意|铅|笔|有|限|责|任|公司|\n",
      "|10|.| 彩|色|笔|墨|有|限|公司||"
     ]
    }
   ],
   "source": [
    "# LCEL LLM+Prompt\n",
    "chain = prompt | llm\n",
    "for chunk in chain.stream({\"product\": \"彩色铅笔\"}):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32dea0d5-8c5c-436d-b006-67b07eceae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1|.| 彩|虹|铅|笔|工|坊|\n",
      "|2|.| 色|彩|世|界|铅|笔|公司|\n",
      "|3|.| 彩|色|创|意|铅|笔|厂|\n",
      "|4|.| 彩|绘|铅|笔|制|造|厂|\n",
      "|5|.| 彩|色|笔|芯|工|艺|厂|\n",
      "|6|.| 彩|铅|笔|创|意|工|坊|\n",
      "|7|.| |五|彩|铅|笔|制|造|公司|\n",
      "|8|.| 彩|色|笔|芯|创|意|工|厂|\n",
      "|9|.| 绚|丽|铅|笔|工|艺|厂|\n",
      "|10|.| 彩|虹|笔|芯|制|造|厂||"
     ]
    }
   ],
   "source": [
    "# LCEL LLM+Prompt+Outputparser\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "for chunk in chain.stream({\"product\": \"彩色铅笔\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73527d37-fdb8-4d76-b70c-4ce1c209a3ed",
   "metadata": {},
   "source": [
    "## 实现一个简单的模拟大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032f3d3-43c6-46d3-8159-9baa9f16d384",
   "metadata": {},
   "source": [
    "### 实现一个Fake大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52b2c9ba-39af-488b-af00-d272b7bff551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Dict, Iterator, List, Optional, Union\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, HumanMessageChunk, AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2ebdb44f-afd7-4ffc-9419-56e144a6d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeChatWithOlder(BaseChatModel):\n",
    "    \"\"\"模拟跟大爷的对话\"\"\"\n",
    "\n",
    "    responses: List[BaseMessage]\n",
    "    sleep: Optional[float] = 0.1\n",
    "    i: int = 0\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        response = self.responses[self.i]\n",
    "        if self.i < len(self.responses) - 1:\n",
    "            self.i += 1\n",
    "        else:\n",
    "            self.i = 0\n",
    "        generation = ChatGeneration(message=response)\n",
    "        return ChatResult(generations=[generation])\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"fake-chat-with-older\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9fb12783-b794-4ce2-8ace-4bd781be835e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "夏洛：大爷，楼上322马冬梅在家吗？\n",
      "大爷：马什么梅？|\n",
      "\n",
      "夏洛：马冬梅啊\n",
      "大爷：什么冬梅？|\n",
      "\n",
      "夏洛：马冬梅！\n",
      "大爷：马东什么？|\n",
      "\n",
      "夏洛：大爷您歇着吧...\n",
      "大爷：好咧|"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"大爷，楼上322马冬梅在家吗？\",\n",
    "    \"马冬梅啊\",\n",
    "    \"马冬梅！\",\n",
    "    \"大爷您歇着吧...\"\n",
    "]\n",
    "\n",
    "reply = [AIMessage(m) for m in [\n",
    "    \"马什么梅？\",\n",
    "    \"什么冬梅？\",\n",
    "    \"马东什么？\",\n",
    "    \"好咧\"\n",
    "]]\n",
    "\n",
    "llm_fake = FakeChatWithOlder(responses=reply)\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\n夏洛：{question}\")\n",
    "    print(\"大爷：\", end=\"\")\n",
    "    # print(llm_fake.invoke(question).content, end=\"\")\n",
    "    for chunk in llm_fake.stream(question):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8231e5a-c8b9-4d8e-8e56-280ccc889fd7",
   "metadata": {},
   "source": [
    "### 支持流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fe2633f0-9002-4684-818a-44daed91c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeStreamChatWithOlder(FakeChatWithOlder):\n",
    "    \"\"\"模拟跟大爷的对话，支持流\"\"\"\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Union[List[str], None] = None,\n",
    "        run_manager: Union[CallbackManagerForLLMRun, None] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        response = self.responses[self.i]\n",
    "        if self.i < len(self.responses) - 1:\n",
    "            self.i += 1\n",
    "        else:\n",
    "            self.i = 0\n",
    "        for chunk in response.content:\n",
    "            if self.sleep is not None:\n",
    "                time.sleep(self.sleep)\n",
    "            yield ChatGenerationChunk(message=AIMessageChunk(content=chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "236c1cf8-0886-423f-9710-cd10ef7c6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "夏洛：大爷，楼上322马冬梅在家吗？\n",
      "大爷：马|什|么|梅|？|\n",
      "\n",
      "夏洛：马冬梅啊\n",
      "大爷：什|么|冬|梅|？|\n",
      "\n",
      "夏洛：马冬梅！\n",
      "大爷：马|东|什|么|？|\n",
      "\n",
      "夏洛：大爷您歇着吧...\n",
      "大爷：好|咧|"
     ]
    }
   ],
   "source": [
    "llm_fake = FakeStreamChatWithOlder(responses=reply)\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\n夏洛：{question}\")\n",
    "    print(\"大爷：\", end=\"\")\n",
    "    for chunk in llm_fake.stream(question):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a47508d-76d7-4c2f-8156-503821e5ff06",
   "metadata": {},
   "source": [
    "### 🌹 看源码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87a1e7-cd8d-495b-8aa0-6342a30135ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0291149-5421-4846-92f6-d2367383c5c8",
   "metadata": {},
   "source": [
    "### Langchain支持的大模型\n",
    "- ChatOpenAI\n",
    "- FakeLLM\n",
    "\n",
    "### 一般用法\n",
    "\n",
    "- invoke\n",
    "- stream\n",
    "- create_qa_chain\n",
    "- create_openai_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2e199-6d19-47db-888d-ea07303af597",
   "metadata": {},
   "source": [
    "## 版本1\n",
    "\n",
    "### 看看智谱官方的简单例子\n",
    "### Langchain 相关库源码\n",
    "### 写一个简单的 Langchain 版本\n",
    "### 在LCEL中使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b0bf2-030c-40e3-8702-153cddd37031",
   "metadata": {},
   "source": [
    "## 版本2\n",
    "\n",
    "### 试试流：暂时不支持\n",
    "### 看看智谱官方对流的支持\n",
    "### 看看流的默认实现源码\n",
    "### 让我们也支持流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e820d-46fc-4bcb-8264-ce0c34e416b4",
   "metadata": {},
   "source": [
    "## 版本3\n",
    "\n",
    "### 试试工具：暂时不支持\n",
    "### 看看智谱官方对工具回调的支持\n",
    "### 回顾工具回调：只是一种消息格式\n",
    "### 看看 openai 实现源码\n",
    "### 让我们也支持工具回调\n",
    "### 在智能体中使用\n",
    "### 完整代码请参考 langchain_zhipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c36b2-6d05-4e49-bbd5-34d231c08ae1",
   "metadata": {},
   "source": [
    "## 1、✍️ 代码准备：langchain中的LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d17151-50f4-4d7c-97a6-6df12706b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM invoke\n",
    "# OpenAI\n",
    "\n",
    "# LLM stream\n",
    "# OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8b752-1a25-4bb9-844e-e92308966b51",
   "metadata": {},
   "source": [
    "### 2、✍️ 代码实践：如何实现一个FakeLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7f2b17-1585-4fe5-bfce-65ff0d9d28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 马冬梅楼下老大爷"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68825344-97a0-4b23-b27b-d7aea3019cad",
   "metadata": {},
   "source": [
    "[已经实现的FakeLLM](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/fake.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b74ef-7182-4c5a-a185-371b9266b90f",
   "metadata": {},
   "source": [
    "### 3、🌹 阅读源码：集成自己的大模型需要如何下手？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43dc22-57e1-4ed3-be18-f3f5f2ad60c8",
   "metadata": {},
   "source": [
    "#### （1）BaseLanguageModel\n",
    "\n",
    "来自：[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/base.py#L74-L81)\n",
    "\n",
    "```python\n",
    "class BaseLanguageModel(\n",
    "    RunnableSerializable[LanguageModelInput, LanguageModelOutputVar], ABC\n",
    "):\n",
    "    \"\"\"Abstract base class for interfacing with language models.\n",
    "\n",
    "\n",
    "    All language model wrappers inherit from BaseLanguageModel.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca17ee1-fba0-4417-ab32-4cb100bf2156",
   "metadata": {},
   "source": [
    "#### （2）BaseChatModel\n",
    "\n",
    "来自：[https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/chat_models.py#L100)\n",
    "\n",
    "```python\n",
    "class BaseChatModel(BaseLanguageModel[BaseMessage], ABC):\n",
    "    \"\"\"Base class for Chat models.\"\"\"\n",
    "\n",
    "    ...\n",
    "\n",
    "    def invoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.generate_prompt(...)\n",
    "        # generate_prompt >> generate >> _generate\n",
    "\n",
    "    def ainvoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.agenerate_prompt(...)\n",
    "        # agenerate_prompt >> agenerate >> _agenerate >> _generate\n",
    "    \n",
    "    def stream(...) -> Iterator[BaseMessageChunk]:\n",
    "        # ...\n",
    "        if type(self)._stream == BaseChatModel._stream:\n",
    "            # model doesn't implement streaming, so use default implementation\n",
    "            yield cast(\n",
    "                BaseMessageChunk, self.invoke(input, config=config, stop=stop, **kwargs)\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    async def astream(...) -> AsyncIterator[BaseMessageChunk]:\n",
    "        # ...\n",
    "        if (\n",
    "            type(self)._astream is BaseChatModel._astream\n",
    "            and type(self)._stream is BaseChatModel._stream\n",
    "        ):\n",
    "            # No async or sync stream is implemented, so fall back to ainvoke\n",
    "            yield cast(\n",
    "                BaseMessageChunk,\n",
    "                await self.ainvoke(input, config=config, stop=stop, **kwargs),\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    ## ！！必须实现 \n",
    "    @abstractmethod\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"Top Level call\"\"\"\n",
    "\n",
    "    ## ！！建议实现 \n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def _astream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterator[ChatGenerationChunk]:\n",
    "    # ...\n",
    "    self._stream(...)\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e1905-cbbe-4339-bf5b-9ff81836a756",
   "metadata": {},
   "source": [
    "### 4、✍️ 代码实践：一步步集成智谱AI大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fdcc70-1271-4e35-8e06-9d8ae37f48ea",
   "metadata": {},
   "source": [
    "- 支持 invoke\n",
    "- 支持 stream\n",
    "- 支持 tools-calling\n",
    "\n",
    "- 完整实现：[langchain_zhipu](https://github.com/arcstep/langchain_zhipu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c0a94-ec25-4bec-bdff-93acc9e025bf",
   "metadata": {},
   "source": [
    "# ❤️（二）LLM输入输出：全面拆解 Runnable 结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4800b-4b93-4a89-8040-397b53c402dc",
   "metadata": {},
   "source": [
    "### 1、大模型调用过程中发生的数据流转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077bf62-1adb-4e92-b2fe-80cbb5265342",
   "metadata": {},
   "source": [
    "- 从训过的模型说起：训练预料和预测文本风格（|<assistent>| xxxxxx |</assistent>|)\n",
    "- 作为API提供：openAI风格\n",
    "- 从提示语到langchain消息：BaseMessages\n",
    "- 从langchain消息到大模型客户端：BaseChatModel\n",
    "- 从大模型结果到langchain消息：BaseMessages\n",
    "- 从langchain消息到输出解析器：OutpurParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a6a02-27aa-4996-81ff-0c27da433aef",
   "metadata": {},
   "source": [
    "### 2、如果在这个过程中统一各模块标准，随时更换？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d13c5-663b-440c-92fd-9d1c51eb630d",
   "metadata": {},
   "source": [
    "### 3、如果在这个过程中使用流、异步、批量、事件流 ... ？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09417b7-12b2-4998-8d89-d5695140a5fa",
   "metadata": {},
   "source": [
    "### 4、这个过程中的缓存、重试、配置 ... ？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee06284-0b63-4231-9aa7-a9dced804e0e",
   "metadata": {},
   "source": [
    "### 1、为什么说可以用 Runnable 组件在生产系统中搭积木？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918dc61-89d0-47c0-877b-2489dcb44b47",
   "metadata": {},
   "source": [
    "- Runnable接口标准化的价值\n",
    "    - 替换大模型：从GPT到国产云模型、到开源自训模型的多层次尝试和落地是必要的\n",
    "    - 替换调用方式：满足业务验证、生产上线、业务扩容等多场景\n",
    "    - 替换提示语模板：适应技术研究、业务定制、运营优化等多阶段\n",
    "    - 替换解析器：适应模块调用、API调用等多协议对接\n",
    "    - 替换回调集成：langsmith、langfuse云、langfuse本地化、自建运维系统\n",
    "    - 替换向量数据库：适应不同场景、阶段的技术选型调整\n",
    "    - 替换持久化：...\n",
    "    - 替换智能体：..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233dae74-6f40-4195-a825-cde34826bd07",
   "metadata": {},
   "source": [
    "### 2、🌹 阅读源码：Runnable 组件8个方法的实现逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5002f62-1c47-4157-9485-eaa10314a517",
   "metadata": {},
   "source": [
    "### 3、🌹 阅读源码：Runnable 组件配置自举能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d9e06-606f-4f72-b9fe-8ec9530eed05",
   "metadata": {},
   "source": [
    "- 了解Runnable 组件的 8 个方法的默认实现\n",
    "- 自定义Runnable（必要实现一般是invoke / stream / astream，或对应的内部函数）\n",
    "- invoke：标准化调度\n",
    "- batch: 标准化批量调度\n",
    "- stream：标准化流式输出\n",
    "- ainvoke / astream / abatch: 标准化异步调度\n",
    "- astream_log / astream_events: 在链、智能体、langgraph等输出中按照names、tags、events提取流式日志\n",
    "- config：统一管理配置\n",
    "- schema：统一探查参数和配置\n",
    "\n",
    "- 序列化\n",
    "\n",
    "- 配置自举：在开放式应用中支持客户端自动识别自定义服务\n",
    "- 容错：标准化重试策略\n",
    "- 与langserve等api框架标准化对接\n",
    "- 与langfuse等callbck框架标准化对接\n",
    "- 与langchainjs等异构实现标准化对接\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a62f75-52bd-462b-a396-8fb9751fc84a",
   "metadata": {},
   "source": [
    "### 4、🌹 阅读源码：遗留的 Chain 是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f68e5-b811-4854-af6f-7a8ded1ba8bd",
   "metadata": {},
   "source": [
    "- langchain中提前写好的Chain资源"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3fa84-035e-4eb5-be59-4c3a902fea45",
   "metadata": {},
   "source": [
    "- 这些 Chain 局限性在究竟哪里？\n",
    "    - 流程不灵活\n",
    "    - 支持流式输出不彻底"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0ddb0-134d-4641-ad0f-994df1e945b5",
   "metadata": {},
   "source": [
    "### 5、✍️ 代码实践：若干种情况下的流输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b85a1-eda7-4c3c-80af-0a125e5b4fee",
   "metadata": {},
   "source": [
    "# ❤️ 第 2 部份：Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64598d5-cdac-4a60-96d9-52b44730d6a2",
   "metadata": {},
   "source": [
    "# ❤️（三）由LCEL实现智能体：全面拆解 LCEL 能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af86c4c-549a-4eb6-9ddc-f07314e393aa",
   "metadata": {},
   "source": [
    "### 1、LCEL 比 遗留 Chain 多哪些优势？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76adf428-cdd4-4aa8-ac8b-3a3648ae7ead",
   "metadata": {},
   "source": [
    "- LCEL 构建的替代 Chain\n",
    "- 了解支撑LCEL的Runnable组件\n",
    "    - Lambda\n",
    "    - 迭代器\n",
    "    - 字典和并行\n",
    "    - 路由\n",
    "    - 条件\n",
    "    - 迭代执行\n",
    "    - 绑定\n",
    "    - 绘图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9e9ba-3388-40f2-a8f0-38ea7b7b2efd",
   "metadata": {},
   "source": [
    "### 2、如何用 LCEL 定义智能体？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bd7d1-572a-447b-89b6-528b45258be9",
   "metadata": {},
   "source": [
    "- 工具：定义一个简单工具\n",
    "- 智能体：\n",
    "    - Tools-Calling 智能体\n",
    "    - ReAct 智能体\n",
    "- 执行器：AgentExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d886c2-abec-4423-8742-068d144e66d3",
   "metadata": {},
   "source": [
    "### 3、🌹 阅读源码：了解 create_react_agent 的设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad31612-b006-4803-96a9-6bb824b1c25a",
   "metadata": {},
   "source": [
    "- 一个简单的智能体需求：与AI玩一个捉迷藏游戏\n",
    "- react智能体的prompt如何工作\n",
    "- 中间步骤的一步步产生过程\n",
    "- action如何解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0378cc-4936-4ce2-abc6-9a7deebfa4c1",
   "metadata": {},
   "source": [
    "### 4、🌹 阅读源码：了解 AgentExecutor 的执行逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243379b-0e24-42ce-9087-239608bf5882",
   "metadata": {},
   "source": [
    "### 4、✍️ 代码实践：如何用 AgentExcutor 再现《手撕AutoGPT》？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba7531-66a6-4fda-81dc-03a87a2a637f",
   "metadata": {},
   "source": [
    "难点：\n",
    "- 官方例子和内置智能体无法支持pydantic参数解析（智谱AI等推理能力较弱的模型可以使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702bd5b7-8aeb-4d5a-bd14-dfe0cc39e238",
   "metadata": {},
   "source": [
    "# ❤️（四）由LangGraph实现智能体：全面拆解 LangGraph 能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b530de-c32e-4de7-a53d-2a7403ae881e",
   "metadata": {},
   "source": [
    "### 1、LangGraph 比 LCEL 多了什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28481dec-c573-4c30-ba7d-a557702475ee",
   "metadata": {},
   "source": [
    "### 2、如何使用 LangGraph 定义智能体？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186660d-0f16-449c-82b1-ee02cb95d07f",
   "metadata": {},
   "source": [
    "### 3、🌹 阅读源码：了解 LangGraph 的执行逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda0a46-ce13-4ce2-9a98-fb743118baaf",
   "metadata": {},
   "source": [
    "### 4、✍️ 代码实践：如何用 LangGraph 再现《手撕AutoGPT》？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed73748-3266-4a30-9468-f441ab10157c",
   "metadata": {},
   "source": [
    "难点：\n",
    "- 官方例子和内置智能体无法支持流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf21ca-cf12-4cd3-a53c-f451ccafa852",
   "metadata": {},
   "source": [
    "# ❤️ 课程结束"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f9b10-8af0-4a42-80be-935f1fc6c853",
   "metadata": {},
   "source": [
    "## 1、课程总结\n",
    "\n",
    "- 我们一起阅读了langchain的源代码结构和部份细节\n",
    "    - BaseLanguageModel / BaseChatModel / \n",
    "    - Runnable\n",
    "    - LambdaRunnable\n",
    "    - Chain\n",
    "    - AgentExcutor\n",
    "    - langgraph.prebuild\n",
    "- 我们学习了如何自己动手集成大模型到 langchain 中\n",
    "- 我们拆解了langchain的基石组件：Runnable\n",
    "- 我们拆解了langchain的核心逻辑能力：LCEL\n",
    "- 我们拆解了langchain的最新逻辑能力：langgraph\n",
    "- 我们动手做了一些代码实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454ac52-a105-45d0-b99e-aa8183cb5f29",
   "metadata": {},
   "source": [
    "## 2、最后建议\n",
    "\n",
    "- 技术选型时要对 Langchain 有绝对信心（几乎都不会是langchain的错）\n",
    "- 内置链尽量使用LCEL链\n",
    "- 内置智能体尽量使用 Langgraph\n",
    "- 自定义智能体时使用 Langgraph\n",
    "- 模块优先做成Runnable或LCEL链，其次再考虑Lambda\n",
    "- 工具中包含大模型调用时优先做成Runnable或LCEL链，其次再考虑invoke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473875b-dd97-48be-b285-dce1528a5b58",
   "metadata": {},
   "source": [
    "## 3、彩蛋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a44e1a-5197-41d2-b6f8-669e59a6196e",
   "metadata": {},
   "source": [
    "### 1、✍️ 代码实践：如何同时使用langchain的记忆和持久化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021d211-8b68-400e-976b-3250035a2e65",
   "metadata": {},
   "source": [
    "这是 langchain 文档中一个自相矛盾的地方，留给大家课后讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa187b9-3d0c-4981-873b-56704520af13",
   "metadata": {},
   "source": [
    "### 2、✍️ 代码实践：如何将自己训的大模型集成到 langchain 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e01f4-4317-46d4-889c-fbc923a1ff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
