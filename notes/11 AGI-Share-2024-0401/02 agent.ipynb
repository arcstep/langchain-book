{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5b5362-cf90-4d8a-9c70-3db56e3f8dcc",
   "metadata": {},
   "source": [
    "# 🦜🔗 LangChain核心源代码解读：关于LLM和Agent（下）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd052d2-91ac-475b-8fd8-fa2fce941ea6",
   "metadata": {},
   "source": [
    "# 课程开始"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aacf2f7-f113-4451-a94c-b6911334f87f",
   "metadata": {},
   "source": [
    "## 下半场的闲聊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a655d7-e62f-481b-be3b-f814f009119a",
   "metadata": {},
   "source": [
    "- 🌹 [LangChain 中的 Agent](https://python.langchain.com/docs/modules/agents/agent_types/)\n",
    "- 🌹 [Chain 遗产](https://python.langchain.com/docs/modules/chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2acb4e-bdbf-4353-a29b-6d7f013ca0b1",
   "metadata": {},
   "source": [
    "### 🌹 智能体相关类整理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbd141-3473-4ebb-a078-e300f5da9668",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**（1）智能体类型**\n",
    "- AgentType\n",
    "    - ZERO_SHOT_REACT_DESCRIPTION（`ReAct`的一般实现）\n",
    "    - REACT_DOCSTORE（ReAct，支持RAG）\n",
    "    - SELF_ASK_WITH_SEARCH（使用`search 工具`不断反思获得答案）\n",
    "    - CONVERSATIONAL_REACT_DESCRIPTION（`ReAct`，支持对话）\n",
    "    - CHAT_ZERO_SHOT_REACT_DESCRIPTION（同上）\n",
    "    - CHAT_CONVERSATIONAL_REACT_DESCRIPTION（同上）\n",
    "    - STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION（`ReAct`，为对话模型优化，支持多输入）\n",
    "    - OPENAI_FUNCTIONS（支持`OpenAI Function Calling`）\n",
    "    - OPENAI_MULTI_FUNCTIONS（支持`OpenAI Function Calling`，支持多函数调度）\n",
    "\n",
    "----\n",
    "**（2）智能体执行器子组件：**\n",
    "\n",
    "[查看 langchain_core/agents.py 源码](https://github.com/langchain-ai/langchain/blob/239dd7c0c03d0430c55c2c41cf56cf0dd537199b/libs/core/langchain_core/agents.py)\n",
    "\n",
    "- `AgentAction`\n",
    "    - `AgentActionMessageLog`\n",
    "- `AgentStep`\n",
    "- `AgentFinish`\n",
    "\n",
    "----\n",
    "**（3）单动智能体：**\n",
    "- `BaseSingleActionAgent`\n",
    "    - RunnableAgent\n",
    "    - LLMSingleActionAgent（__deprecated__：`create_***_agent`）\n",
    "    - XMLAgent（__deprecated__：create_xml_agent）\n",
    "    - Agent\n",
    "        - ChatAgent（__deprecated__：`create_react_agent`）\n",
    "        - ConversationalAgent（__deprecated__：`create_react_agent`）\n",
    "        - ConversationalChatAgent（__deprecated__：`create_json_chat_agent`）\n",
    "        - StructuredChatAgent（__deprecated__：`create_structured_chat_agent`）\n",
    "        - ZeroShotAgent（__deprecated__：`create_react_agent`）\n",
    "        - ReActDocstoreAgent（__deprecated__）\n",
    "            - ReActTextWorldAgent（__deprecated__）\n",
    "        - SelfAskWithSearchAgent（__deprecated__：`create_self_ask_with_search`）\n",
    "    - OpenAIFunctionsAgent（__deprecated__：`create_openai_functions_agent`）\n",
    "\n",
    "----\n",
    "**（4）多动智能体：**\n",
    "- BaseMultiActionAgent\n",
    "    - RunnableMultiActionAgent\n",
    "    - OpenAIMultiFunctionsAgent（__deprecated__：`create_openai_tools_agent`）\n",
    "\n",
    "----\n",
    "**（5）Assistant：**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - Chain\n",
    "            - `AgentExecutor`\n",
    "                - MRKLChain（__deprecated__）\n",
    "                - ReActChain（__deprecated__）\n",
    "                - SelfAskWithSearchChain（__deprecated__）\n",
    "        - `OpenAIAssistantRunnable`\n",
    "\n",
    "----\n",
    "**（6）提示语模板：**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BasePromptTemplate [Dict, PromptValue]\n",
    "            - BaseChatPromptTemplate\n",
    "                - ChatPromptTemplate\n",
    "                    - `AgentScratchPadChatPromptTemplate`\n",
    "\n",
    "----\n",
    "**（7）输出解析：**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseOutputParser\n",
    "            - `AgentOutputParser`\n",
    "            - `MultiActionAgentOutputParser`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2661030-84bd-47c6-8194-1d4570cb144a",
   "metadata": {},
   "source": [
    "### 🌹 从源码中看 openai 作为先驱的影响\n",
    "\n",
    "- [partners/openai/langchain_openai/chat_models/base.py（OpenAI模型）](https://github.com/langchain-ai/langchain/blob/master/libs/partners/openai/langchain_openai/chat_models/base.py)\n",
    "- [community/langchain_community/adapters/openai.py（OpenAI风格API转换）](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/adapters/openai.py)\n",
    "- [core/langchain_core/utils/function_calling.py（OpenAI风格回调工具函数）](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/utils/function_calling.py)\n",
    "- [core/langchain_core/output_parsers/openai_tools.py（OpenAI风格输出解析）](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/output_parsers/openai_tools.py)\n",
    "- [core/langchain_core/output_parsers/openai_functions.py（OpenAI风格输出解析）](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/output_parsers/openai_functions.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142438a-78bf-4cfc-aa37-02cb219047b3",
   "metadata": {},
   "source": [
    "# （二）解读源码，拆解和自定义智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c9102-787d-4efe-bebb-4acaa397b46b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>干货从这里开始！</b><br>\n",
    "    接下来的例子中，会穿插 langchian 源码解读。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4860d2d9-e16e-4077-8e5e-be72f92777b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载 .env 到环境变量\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270bb25b-fbf8-468a-801e-0d38adc61349",
   "metadata": {},
   "source": [
    "## 4、解读 OpenAI 工具回调风格智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c182357-9e1e-4036-ad7c-e7159d69796b",
   "metadata": {},
   "source": [
    "### ✍️ 拆解 OpenAI 工具回调智能体的定义过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96fdb2b-8b94-478b-8204-b2264f23823a",
   "metadata": {},
   "source": [
    "![还是那个故事，但这次我们让老大爷聪明一点...如果可以的话。](./madongmei.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cbde4eac-9718-4556-a79e-4d74475a6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_zhipu import ChatZhipuAI\n",
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "from langchain.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool, convert_to_openai_function\n",
    "import re\n",
    "\n",
    "@tool\n",
    "def ask_neighber(query: str) -> str:\n",
    "    \"\"\"想问你找的人住哪里就问我吧，我是楼下老大爷\"\"\"\n",
    "    if(re.search(\"马冬梅\", query)):\n",
    "        return \"楼上322\"\n",
    "    else:\n",
    "        return \"我不清楚\"\n",
    "\n",
    "def create_openai_neighber(llm):\n",
    "    \"\"\"\n",
    "    使用openai智能体定义一个应用\n",
    "    \"\"\"\n",
    "    # 定义 tools\n",
    "    tools = [ask_neighber]\n",
    "    # 定义 prompt\n",
    "    prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "    # 定义 Agent\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    # 定义 AgentExecutor\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "    return executor\n",
    "\n",
    "neighber = create_openai_neighber(ChatZhipuAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b02e0c-154a-4bfb-84cb-096f6a95d685",
   "metadata": {},
   "source": [
    "### 🌹 prompt： 观察 OpenAI 智能体的提示语"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb242bb3-ddfd-4d41-8c83-2aa1d595d658",
   "metadata": {},
   "source": [
    "#### （1）从 Langsmith 的 hub 下载 hwchase17/openai-tools-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87972ce9-815d-461a-995c-32b356c7ffef",
   "metadata": {},
   "source": [
    "[查看 hub.pull(\"hwchase17/openai-tools-agent\")](https://smith.langchain.com/hub/hwchase17/openai-tools-agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf6a6c-010c-4205-8c9e-47977e75e6b9",
   "metadata": {},
   "source": [
    "#### （2）等价的自定义 Prompt 模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2dd9751f-85b3-4b87-bc2e-de179c591752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "# openai agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20ae236a-0407-4296-b473-d04dbe605e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant'), HumanMessage(content='请问马冬梅的家在哪里？')])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\n",
    "    \"input\": \"请问马冬梅的家在哪里？\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ac141-5874-4717-a72b-db95e66e3cc0",
   "metadata": {},
   "source": [
    "### 🌹 agent：阅读 create_openai_tools_agent 源码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6096ec-803f-443b-842a-9f5d889703e8",
   "metadata": {},
   "source": [
    "[查看 langchain/agents/openai_tools/base.py 源码](https://github.com/langchain-ai/langchain/blob/239dd7c0c03d0430c55c2c41cf56cf0dd537199b/libs/langchain/langchain/agents/openai_tools/base.py#L15-L97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53e5e93-8a82-48b0-ace0-1ed14ff25689",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "```python\n",
    "def create_openai_tools_agent(\n",
    "    llm: BaseLanguageModel, tools: Sequence[BaseTool], prompt: ChatPromptTemplate\n",
    ") -> Runnable:\n",
    "    \"\"\"Create an agent that uses OpenAI tools.\"\"\"\n",
    "\n",
    "    missing_vars = {\"agent_scratchpad\"}.difference(prompt.input_variables)\n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Prompt missing required variables: {missing_vars}\")\n",
    "\n",
    "    llm_with_tools = llm.bind(tools=[convert_to_openai_tool(tool) for tool in tools])\n",
    "\n",
    "    agent = (\n",
    "        RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_to_openai_tool_messages(\n",
    "                x[\"intermediate_steps\"]\n",
    "            )\n",
    "        )\n",
    "        | prompt\n",
    "        | llm_with_tools\n",
    "        | OpenAIToolsAgentOutputParser()\n",
    "    )\n",
    "    return agent\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c7944-801f-439c-bed7-8c5e3e8317cc",
   "metadata": {},
   "source": [
    "### 🌹 executor： 阅读 AgentExcutor 源码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a057c3-40ed-4ddc-873c-aa6b30842187",
   "metadata": {},
   "source": [
    "[查看 AgentExcutor 源码](https://github.com/langchain-ai/langchain/blob/239dd7c0c03d0430c55c2c41cf56cf0dd537199b/libs/langchain/langchain/agents/agent.py#L915)\n",
    "\n",
    "- 代码中的运行逻辑非常复杂，因此我们可以通过下面的方式研究其实际运行过程。\n",
    "- 作为 Chain 子类，AgentExcutor 覆写了 stream 方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4729ef-baa1-4741-85d8-15d8a89c4a46",
   "metadata": {},
   "source": [
    "### 🌹 run：观察 OpenAI 智能体的运行过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e339f1d-3ea6-45c4-8d6a-a5ff118cebaa",
   "metadata": {},
   "source": [
    "#### （1）简单执行：invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f4722734-d500-4724-a924-38a1223fe85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ask_neighber` with `{'query': '马冬梅住哪里'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m楼上322\u001b[0m\u001b[32;1m\u001b[1;3m根据楼下老大爷的回答，马冬梅住在楼上322。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '马冬梅住哪里', 'output': '根据楼下老大爷的回答，马冬梅住在楼上322。'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke\n",
    "neighber.invoke({\"input\":\"马冬梅住哪里\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a8351-d72b-4613-a820-1680b4c1e2f5",
   "metadata": {},
   "source": [
    "#### （2）流输出：stream（仅智能体中的流）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ae095682-60f7-46ab-9e4f-07474bc48353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{'actions': [OpenAIToolAgentAction(tool='ask_neighber', tool_input={'query': '马冬梅住哪里'}, log=\"\\nInvoking: `ask_neighber` with `{'query': '马冬梅住哪里'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8516974814413003915', 'function': {'arguments': '{\"query\":\"马冬梅住哪里\"}', 'name': 'ask_neighber'}, 'type': 'function'}]})], tool_call_id='call_8516974814413003915')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8516974814413003915', 'function': {'arguments': '{\"query\":\"马冬梅住哪里\"}', 'name': 'ask_neighber'}, 'type': 'function'}]})]}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ask_neighber` with `{'query': '马冬梅住哪里'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m楼上322\u001b[0m{'steps': [AgentStep(action=OpenAIToolAgentAction(tool='ask_neighber', tool_input={'query': '马冬梅住哪里'}, log=\"\\nInvoking: `ask_neighber` with `{'query': '马冬梅住哪里'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8516974814413003915', 'function': {'arguments': '{\"query\":\"马冬梅住哪里\"}', 'name': 'ask_neighber'}, 'type': 'function'}]})], tool_call_id='call_8516974814413003915'), observation='楼上322')], 'messages': [FunctionMessage(content='楼上322', name='ask_neighber')]}\n",
      "\u001b[32;1m\u001b[1;3m根据我的查询结果，马冬梅住在楼上322房间。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'output': '根据我的查询结果，马冬梅住在楼上322房间。', 'messages': [AIMessage(content='根据我的查询结果，马冬梅住在楼上322房间。')]}\n"
     ]
    }
   ],
   "source": [
    "# stream\n",
    "for s in neighber.stream({\"input\":\"马冬梅住哪里\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd1500-560b-4247-88a7-4b5dd5adab6a",
   "metadata": {},
   "source": [
    "#### （3）还是要使用事件流：astream_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05eb804-9355-4abe-b9b6-91101cc4ed3b",
   "metadata": {},
   "source": [
    "**看看方法 astream_events 的能力：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1aab2d-9243-4916-bc85-1d684ad99e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentExecutor\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      " [] on_chain_start\n",
      "RunnableSequence [] on_chain_start\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_start\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_stream\n",
      "RunnableParallel<agent_scratchpad> [] on_chain_start\n",
      "RunnableLambda ['map:key:agent_scratchpad'] on_chain_start\n",
      "RunnableLambda ['map:key:agent_scratchpad'] on_chain_stream\n",
      "RunnableParallel<agent_scratchpad> [] on_chain_stream\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_stream\n",
      "RunnableLambda ['map:key:agent_scratchpad'] on_chain_end\n",
      "RunnableParallel<agent_scratchpad> [] on_chain_end\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_end\n",
      "ChatPromptTemplate ['seq:step:2'] on_prompt_start\n",
      "ChatPromptTemplate ['seq:step:2'] on_prompt_end\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_start\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_end\n",
      "OpenAIToolsAgentOutputParser ['seq:step:4'] on_parser_start\n",
      "OpenAIToolsAgentOutputParser ['seq:step:4'] on_parser_end\n",
      "RunnableSequence [] on_chain_stream\n",
      "RunnableSequence [] on_chain_end\n",
      "AgentExecutor [] on_chain_stream\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ask_neighber` with `{'query': '马冬梅住哪里'}`\n",
      "\n",
      "\n",
      "\u001b[0mask_neighber [] on_tool_start\n",
      "\u001b[36;1m\u001b[1;3m楼上322\u001b[0mask_neighber [] on_tool_end\n",
      "AgentExecutor [] on_chain_stream\n",
      "RunnableSequence [] on_chain_start\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_start\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_stream\n",
      "RunnableParallel<agent_scratchpad> [] on_chain_start\n",
      "RunnableLambda ['map:key:agent_scratchpad'] on_chain_start\n",
      "RunnableLambda ['map:key:agent_scratchpad'] on_chain_stream\n",
      "RunnableParallel<agent_scratchpad> [] on_chain_stream\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_stream\n",
      "RunnableLambda ['map:key:agent_scratchpad'] on_chain_end\n",
      "RunnableParallel<agent_scratchpad> [] on_chain_end\n",
      "RunnableAssign<agent_scratchpad> ['seq:step:1'] on_chain_end\n",
      "ChatPromptTemplate ['seq:step:2'] on_prompt_start\n",
      "ChatPromptTemplate ['seq:step:2'] on_prompt_end\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_start\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_stream\n",
      "ChatZhipuAI ['seq:step:3'] on_chat_model_end\n",
      "OpenAIToolsAgentOutputParser ['seq:step:4'] on_parser_start\n",
      "OpenAIToolsAgentOutputParser ['seq:step:4'] on_parser_end\n",
      "RunnableSequence [] on_chain_stream\n",
      "RunnableSequence [] on_chain_end\n",
      "\u001b[32;1m\u001b[1;3m根据我的查询结果，马冬梅住在楼上322房间。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AgentExecutor [] on_chain_stream\n",
      "AgentExecutor [] on_chain_end\n"
     ]
    }
   ],
   "source": [
    "# astream_events\n",
    "async for e in neighber.astream_events({\"input\":\"马冬梅住哪里\"}, version=\"v1\"):\n",
    "    print(e['name'], e['tags'], e['event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c714e2-b233-447e-81ae-8c7cf82de783",
   "metadata": {},
   "source": [
    "#### （4）观察与大模型的交互过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df3f9c-f5c4-482d-bbff-8101b9c2a04c",
   "metadata": {},
   "source": [
    "只读取 **on_tool_end** 和 **on_chat_model_end** 两个事件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21c8eb73-2cc6-412c-857f-02f7bd3ee569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "INPUT:\n",
      "{'messages': [[SystemMessage(content='You are a helpful assistant'), HumanMessage(content='马冬梅住哪里')]]}\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "OUTPUT:\n",
      "{'generations': [[{'text': '', 'generation_info': {'finish_reason': 'tool_calls'}, 'type': 'ChatGenerationChunk', 'message': AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8516985431572319825', 'function': {'arguments': '{\"query\":\"马冬梅住哪里\"}', 'name': 'ask_neighber'}, 'type': 'function'}]})}]], 'llm_output': None, 'run': None}\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ask_neighber` with `{'query': '马冬梅住哪里'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m楼上322\u001b[0m\n",
      " ---------- ask_neighber -- on_tool_end ----------\n",
      "INPUT:\n",
      "{'query': '马冬梅住哪里'}\n",
      "\n",
      " ---------- ask_neighber -- on_tool_end ----------\n",
      "OUTPUT:\n",
      "楼上322\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "INPUT:\n",
      "{'messages': [[SystemMessage(content='You are a helpful assistant'), HumanMessage(content='马冬梅住哪里'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_8516985431572319825', 'function': {'arguments': '{\"query\":\"马冬梅住哪里\"}', 'name': 'ask_neighber'}, 'type': 'function'}]}), ToolMessage(content='楼上322', additional_kwargs={'name': 'ask_neighber'}, tool_call_id='call_8516985431572319825')]]}\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "OUTPUT:\n",
      "{'generations': [[{'text': '根据我的查询结果，马冬梅住在楼上322房间。', 'generation_info': {'finish_reason': 'stop'}, 'type': 'ChatGenerationChunk', 'message': AIMessageChunk(content='根据我的查询结果，马冬梅住在楼上322房间。')}]], 'llm_output': None, 'run': None}\n",
      "\u001b[32;1m\u001b[1;3m根据我的查询结果，马冬梅住在楼上322房间。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "neighber = create_neighber(ChatZhipuAI())\n",
    "\n",
    "async for e in neighber.astream_events({\"input\":\"马冬梅住哪里\"}, version=\"v1\"):\n",
    "    if e['event'] in [\"on_chat_model_end\", \"on_tool_end\"]:\n",
    "        if(\"input\" in e['data']):\n",
    "            print(\"\\n\", \"-\"*10, e['name'], \"-\"*2, e['event'], \"-\"*10)\n",
    "            print(\"INPUT:\")\n",
    "            print(e['data']['input'])\n",
    "        if(\"output\" in e['data']):\n",
    "            print(\"\\n\", \"-\"*10, e['name'], \"-\"*2, e['event'], \"-\"*10)\n",
    "            print(\"OUTPUT:\")\n",
    "            print(e['data']['output'])\n",
    "        # print(\"\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad2d3a-528d-4c64-a9db-fdd5054b4a2b",
   "metadata": {},
   "source": [
    "#### （5）总结智能体的定义过程\n",
    "\n",
    "- STEP-1 请求智能体（langchain -> ZhipuAI）: 发送带有Tools的请求\n",
    "- STEP-2 智能体解析（ZhipuAI -> langchain）: 收到Tools-Calling消息\n",
    "- STEP-3 调用本地工具（langchain）: 调用工具\n",
    "- STEP-4 重新请求智能体（langchain） -> ZhipuAI）: 提交调用结果\n",
    "- STEP-5 智能体最终生成（ZhipuAI -> langchain）: 大模型重新生成结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554072f-070b-49ea-a45c-ddfd38fe4810",
   "metadata": {},
   "source": [
    "### ✍️ 一步一步执行：就像我们常对大模型说的那样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70658fb-fad7-4814-b3df-506061a2f2d6",
   "metadata": {},
   "source": [
    "#### （1）STEP-1 请求智能体（langchain -> ZhipuAI）: 发送带有Tools的请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "94873b39-8c65-4588-b28e-775e601359f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "# openai agent\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "input = \"马冬梅住在哪里？\"\n",
    "history = []\n",
    "\n",
    "llm = ChatZhipuAI(tools=[convert_to_openai_tool(ask_neighber)])\n",
    "\n",
    "agent = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ff1dc-1436-4dd0-bc34-625247273341",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>⚠️ 思考：</b><br>\n",
    "    <b>convert_to_openai_function</b> 和 <b>convert_to_openai_tool</b> 的区别是什么？\n",
    "</div>\n",
    "\n",
    "**🌞 参考：**\n",
    "- [查看 convert_to_openai_tool 的实现源码](https://github.com/langchain-ai/langchain/blob/c93d4ea91cfcf55dfe871931d42aa22562f8dae2/libs/core/langchain_core/utils/function_calling.py#L323-L341)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48061e6c-3779-4ccb-818d-c3c6a1aaaa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ask_neighber',\n",
       " 'description': 'ask_neighber(query: str) -> str - 我在玩找人的游戏，我知道你找的人住在哪个房间',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query']}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_function(ask_neighber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97bafddf-c37d-4636-9fd9-c11335d28ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'ask_neighber',\n",
       "  'description': 'ask_neighber(query: str) -> str - 我在玩找人的游戏，我知道你找的人住在哪个房间',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string'}},\n",
       "   'required': ['query']}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_tool(ask_neighber)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d829924d-9a26-4af0-b38b-b099d3c16953",
   "metadata": {},
   "source": [
    "#### （2）STEP-2 智能体解析（ZhipuAI -> langchain）: 收到Tools-Calling消息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6eddb81f-dbb2-466e-ab39-867df638794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8516987149559268121', 'function': {'arguments': '{\"query\":\"马冬梅住在哪里？\"}', 'name': 'ask_neighber'}, 'type': 'function'}]})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_info = []\n",
    "resp_llm = agent.invoke({\"input\": input, \"chat_history\": history, \"agent_scratchpad\": steps_info})\n",
    "resp_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a4a18-64d7-4110-bb97-f3c78904a53c",
   "metadata": {},
   "source": [
    "#### （3）STEP-3 调用本地工具（langchain）: 调用工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f749d0a5-0937-4844-b83a-11025a44e8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query\":\"马冬梅住在哪里？\"}'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_llm.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b65819c-65d1-4fc9-aadb-672f17c38dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '马冬梅住在哪里？'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "tool_args = json.loads(resp_llm.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"])\n",
    "tool_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "67b9d2c9-53ad-44fd-9694-8fe98af6e3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'楼上322'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_tool = ask_neighber.invoke(tool_args)\n",
    "resp_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d1635-a21f-4301-b6e9-8b81d216542d",
   "metadata": {},
   "source": [
    "#### （4）STEP-4 重新请求智能体（langchain） -> ZhipuAI）: 提交调用结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "58a38c34-6293-46a0-8387-633e712296f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['马冬梅住在哪里？',\n",
       " '楼上322',\n",
       " '马冬梅住在哪里？',\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8516987149559268121', 'function': {'arguments': '{\"query\":\"马冬梅住在哪里？\"}', 'name': 'ask_neighber'}, 'type': 'function'}]}),\n",
       " '楼上322']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_info.append(input)\n",
    "steps_info.append(resp_llm)\n",
    "steps_info.append(resp_tool)\n",
    "steps_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066d57b-7052-445d-97c9-c82cda7c7871",
   "metadata": {},
   "source": [
    "#### （5）STEP-5 智能体最终生成（ZhipuAI -> langchain）: 大模型重新生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "678c5175-8edf-4b88-af16-a4ebd7f8fdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='根据我的查询结果，马冬梅住在楼上322。您还需要我提供其他信息吗？')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_llm = agent.invoke({\"input\": input, \"chat_history\": history, \"agent_scratchpad\": steps_info})\n",
    "resp_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e575ef-202b-42b8-9eb9-0043b7733542",
   "metadata": {},
   "source": [
    "## 5、解读 ReAct 风格智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e849eb22-0009-4c7b-a0cd-bf0e184f7337",
   "metadata": {},
   "source": [
    "### 🌹 构造 ReAct 智能体的提示语"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0adfd0b-f51c-4cde-9e6c-bdb41d8e8645",
   "metadata": {},
   "source": [
    "[查看 hub.pull(\"hwchase17/react\")](https://smith.langchain.com/hub/hwchase17/react)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2764890b-da71-4d89-8b56-0b29b1009610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e14ca3c1-b866-4404-9d21-9ff1ec78161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf39eb9-2a2f-473c-a758-406d642a968f",
   "metadata": {},
   "source": [
    "### ✍️ 拆解 react 智能体的核心结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a089e4-bd6d-4081-8be5-37d37d32bca1",
   "metadata": {},
   "source": [
    "#### （1）定义 ReAct 智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903bbf26-d989-42f9-9983-9e80990eb2e5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>⚠️ 注意：</b><br>\n",
    "    ReAct 智能体提示语的核心在于：<b>请使用如下的输出格式...</b>\n",
    "    <br>\n",
    "    这相当于提示语模板中的：step by step ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7d0e8cfb-4ba4-46ef-a1f6-d3a3cb741099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_zhipu import ChatZhipuAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, Tool, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain.tools import tool\n",
    "import re\n",
    "\n",
    "@tool\n",
    "def ask_neighber(query: str) -> str:\n",
    "    \"\"\"我是马冬梅的邻居老大爷，关于她的事情你可以问我\"\"\"\n",
    "    if(re.search(\"马冬梅\", query)):\n",
    "        return \"楼上322\"\n",
    "    else:\n",
    "        return \"我不清楚\"\n",
    "\n",
    "prompt_react = \"\"\"\n",
    "请尽你最大努力回答用户的问题，并使用中文。\n",
    "你可以访问如下工具：\n",
    "{tools}\n",
    "\n",
    "请使用如下的输出格式：\n",
    "\n",
    "Question: 你必须回答的问题\n",
    "Thought: 你为了完成任务必须采取的思考过程\n",
    "Action: 又称为工具，必须是 {tool_names} 等其中之一\n",
    "Action Input: 调用工具所使用的参数\n",
    "Observation: 工具执行的结果\n",
    "... (这些过程 Thought/Action/Action Input/Observation 可以重复执行N次)\n",
    "Thought: 我现在知道答案了\n",
    "Final Answer: 问题的最终答案\n",
    "\n",
    "开始！\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "def create_react_neighber(llm):\n",
    "    # 定义 tools\n",
    "    tools = [ask_neighber]\n",
    "    # 定义 prompt\n",
    "    prompt = PromptTemplate.from_template(prompt_react)\n",
    "    # 定义 Agent\n",
    "    agent = create_react_agent(llm, tools, prompt)\n",
    "    # 定义 AgentExecutor\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    \n",
    "    return executor\n",
    "\n",
    "neighber = create_react_neighber(ChatZhipuAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f489c-93c0-47a8-9716-7e06346ac371",
   "metadata": {},
   "source": [
    "#### （2）简单执行：invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e1964227-79f2-4ae8-8cab-dc81dc992813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m我需要获取马冬梅的住址信息，这个问题明显需要使用提供的工具来询问她的邻居。\n",
      "\n",
      "Action: ask_neighber\n",
      "Action Input: '马冬梅住在哪里？'\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m楼上322\u001b[0m\u001b[32;1m\u001b[1;3mThought: 通过邻居老大爷的回答，我已经得到了马冬梅的住址信息。\n",
      "\n",
      "Final Answer: 马冬梅住在楼上322。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '马冬梅住哪里', 'output': '马冬梅住在楼上322。'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke\n",
    "neighber.invoke({\"input\":\"马冬梅住哪里\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f09f9b-1f61-4f46-9b77-028fd38dcfd3",
   "metadata": {},
   "source": [
    "#### （3）大模型的流输出：stream VS astream_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3a00dd4d-74fe-436e-b77b-7ec0902b9472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "{'actions': [AgentAction(tool='ask_neighber', tool_input='马冬梅住在哪里？\"\\nObservation', log='我需要获取马冬梅的住址信息，这个问题明显需要使用提供的工具 ask_neighber 来向她的邻居老大爷询问。\\n\\nAction: ask_neighber\\nAction Input: \"马冬梅住在哪里？\"\\nObservation')], 'messages': [AIMessage(content='我需要获取马冬梅的住址信息，这个问题明显需要使用提供的工具 ask_neighber 来向她的邻居老大爷询问。\\n\\nAction: ask_neighber\\nAction Input: \"马冬梅住在哪里？\"\\nObservation')]}\n",
      "\u001b[32;1m\u001b[1;3m我需要获取马冬梅的住址信息，这个问题明显需要使用提供的工具 ask_neighber 来向她的邻居老大爷询问。\n",
      "\n",
      "Action: ask_neighber\n",
      "Action Input: \"马冬梅住在哪里？\"\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m楼上322\u001b[0m{'steps': [AgentStep(action=AgentAction(tool='ask_neighber', tool_input='马冬梅住在哪里？\"\\nObservation', log='我需要获取马冬梅的住址信息，这个问题明显需要使用提供的工具 ask_neighber 来向她的邻居老大爷询问。\\n\\nAction: ask_neighber\\nAction Input: \"马冬梅住在哪里？\"\\nObservation'), observation='楼上322')], 'messages': [HumanMessage(content='楼上322')]}\n",
      "\u001b[32;1m\u001b[1;3mThought: 邻居老大爷已经告诉我马冬梅的住址是在楼上322，我现在知道问题的答案了。\n",
      "\n",
      "Final Answer: 马冬梅住在楼上322。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'output': '马冬梅住在楼上322。', 'messages': [AIMessage(content='Thought: 邻居老大爷已经告诉我马冬梅的住址是在楼上322，我现在知道问题的答案了。\\n\\nFinal Answer: 马冬梅住在楼上322。')]}\n"
     ]
    }
   ],
   "source": [
    "for chunk in neighber.stream({\"input\": \"马冬梅住哪里\"}):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "39af442a-8893-4ac0-a608-6f828747744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "on_chain_end\n",
      "on_chain_end\n",
      "on_prompt_start\n",
      "on_prompt_end\n",
      "on_chat_model_start\n",
      "我_需要_获取_马_冬_梅_的_住_址_信息_，_这个问题_明显_需要_使用_提供_的信息_查询_工具_。\n",
      "\n",
      "Action_:_ ask__ne_igh_ber_\n",
      "Action_ Input_:_ '_马_冬_梅_住_在哪里_'\n",
      "Observ_ation__on_chat_model_end\n",
      "on_parser_start\n",
      "on_parser_end\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "on_chain_stream\n",
      "\u001b[32;1m\u001b[1;3m我需要获取马冬梅的住址信息，这个问题明显需要使用提供的信息查询工具。\n",
      "\n",
      "Action: ask_neighber\n",
      "Action Input: '马冬梅住在哪里'\n",
      "Observation\u001b[0mon_tool_start\n",
      "\u001b[36;1m\u001b[1;3m楼上322\u001b[0mon_tool_end\n",
      "on_chain_stream\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_start\n",
      "on_chain_start\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "on_chain_end\n",
      "on_chain_end\n",
      "on_prompt_start\n",
      "on_prompt_end\n",
      "on_chat_model_start\n",
      "Thought_:_ 我_已经_从_邻居_老大_爷_那里_得到了_马_冬_梅_的_住_址_信息_。\n",
      "\n",
      "Final_ Answer_:_ 马_冬_梅_住在_楼上_3_22_。__on_chat_model_end\n",
      "on_parser_start\n",
      "on_parser_end\n",
      "on_chain_stream\n",
      "on_chain_end\n",
      "\u001b[32;1m\u001b[1;3mThought: 我已经从邻居老大爷那里得到了马冬梅的住址信息。\n",
      "\n",
      "Final Answer: 马冬梅住在楼上322。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "on_chain_stream\n",
      "on_chain_end\n"
     ]
    }
   ],
   "source": [
    "async for event in neighber.astream_events({\"input\": \"马冬梅住哪里\"}, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content, end=\"_\")\n",
    "    else:\n",
    "        print(kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537231d-185f-4cb6-9936-2add5fc61fe2",
   "metadata": {},
   "source": [
    "### 🌹 观察 ReAct 智能体的运行过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0db4fa-f294-46bb-a745-ab40cb19eee2",
   "metadata": {},
   "source": [
    "只读取 **on_tool_end** 和 **on_chat_model_end** 两个事件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7ff5f9b0-7aa9-4cfe-9bc1-d0e24ad0eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "INPUT:\n",
      "\n",
      "请尽你最大努力回答用户的问题，并用中文回答问题。\n",
      "你可以访问如下工具：\n",
      "ask_neighber: ask_neighber(query: str) -> str - 我是马冬梅的邻居老大爷，关于她的事情你可以问我\n",
      "\n",
      "请使用如下的输出格式：\n",
      "\n",
      "Question: 你必须回答的问题\n",
      "Thought: 你为了完成任务必须采取的思考过程\n",
      "Action: 又称为工具，必须是 ask_neighber 等其中之一\n",
      "Action Input: 调用工具所使用的参数\n",
      "Observation: 工具执行的结果\n",
      "... (这些过程 Thought/Action/Action Input/Observation 可以重复执行N次)\n",
      "Thought: 我现在知道答案了\n",
      "Final Answer: 问题的最终答案\n",
      "\n",
      "开始！\n",
      "\n",
      "Question: 马冬梅住哪里\n",
      "Thought:\n",
      "\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "OUTPUT:\n",
      "我需要获取马冬梅的住址信息，这个问题明显需要使用邻居老大爷提供的询问功能。\n",
      "\n",
      "Action: ask_neighber\n",
      "Action Input: '马冬梅住在哪里？'\n",
      "Observation\n",
      "\u001b[32;1m\u001b[1;3m我需要获取马冬梅的住址信息，这个问题明显需要使用邻居老大爷提供的询问功能。\n",
      "\n",
      "Action: ask_neighber\n",
      "Action Input: '马冬梅住在哪里？'\n",
      "Observation\u001b[0m\u001b[36;1m\u001b[1;3m楼上322\u001b[0m\n",
      " ---------- ask_neighber -- on_tool_end ----------\n",
      "INPUT:\n",
      "'马冬梅住在哪里？'\n",
      "Observation\n",
      "\n",
      " ---------- ask_neighber -- on_tool_end ----------\n",
      "OUTPUT:\n",
      "楼上322\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "INPUT:\n",
      "\n",
      "请尽你最大努力回答用户的问题，并用中文回答问题。\n",
      "你可以访问如下工具：\n",
      "ask_neighber: ask_neighber(query: str) -> str - 我是马冬梅的邻居老大爷，关于她的事情你可以问我\n",
      "\n",
      "请使用如下的输出格式：\n",
      "\n",
      "Question: 你必须回答的问题\n",
      "Thought: 你为了完成任务必须采取的思考过程\n",
      "Action: 又称为工具，必须是 ask_neighber 等其中之一\n",
      "Action Input: 调用工具所使用的参数\n",
      "Observation: 工具执行的结果\n",
      "... (这些过程 Thought/Action/Action Input/Observation 可以重复执行N次)\n",
      "Thought: 我现在知道答案了\n",
      "Final Answer: 问题的最终答案\n",
      "\n",
      "开始！\n",
      "\n",
      "Question: 马冬梅住哪里\n",
      "Thought:我需要获取马冬梅的住址信息，这个问题明显需要使用邻居老大爷提供的询问功能。\n",
      "\n",
      "Action: ask_neighber\n",
      "Action Input: '马冬梅住在哪里？'\n",
      "Observation\n",
      "Observation: 楼上322\n",
      "Thought: \n",
      "\n",
      "\n",
      " ---------- ChatZhipuAI -- on_chat_model_end ----------\n",
      "OUTPUT:\n",
      "Thought: 通过邻居老大爷的信息，我现在已经知道马冬梅的住址了。\n",
      "\n",
      "Final Answer: 马冬梅住在楼上322。\n",
      "\u001b[32;1m\u001b[1;3mThought: 通过邻居老大爷的信息，我现在已经知道马冬梅的住址了。\n",
      "\n",
      "Final Answer: 马冬梅住在楼上322。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "neighber = create_react_neighber(ChatZhipuAI())\n",
    "\n",
    "async for e in neighber.astream_events({\"input\":\"马冬梅住哪里\"}, version=\"v1\"):\n",
    "    print_line = lambda : print(\"\\n\", \"-\"*10, e['name'], \"-\"*2, e['event'], \"-\"*10)\n",
    "    if e['event'] in [\"on_chat_model_end\", \"on_tool_end\"]:\n",
    "        if(\"input\" in e['data']):\n",
    "            input = e['data']['input']\n",
    "            print_line()\n",
    "            print(\"INPUT:\")\n",
    "            if(\"messages\" in input):\n",
    "                print(input[\"messages\"][0][0].content)\n",
    "            else:\n",
    "                print(input)\n",
    "        if(\"output\" in e['data']):\n",
    "            output = e['data']['output'] \n",
    "            print_line()\n",
    "            print(\"OUTPUT:\")\n",
    "            if(\"generations\" in output):\n",
    "                print(output[\"generations\"][0][0][\"text\"])\n",
    "            else:\n",
    "                print(output)\n",
    "        # print(\"\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a53480-aac6-41ae-922c-c11adf288042",
   "metadata": {},
   "source": [
    "### 🌹 阅读源码，解读 ReAct 智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46467905-272a-43d3-add6-b5ef95c1eb32",
   "metadata": {},
   "source": [
    "- `ReAct` 比 `OpenAI智能体` 多了必要的解析过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433903a-47b9-4030-aa1e-e6aea461e21e",
   "metadata": {},
   "source": [
    "- [查看 create_react_agent 源码](https://github.com/langchain-ai/langchain/blob/239dd7c0c03d0430c55c2c41cf56cf0dd537199b/libs/langchain/langchain/agents/react/agent.py#L16)\n",
    "- [查看 ReAct 输出解析的源码](https://github.com/langchain-ai/langchain/blob/239dd7c0c03d0430c55c2c41cf56cf0dd537199b/libs/langchain/langchain/agents/output_parsers/react_single_input.py#L22-L95)\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>思考：上面的提示语中为什么不修改这几个关键词？</b><br>\n",
    "    <ul>\n",
    "        <li>Final Answer</li>\n",
    "        <li>Action</li>\n",
    "        <li>Action Input</li>\n",
    "        <li>Observation</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7cee4-e12e-44c4-b48b-e74df9bb0db9",
   "metadata": {},
   "source": [
    "## 6、在LCEL框架下重定义《手撕AutoGPT》中的智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf9882-63e3-4437-b23b-a18fb47794ca",
   "metadata": {},
   "source": [
    "### ✍️ 自定义基于思维链的提示语"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472006b-54b5-4312-838c-b325e19754bd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>⚠️ 注意：</b><br>\n",
    "    CoT 智能体提示语的核心在于：<b>请使用如下的输出格式...</b>\n",
    "    <br>\n",
    "    这相当于提示语模板中的：step by step ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3e19e742-49ef-44a7-8e8e-04ce50204c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_COT = \"\"\"\n",
    "你是强大的AI助手，可以使用工具与指令自动化解决问题。\n",
    "\n",
    "你必须遵循以下约束来完成任务:\n",
    "1. 每次你的决策只使用一种工具，你可以使用任意多次。\n",
    "2. 确保你调用的指令或使用的工具在下述给定的工具列表中。\n",
    "3. 确保你的回答不会包含违法或有侵犯性的信息。\n",
    "4. 如果你已经完成所有任务，确保以\"FINISH\"指令结束。\n",
    "5. 用中文思考和输出。\n",
    "6. 如果执行某个指令或工具失败，尝试改变参数或参数格式再次调用。\n",
    "7. 你生成的回复必须遵循上文中给定的事实信息。不可以编造信息。DO NOT MAKE UP INFORMATION.\n",
    "8. 如果得到的结果不正确，尝试更换表达方式。\n",
    "9. 已经得到的信息，不要反复查询。\n",
    "10. 确保你生成的动作是可以精确执行的。动作做中可以包括具体方法和目标输出。\n",
    "11. 看到一个概念时尝试获取它的准确定义，并分析从哪些输入可以得到它的具体取值。\n",
    "12. 生成一个自然语言查询时，请在查询中包含全部的已知信息。\n",
    "13. 在执行分析或计算动作前，确保该分析或计算中涉及的所有子概念都已经得到了定义。\n",
    "14. 你不可以打印一个文件的全部内容，这样的操作代价太大，且会造成不可预期的后果，是被严格禁止的。\n",
    "15. 不要向用户提问。\n",
    "16. 在需要使用本地文件时，请务必使用相关工具查询，而不要编造文件名。\n",
    "\n",
    "你的任务是:\n",
    "{input}\n",
    "\n",
    "你有非常优秀的逻辑分析能力，可以通过因果关系找到最优的解决方案。\n",
    "\n",
    "你要参考之前的思考记录:\n",
    "{agent_scratchpad}\n",
    "\n",
    "你需要评估你的表现:\n",
    "1. 尽你最大的努力，用你最好的水平，通过分析和检查，做出最好的决定。\n",
    "2. 带着全局观，自我反思你计划与动作。\n",
    "3. 考虑你之前的策略与决策来改善的你的计划。\n",
    "4. 如果你反复得到相同的结果，修改你的计划和决策，避免死循环。\n",
    "5. 如果你当前的动作无法获取到需要的信息，尝试展开关键概念的定义，再重新推理。\n",
    "\n",
    "如果你必须选择工具才能完成任务，可以使用以下工具之一，它们又称为动作或actions:\n",
    "\n",
    "{tools}\n",
    "\n",
    "你有两种情况你都应当选择FINISH工具:\n",
    "\n",
    "(1) 如果任务显示“无”、“没有了”、“已完成”、“FINISH”或类似表达，你就选择FINISH工具，\n",
    "(2) 如果没有选择任何工具就获得输出，你就直接选择FINISH工具\n",
    "\n",
    "无论上述哪一种情况，你都必须将最终结果以键值对的方式输出给FINISH工具，其中键的名称是\"output\"，值就是你的最终结果。\n",
    "\n",
    "你必须根据以下格式说明，输出你的思考过程:\n",
    "1. 关键概念: 任务中涉及的组合型概念或实体。已经明确获得取值的关键概念，将其取值完整备注在概念后。\n",
    "2. 概念拆解: 将任务中的关键概念拆解为一系列待查询的子要素。每个关键概念一行，后接这个概念的子要素，每个子要素一行，行前以' -'开始。\n",
    "3. 反思:\n",
    "   - 自我反思，观察以前的执行记录，思考概念拆解是否完整、准确。\n",
    "   - 一步步思考是否每一个的关键概念或要素的查询都得到了准确的结果。\n",
    "   - 反思你已经得到哪个要素/概念。你得到的要素/概念取值是否正确。从当前的信息中还不能得到哪些要素/概念。\n",
    "   - 每个反思一行，行前以' -'开始。\n",
    "4. 思考: 观察执行记录和你的自我反思，并一步步思考\n",
    "  （1）分析要素间的依赖关系，例如：\n",
    "    i. 我是否需要先获得A的值/定义，才能通过A来获得B？\n",
    "    ii. 如果我先获得A，是否可以通过A筛选B，减少穷举每个B的代价？\n",
    "    iii. A和B是否存在在同一数据源中，我能否在获取A的同时获取B？\n",
    "    iv. 是否还有更高效或更聪明的办法来查询一个概念或要素？\n",
    "    v. 如果上一次尝试查询一个概念或要素时失败了，我是否可以尝试从另一个资源中再次查询？\n",
    "    vi. 诸如此类，你可以扩展更多的思考 ...\n",
    "  （2）根据以上分析，排列子要素间的查询优先级\n",
    "  （3）找出当前需要获得取值的子要素\n",
    "  注意，不要对要素的取值/定义做任何假设，确保你的信息来自给定的数据源！\n",
    "5. 推理: 根据你的反思与思考，一步步推理被选择的子要素取值的获取方式。如果前一次的计划失败了，请检查输入中是否包含每个概念/要素的明确定义，并尝试细化你的查询描述。\n",
    "6. 计划: 严格遵守以下规则，计划你的当前动作。\n",
    "  （1）详细列出当前动作的执行计划。只计划一步的动作。PLAN ONE STEP ONLY!\n",
    "  （2）一步步分析，包括数据源，对数据源的操作方式，对数据的分析方法。有哪些已知常量可以直接代入此次分析。\n",
    "  （3）不要尝试计算文件的每一个元素，这种计算代价太高，是严格禁止的。你可以通过分析找到更有效的方法，比如条件筛选。\n",
    "  （4）上述分析是否依赖某个要素的取值/定义，且该要素的取值/定义尚未获得。若果是，重新规划当前动作，确保所有依赖的要素的取值/定义都已经获得。\n",
    "  （5）不要对要素的取值/定义做任何假设，确保你的信息来自给定的数据源。不要编造信息。DO NOT MAKE UP ANY INFORMATION!!!\n",
    "  （6）确保你执行的动作涉及的所有要素都已获得确切的取值/定义。\n",
    "  （7）如果全部子任务已完成，请用FINISH动作结束任务。\n",
    "\n",
    "你必须根据以下格式说明，输出所选择执行的动作/工具/指令:\n",
    "{action_format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd252e7-9caf-41cf-9c04-77d65677a345",
   "metadata": {},
   "source": [
    "### ✍️ 自定义 OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "eef150fe-fbf2-4856-906b-b43f82a1aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Any, Union, Callable\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.agents.agent import AgentOutputParser, AgentAction, AgentFinish\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "125e6832-4d99-4214-bbfa-0c8bf033f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"The name of tool or action: FINISH or Other tool names.\"\n",
    "        )\n",
    "    args: Optional[Dict[str, Any]] = Field(\n",
    "        default=None,\n",
    "        description=\"Parameters of tool or action are composed of names and values.\"\n",
    "        )\n",
    "\n",
    "# 解析Action\n",
    "_action_output_parser = PydanticOutputParser(pydantic_object=Action)\n",
    "_action_parser_format = _action_output_parser.get_format_instructions()\n",
    "\n",
    "class ReasonOutputParser(AgentOutputParser):\n",
    "    \"\"\"解析单个动作的智能体action和输入参数。\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        action: Action = _action_output_parser.invoke(text)\n",
    "        name: Optional[str] = action.name\n",
    "        args: Optional[Dict[str, Any]] = action.args if text is not None else \"No Args\"\n",
    "        log: str = text if text is not None else \"\"\n",
    "\n",
    "        if name == \"FINISH\":\n",
    "            return AgentFinish(args, log)\n",
    "        elif name is not None:\n",
    "            return AgentAction(name, args, log)\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"Chain-of-Thought\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff71d04-4457-4761-abbf-d67abdcddd48",
   "metadata": {},
   "source": [
    "### ✍️ 自定义一个智能体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f301bc7c-0c38-49c9-8b5a-18ac4cc992b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "def _prompt_creator(prompt: str) -> Callable[[List[str]], str]:\n",
    "    def creator(tools: List[str]) -> str:\n",
    "        # 请注意，智谱AI等国内大模型对于pydantic的参数解析并不友好，使用JSON描述参数时会误读\n",
    "        # 因此，不要使用 render_text_description_and_args 来生成工具描述\n",
    "        tools_format = render_text_description(tools)\n",
    "\n",
    "        template = PromptTemplate.from_template(prompt)\n",
    "        return template.partial(\n",
    "            tools=tools_format,\n",
    "            action_format_instructions=_action_parser_format,\n",
    "        )\n",
    "\n",
    "    return creator\n",
    "\n",
    "# 基于 CoT 的智能体\n",
    "def create_cot_agent(llm: Any, prompt: Optional[str] = None, tools: List[str] = []) -> Any:\n",
    "    prompt_creator = _prompt_creator(PROMPT_COT)\n",
    "    if prompt is not None:\n",
    "        prompt_creator = _prompt_creator(prompt)\n",
    "\n",
    "    agent = (\n",
    "        RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"])\n",
    "        )\n",
    "        | prompt_creator(tools)\n",
    "        | llm\n",
    "        | ReasonOutputParser()\n",
    "    )\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2ce2c-8174-41b6-8e4e-5381e09ad13d",
   "metadata": {},
   "source": [
    "### ✍️ 尝试运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f6680288-649b-4ae5-b30a-e974cde9c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cot_executor(llm, tools):\n",
    "    # 定义 Agent\n",
    "    agent = create_cot_agent(llm, tools=tools)\n",
    "    # 定义 AgentExecutor\n",
    "    executor = AgentExecutor(agent=agent, tools=tools, verbose=False, handle_parsing_errors=True)\n",
    "    \n",
    "    return executor\n",
    "\n",
    "neighber = create_cot_executor(ChatZhipuAI(), [ask_neighber])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0df7abda-998c-4135-b5bf-218cff0b7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关键_概念_:\n",
      "-_ 马_冬_梅_住_址_\n",
      "\n",
      "概念_拆_解_:\n",
      "-_ 马_冬_梅_住_址_ -_ _位置_信息_\n",
      "\n",
      "反思_:\n",
      "-_ 需_要_准确_获得_马_冬_梅_的_住_址_信息_。\n",
      "-_ 当前_没有_获得_任何_关于_马_冬_梅_住_址_的信息_。\n",
      "\n",
      "思考_:\n",
      "-_ 要_获取_马_冬_梅_的_住_址_信息_，_可以使用_提供的_工具_“_ask__ne_igh_ber_”_。\n",
      "-_ _位置_信息_是_住_址_的核心_概念_，_可以通过_一次_工具_调用_获得_。\n",
      "\n",
      "推理_:\n",
      "-_ 使用_“_ask__ne_igh_ber_”_工具_，_查询_“_马_冬_梅_住_在哪里_”。\n",
      "\n",
      "计划_:\n",
      "-_ 使用_工具_“_ask__ne_igh_ber_”，_传入_查询_参数_“_马_冬_梅_住_在哪里_？”_。\n",
      "\n",
      "所_选择_执行_的动作_/_工具_/_指令_:\n",
      "```_json_\n",
      "{\"_name_\":_ \"_ask__ne_igh_ber_\",_ \"_args_\":_ {\"_query_\":_ \"_马_冬_梅_住_在哪里_？_\"}}\n",
      "```__关键_概念_:_ 马_冬_梅_住_址_（_已知_：_楼上_3_22_）\n",
      "\n",
      "概念_拆_解_:\n",
      "-_ 马_冬_梅_住_址_ -_ _位置_信息_（_已知_：_楼上_3_22_）\n",
      "\n",
      "反思_:\n",
      "-_ 已经_获得了_马_冬_梅_的_住_址_信息_，_位于_楼上_3_22_。\n",
      "\n",
      "思考_:\n",
      "-_ 任务_已经_完成_，_无需_进一步_查询_或_分析_。\n",
      "\n",
      "推理_:\n",
      "-_ 根_据_已_获取_的信息_，_可以直接_结束_任务_。\n",
      "\n",
      "计划_:\n",
      "-_ 使用_FIN_ISH_工具_结束_任务_。\n",
      "\n",
      "所_选择_执行_的动作_/_工具_/_指令_:\n",
      "```_json_\n",
      "{\"_name_\":_ \"_FIN_ISH_\",_ \"_args_\":_ {\"_output_\":_ \"_马_冬_梅_住在_楼上_3_22_\"}}\n",
      "```__"
     ]
    }
   ],
   "source": [
    "async for chunk in neighber.astream_events({\"input\": \"马冬梅家住哪里？\"}, version=\"v1\"):\n",
    "    event = chunk['event']\n",
    "    if(event == \"on_chat_model_stream\"):\n",
    "        if('chunk' in chunk['data']):\n",
    "            print(chunk['data']['chunk'].content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c7b21-65e0-4282-a023-3436685c7a22",
   "metadata": {},
   "source": [
    "# （三）再现《手撕AutoGPT》：langchain+智谱+智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7facba-ea0c-4f06-836e-770febfe3150",
   "metadata": {},
   "source": [
    "## 7、定义工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99833a-7cbd-4593-ae77-24247b0cd7fe",
   "metadata": {},
   "source": [
    "### ✍️ 列举文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "4a39dc24-6ef4-49bc-aa52-14011569bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "\n",
    "@tool\n",
    "def list_files(args=None) -> str:\n",
    "    \"\"\"如果需要查询资料，就首先使用该工具探查本地文件夹的结构和内容，展示它的文件名和文件夹名\"\"\"\n",
    "\n",
    "    # 工作目录\n",
    "    path = \"./data\"\n",
    "    print(\"当前目录为：\", path)\n",
    "\n",
    "    # 定义你想要过滤的模式\n",
    "    patterns = ['*.pdf', \"*.xlsx\"]\n",
    "\n",
    "    if(os.path.isdir(path)):\n",
    "        all_files = os.listdir(path)\n",
    "        # 过滤出所有匹配的文件\n",
    "        matching_files = [os.path.join(path, f) for f in all_files for p in patterns if fnmatch.fnmatch(f, p)]\n",
    "\n",
    "        return \"\\n\".join(matching_files)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "d4097187-2538-4440-837c-665b11e7fc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前目录为： ./data\n",
      "./data/2023年8月-9月销售记录.xlsx\n",
      "./data/供应商名录.xlsx\n",
      "./data/供应商资格要求.pdf\n"
     ]
    }
   ],
   "source": [
    "print(list_files.invoke({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84dc3bc-f2dd-44d7-92cd-36d175c91da3",
   "metadata": {},
   "source": [
    "### ✍️ 查询文档"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18407606-4160-4c54-8671-e4f67d452a7d",
   "metadata": {},
   "source": [
    "#### （1）准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "2a86ac37-0f36-4b26-a157-4ca33dbba461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c4d20b40-25cb-4538-8ef8-129c14f7016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_extension(filename: str) -> str:\n",
    "    return filename.split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "69cdb4f0-bf07-448e-83fb-2c2488573dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileLoadFactory:\n",
    "    @staticmethod\n",
    "    def get_loader(filename: str):\n",
    "        filename = filename.strip()\n",
    "        ext = get_file_extension(filename)\n",
    "        if ext == \"pdf\":\n",
    "            return PyPDFLoader(filename)\n",
    "        elif ext == \"docx\" or ext == \"doc\":\n",
    "            return Docx2txtLoader(filename)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"File extension {ext} not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "c14e4c9e-5d55-455b-b788-c6a83dddadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(filename: str) -> List[Document]:\n",
    "    file_loader = FileLoadFactory.get_loader(filename)\n",
    "    pages = file_loader.load_and_split()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b6e6a7-c326-4b87-8173-d720b4de0c3e",
   "metadata": {},
   "source": [
    "#### （2）使用 RAG 查询文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "b0fcda75-1a11-49d1-85df-6716984e06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def ask_docment(\n",
    "        filename: str,\n",
    "        query: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    如果给定一个文件，如Word或PDF文档，就可以根据该工具查询文件内容，以便回答问题。\n",
    "    考虑上下文信息，确保问题对相关概念的定义表述完整。\n",
    "    \"\"\"\n",
    "\n",
    "    raw_docs = load_docs(filename)\n",
    "    if len(raw_docs) == 0:\n",
    "        return \"抱歉，文档内容为空\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "                        chunk_size=1000,\n",
    "                        chunk_overlap=200,\n",
    "                        length_function=len,\n",
    "                        add_start_index=True,\n",
    "                    )\n",
    "    documents = text_splitter.split_documents(raw_docs)\n",
    "    if documents is None or len(documents) == 0:\n",
    "        return \"无法读取文档内容\"\n",
    "    db = Chroma.from_documents(documents, OpenAIEmbeddings(model=\"text-embedding-ada-002\"))\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(\n",
    "            temperature=0,\n",
    "            model_kwargs={\n",
    "                \"seed\": 42\n",
    "            },\n",
    "        ),  # 语言模型\n",
    "        chain_type=\"stuff\",  # prompt的组织方式\n",
    "        retriever=db.as_retriever()  # 检索器\n",
    "    )\n",
    "    response = qa_chain.invoke(query+\"(请用中文回答)\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24988a01-b887-41ab-9f6f-769fa42a533c",
   "metadata": {},
   "source": [
    "### ✍️ Excel 结构探查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "42346d58-b95e-466e-87e0-05c005600ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "0c5ffc59-fbe1-4968-bc56-38dbee922091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheet_names(\n",
    "        filename : str\n",
    ") -> str :\n",
    "    \"\"\"获取 Excel 文件的工作表名称\"\"\"\n",
    "    excel_file = pd.ExcelFile(filename.strip())\n",
    "    sheet_names = excel_file.sheet_names\n",
    "    return f\"这是 '{filename}' 文件的工作表名称：\\n\\n{sheet_names}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "63612915-fbfb-46d3-b2e4-93e4371af8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(\n",
    "        filename : str\n",
    ") -> str:\n",
    "    \"\"\"获取 Excel 文件的列名\"\"\"\n",
    "\n",
    "    # 读取 Excel 文件的第一个工作表\n",
    "    df = pd.read_excel(filename.strip(), sheet_name=0)  # sheet_name=0 表示第一个工作表\n",
    "    column_names = '\\n'.join(\n",
    "        df.columns.to_list()\n",
    "    )\n",
    "\n",
    "    result = f\"这是 '{filename.strip()}' 文件第一个工作表的列名：\\n\\n{column_names}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "987ceb8c-d051-4914-93c7-f1e5cbda0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_first_n_rows(\n",
    "        filename : str,\n",
    "        n : int = 3\n",
    ") -> str :\n",
    "    \"\"\"\n",
    "    如果给定一个Excel文件，就可以根据该工具探查表格文件的内容和结构，展示它的列名和前n行，n默认为3。\n",
    "    \n",
    "    使用该函数时应当准备提供filename和n两个参数，其中：\n",
    "    \n",
    "    - filename：要探查的Excel文件名\n",
    "    - n: 默认的行数\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    filename = filename.strip()\n",
    "    result = get_sheet_names(filename)+\"\\n\\n\"\n",
    "    result += get_column_names(filename)+\"\\n\\n\"\n",
    "\n",
    "    # 读取 Excel 文件的第一个工作表\n",
    "    df = pd.read_excel(filename, sheet_name=0)  # sheet_name=0 表示第一个工作表\n",
    "    n_lines = '\\n'.join(\n",
    "        df.head(n).to_string(index=False, header=True).split('\\n')\n",
    "    )\n",
    "\n",
    "    result += f\"这是 '{filename}' 文件第一个工作表的前{n}行样例：\\n\\n{n_lines}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce36f4-4637-4f30-8bf9-f08ff0c78f16",
   "metadata": {},
   "source": [
    "### ✍️ Excel 数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b83941-34f3-446f-8213-a922ba37444d",
   "metadata": {},
   "source": [
    "#### （1）准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "4e904aab-0239-4bad-9ac2-913b285d4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "# from Utils.PythonExecUtil import execute_python_code\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e6e9d-8278-47e9-94db-a5da3e94ca3a",
   "metadata": {},
   "source": [
    "#### （2）自定义一个OutputParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "5786995e-9011-4e46-a826-dec2543a746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PythonCodeParser(BaseOutputParser):\n",
    "    \"\"\"从OpenAI返回的文本中提取Python代码。\"\"\"\n",
    "\n",
    "    def _remove_marked_lines(self, input_str: str) -> str:\n",
    "        lines = input_str.strip().split('\\n')\n",
    "        if lines and lines[0].strip().startswith('```'):\n",
    "            del lines[0]\n",
    "        if lines and lines[-1].strip().startswith('```'):\n",
    "            del lines[-1]\n",
    "\n",
    "        ans = '\\n'.join(lines)\n",
    "        return ans\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        # 使用正则表达式找到所有的Python代码块\n",
    "        python_code_blocks = re.findall(r'```python\\n(.*?)\\n```', text, re.DOTALL)\n",
    "        # 从re返回结果提取出Python代码文本\n",
    "        python_code = None\n",
    "        if len(python_code_blocks) > 0:\n",
    "            python_code = python_code_blocks[0]\n",
    "            python_code = self._remove_marked_lines(python_code)\n",
    "        return python_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b77b4-5c15-42e8-84f1-f85cf142a181",
   "metadata": {},
   "source": [
    "#### （3）定义提示语模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "691458c9-ac30-4d79-9a16-e47c8a0f86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "excel_analyser_prompt = PromptTemplate.from_template(\"\"\"\n",
    "你的任务是先分析，再生成代码。\n",
    "\n",
    "请根据用户的输入，一步步分析：\n",
    "（1）用户的输入是否依赖某个条件，而这个条件没有明确赋值？\n",
    "（2）我是否需要对某个变量的值做假设？\n",
    "（3）已经从用户的输入中拆解概念，将其中包含的数字或实体名称，映射为所生成的函数入参，并在代码中使用？\n",
    "（4）不能生成用户输入中没有包含的函数入参，将导致严重后果，这一点是否已经确认？\n",
    "\n",
    "如果我需要对某个变量的值做假设，请直接输出：\n",
    "```python\n",
    "print(\"我需要知道____的值，才能生成代码。请完善你的查询。\") # 请将____替换为需要假设的的条件\n",
    "```\n",
    "否则，创建Python代码，分析指定文件的内容。\n",
    "\n",
    "MUST 确保你生成的代码按照固定格式：先定义一个带有参数的函数，再执行该函数完成分析任务。\n",
    "\n",
    "MUST 请不要将问题中的数字、名称写死在代码中，而是提取问题中对应的数字、名称等作为你定义的函数的入参变量，\n",
    "并在代码中做 ==、>、< 等逻辑判断时使用这些入参变量；\n",
    "MUST 确保问题中的所有数字或实体名称都做了上述的入参映射，不要遗漏。\n",
    "MUST 确保所有入参都使用相应默认值。\n",
    "\n",
    "MUST 请不要使用filename作为入参变量，直接写死在代码里即可。\n",
    "\n",
    "MUST 请在函数定义时增加文档字符串，针对问题总结函数的用途，并同时说明各参数的用途\n",
    "\n",
    "MUST 你生成代码中所有的常量都必须来自我给你的信息或来自文件本身。不要编造任何常量。\n",
    "如果常量缺失，你的代码将无法运行。你可以拒绝生成代码，但是不要生成编造的代码。\n",
    "确保你生成的代码最终以print的方式输出结果(回答用户的问题)。\n",
    "\n",
    "MUST 你可以使用的库只包括：pandas, re, math, datetime, openpyxl\n",
    "确保你的代码只使用上述库，否则你的代码将无法运行。\n",
    "当你引用这些库时，请在函数内部执行import。\n",
    "\n",
    "MUST 确保你的代码可以通过运行的。\n",
    "\n",
    "给定文件为：\n",
    "{{filename}}\n",
    "\n",
    "文件内容样例：\n",
    "{{inspections}}\n",
    "\n",
    "你输出的Python代码前后必须有markdown标识符，如下所示：\n",
    "```python\n",
    "# example code\n",
    "def hello(product):\n",
    "    print(product)\n",
    "```\n",
    "\n",
    "用户输入：\n",
    "{{query}}\n",
    "\"\"\", template_format=\"jinja2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a487a8fc-1531-401a-9b50-444029c6a0d7",
   "metadata": {},
   "source": [
    "#### （4）定义执行链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "73ca3e62-4479-4d58-882e-ea3c52085efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        temperature=0,\n",
    "        # model_kwargs={\"seed\": 42},\n",
    "    )\n",
    "analysis_chain = excel_analyser_prompt | llm | PythonCodeParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4413d08-258d-4203-a670-79b6dec4744a",
   "metadata": {},
   "source": [
    "#### （5）生成 python 代码并执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "08749f35-6a4d-414c-ae79-28b74d73cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import types\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "@tool\n",
    "def excel_analyse(query, filename):\n",
    "    \"\"\"如果给定一个Excel文件，就可以根据该工具分析其内容。\"\"\"\n",
    "\n",
    "    filename = filename.strip()\n",
    "    # columns = get_column_names(filename)\n",
    "    inspections = get_first_n_rows(filename, 3)\n",
    "\n",
    "    code = \"\"\n",
    "\n",
    "    # 打印详细信息\n",
    "    color_print(\"\\n#!/usr/bin/env python\", CODE_COLOR, end=\"\\n\")\n",
    "\n",
    "    # 生成代码\n",
    "    for c in analysis_chain.stream({\n",
    "        \"query\": query,\n",
    "        \"filename\": filename,\n",
    "        \"inspections\": inspections\n",
    "    }):\n",
    "        ## 打印详细信息\n",
    "        color_print(c, CODE_COLOR, end=\"\")\n",
    "        ## 收集代码成果\n",
    "        code += c\n",
    "\n",
    "    if code:\n",
    "        # 动态创建工具函数   \n",
    "        tree = ast.parse(code)\n",
    "        func_def = tree.body[0]\n",
    "        func_str = ast.unparse(func_def)\n",
    "        exec(func_str)\n",
    "        func = globals()[func_def.name]\n",
    "        tool = convert_to_openai_tool(func)\n",
    "        print(\"\\n New Tool:\")\n",
    "        print(tool)\n",
    "        \n",
    "        # 执行代码\n",
    "        return PythonREPL().run(code)\n",
    "        # return newTool.func()\n",
    "    else:\n",
    "        return \"没有找到可执行的Python代码\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0243d0-83c8-49fa-9b26-923435fa7fd7",
   "metadata": {},
   "source": [
    "### ✍️ FINISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a2ad2900-4873-4515-8d56-2086a6a9a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "\n",
    "finish_placeholder = StructuredTool.from_function(\n",
    "    func=lambda: None,\n",
    "    name=\"FINISH\",\n",
    "    description=\"用于表示任务完成的占位符工具\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613d468-d62b-4d22-afdd-fd32cd160c2e",
   "metadata": {},
   "source": [
    "### ✍️ 准备工具集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "e200b8c8-8835-471c-b211-c4509512247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Tool:  list_files\n",
      "DESC:  list_files(args=None) -> str - 如果需要查询资料，就首先使用该工具探查本地文件夹的结构和内容，展示它的文件名和文件夹名\n",
      "--------------------------------------------------------------------------------\n",
      "Tool:  ask_docment\n",
      "DESC:  ask_docment(filename: str, query: str) -> str - 如果给定一个文件，如Word或PDF文档，就可以根据该工具查询文件内容，以便回答问题。\n",
      "    考虑上下文信息，确保问题对相关概念的定义表述完整。\n",
      "--------------------------------------------------------------------------------\n",
      "Tool:  get_first_n_rows\n",
      "DESC:  get_first_n_rows(filename: str, n: int = 3) -> str - 如果给定一个Excel文件，就可以根据该工具探查表格文件的内容和结构，展示它的列名和前n行，n默认为3。\n",
      "    \n",
      "    使用该函数时应当准备提供filename和n两个参数，其中：\n",
      "    \n",
      "    - filename：要探查的Excel文件名\n",
      "    - n: 默认的行数\n",
      "--------------------------------------------------------------------------------\n",
      "Tool:  excel_analyse\n",
      "DESC:  excel_analyse(query, filename) - 如果给定一个Excel文件，就可以根据该工具分析其内容。\n",
      "--------------------------------------------------------------------------------\n",
      "Tool:  FINISH\n",
      "DESC:  FINISH() - 用于表示任务完成的占位符工具\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    list_files,\n",
    "    ask_docment,\n",
    "    get_first_n_rows,\n",
    "    excel_analyse,\n",
    "    finish_placeholder,\n",
    "]\n",
    "\n",
    "for t in tools:\n",
    "    print(\"-\"*80)\n",
    "    print(\"Tool: \", t.name)\n",
    "    print(\"DESC: \", t.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e77ba-68bc-491d-98db-23bce5c2aa39",
   "metadata": {},
   "source": [
    "## 8、基于 🦜🔗LangChain 的智能体对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddadab-5f65-48ba-b13a-f1bd887f329d",
   "metadata": {},
   "source": [
    "### ✍️ GPT4 + create_openai_tools_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9fd60e-e346-46ec-8b5d-306004e18a15",
   "metadata": {},
   "source": [
    "### ✍️ GLM4 + create_openai_tools_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc647c-00c2-4fa0-8413-4ab466e7d1b1",
   "metadata": {},
   "source": [
    "### ✍️ GPT4 + create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2f71f-8bdd-4c83-a7b0-380a2daa8a10",
   "metadata": {},
   "source": [
    "### ✍️ GLM4 + create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef8f49-425d-467e-a8df-41ebba848508",
   "metadata": {},
   "source": [
    "### ✍️ GPT4 + create_cot_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "483e9e06-178c-4235-97c0-2a5078cfe462",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_cot = create_cot_executor(ChatOpenAI(), tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "6db1e202-d83c-490e-ace0-5c64bddcf61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_{\n",
      "_ _ \"_name_\":_ \"_list__files_\",\n",
      "_ _ \"_args_\":_ {}\n",
      "_}__当前目录为： ./data\n",
      "_关_键_概_念_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "\n",
      "_概_念_拆_解_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "_ _ -_ _无_\n",
      "\n",
      "_反_思_:\n",
      "_-_ _通过_之_前_的_信息_并_不能_获_得_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_思_考_:\n",
      "_-_ 根_据_之_前_的_反_思_，_我们_需要_更_多_的_信息_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_推_理_:\n",
      "_-_ 根_据_当前_情_况_，_我们_需要_进_一_步_查询_相关_的_文件_和_数据_源_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_计_划_:\n",
      "_-_ 根_据_之_前_的_反_思_和_推_理_，_我们_需要_查询_\"_供_应_商_资_格_要_求_.pdf_\"_文件_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_{\n",
      "_ _ \"_name_\":_ \"_ask__document_\",\n",
      "_ _ \"_args_\":_ {\n",
      "_   _ \"_filename_\":_ \"./_data_/_供_应_商_资_格_要_求_.pdf_\",\n",
      "_   _ \"_query_\":_ \"_供_应_商_达_标_的_标_准_是_什_么_？_\"\n",
      "_ _ }\n",
      "_}___关_键_概_念_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "\n",
      "_概_念_拆_解_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "_ _ -_ _无_\n",
      "\n",
      "_反_思_:\n",
      "_-_ _通过_之_前_的_信息_并_不能_获_得_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_思_考_:\n",
      "_-_ 根_据_之_前_的_反_思_，_我们_需要_更_多_的_信息_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_推_理_:\n",
      "_-_ 根_据_当前_情_况_，_我们_需要_进_一_步_查询_相关_的_文件_和_数据_源_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_计_划_:\n",
      "_-_ 根_据_之_前_的_反_思_和_推_理_，_我们_需要_查询_\"_供_应_商_资_格_要_求_.pdf_\"_文件_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_我_将_执行_以下_动_作_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_:\n",
      "_{\n",
      "_ _ \"_name_\":_ \"_ask__document_\",\n",
      "_ _ \"_args_\":_ {\n",
      "_   _ \"_filename_\":_ \"./_data_/_供_应_商_资_格_要_求_.pdf_\",\n",
      "_   _ \"_query_\":_ \"_供_应_商_达_标_的_标_准_是_什_么_？_\"\n",
      "_ _ }\n",
      "_}___关_键_概_念_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "\n",
      "_概_念_拆_解_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "_ _ -_ _无_\n",
      "\n",
      "_反_思_:\n",
      "_-_ _通过_之_前_的_信息_并_不能_获_得_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_思_考_:\n",
      "_-_ 根_据_之_前_的_反_思_，_我们_需要_更_多_的_信息_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_推_理_:\n",
      "_-_ 根_据_当前_情_况_，_我们_需要_进_一_步_查询_相关_的_文件_和_数据_源_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_计_划_:\n",
      "_-_ 根_据_之_前_的_反_思_和_推_理_，_我们_需要_查询_\"_供_应_商_资_格_要_求_.pdf_\"_文件_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_我_将_执行_以下_动_作_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_:\n",
      "_{\n",
      "_ _ \"_name_\":_ \"_ask__document_\",\n",
      "_ _ \"_args_\":_ {\n",
      "_   _ \"_filename_\":_ \"./_data_/_供_应_商_资_格_要_求_.pdf_\",\n",
      "_   _ \"_query_\":_ \"_供_应_商_达_标_的_标_准_是_什_么_？_\"\n",
      "_ _ }\n",
      "_}___关_键_概_念_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "\n",
      "_概_念_拆_解_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "_ _ -_ _无_\n",
      "\n",
      "_反_思_:\n",
      "_-_ _通过_之_前_的_信息_并_不能_获_得_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_思_考_:\n",
      "_-_ 根_据_之_前_的_反_思_，_我们_需要_更_多_的_信息_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_推_理_:\n",
      "_-_ 根_据_当前_情_况_，_我们_需要_进_一_步_查询_相关_的_文件_和_数据_源_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_计_划_:\n",
      "_-_ 根_据_之_前_的_反_思_和_推_理_，_我们_需要_查询_\"_供_应_商_资_格_要_求_.pdf_\"_文件_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_我_将_执行_以下_动_作_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_:\n",
      "_{\n",
      "_ _ \"_name_\":_ \"_ask__document_\",\n",
      "_ _ \"_args_\":_ {\n",
      "_   _ \"_filename_\":_ \"./_data_/_供_应_商_资_格_要_求_.pdf_\",\n",
      "_   _ \"_query_\":_ \"_供_应_商_达_标_的_标_准_是_什_么_？_\"\n",
      "_ _ }\n",
      "_}___关_键_概_念_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "\n",
      "_概_念_拆_解_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "_ _ -_ _无_\n",
      "\n",
      "_反_思_:\n",
      "_-_ _通过_之_前_的_信息_并_不能_获_得_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_思_考_:\n",
      "_-_ 根_据_之_前_的_反_思_，_我们_需要_更_多_的_信息_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_推_理_:\n",
      "_-_ 根_据_当前_情_况_，_我们_需要_进_一_步_查询_相关_的_文件_和_数据_源_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_计_划_:\n",
      "_-_ 根_据_之_前_的_反_思_和_推_理_，_我们_需要_查询_\"_供_应_商_资_格_要_求_.pdf_\"_文件_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_我_将_执行_以下_动_作_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_:\n",
      "_{\n",
      "_ _ \"_name_\":_ \"_ask__document_\",\n",
      "_ _ \"_args_\":_ {\n",
      "_   _ \"_filename_\":_ \"./_data_/_供_应_商_资_格_要_求_.pdf_\",\n",
      "_   _ \"_query_\":_ \"_供_应_商_达_标_的_标_准_是_什_么_？_\"\n",
      "_ _ }\n",
      "_}___关_键_概_念_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "\n",
      "_概_念_拆_解_:\n",
      "_-_ _供_应_商_达_标_的_标_准_\n",
      "_ _ -_ _无_\n",
      "\n",
      "_反_思_:\n",
      "_-_ _通过_之_前_的_信息_并_不能_获_得_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_思_考_:\n",
      "_-_ 根_据_之_前_的_反_思_，_我们_需要_更_多_的_信息_来_获取_供_应_商_达_标_的_标_准_的_具_体_定义_和_取_值_。\n",
      "\n",
      "_推_理_:\n",
      "_-_ 根_据_当前_情_况_，_我们_需要_进_一_步_查询_相关_的_文件_和_数据_源_来__"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens. However, your messages resulted in 4113 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[387], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m gpt_cot\u001b[38;5;241m.\u001b[39mastream_events({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m供应商达标的标准是什么？\u001b[39m\u001b[38;5;124m\"\u001b[39m}, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     event \u001b[38;5;241m=\u001b[39m chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_chat_model_stream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:905\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m root_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;66;03m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m _astream_log_implementation(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    908\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    909\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    910\u001b[0m     diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    911\u001b[0m     with_streamed_output_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    913\u001b[0m ):\n\u001b[1;32m    914\u001b[0m     run_log \u001b[38;5;241m=\u001b[39m run_log \u001b[38;5;241m+\u001b[39m log\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;66;03m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:612\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;66;03m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:566\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    563\u001b[0m prev_final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    564\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    567\u001b[0m     prev_final_output \u001b[38;5;241m=\u001b[39m final_output\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1551\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1540\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1541\u001b[0m iterator \u001b[38;5;241m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1550\u001b[0m )\n\u001b[0;32m-> 1551\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;66;03m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1262\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1262\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39maplan(\n\u001b[1;32m   1263\u001b[0m         intermediate_steps,\n\u001b[1;32m   1264\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[1;32m   1266\u001b[0m     )\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:422\u001b[0m, in \u001b[0;36mRunnableAgent.aplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a streaming\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# fashion to make it possible to get access to the individual LLM tokens\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# when using stream_log with the Agent Executor.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mastream(\n\u001b[1;32m    423\u001b[0m     inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    424\u001b[0m ):\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m         final_output \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2471\u001b[0m, in \u001b[0;36mRunnableSequence.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput_aiter\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Input]:\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m-> 2471\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matransform(input_aiter(), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2472\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2454\u001b[0m, in \u001b[0;36mRunnableSequence.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matransform\u001b[39m(\n\u001b[1;32m   2449\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2450\u001b[0m     \u001b[38;5;28minput\u001b[39m: AsyncIterator[Input],\n\u001b[1;32m   2451\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2452\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2453\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Output]:\n\u001b[0;32m-> 2454\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform_stream_with_config(\n\u001b[1;32m   2455\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2456\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atransform,\n\u001b[1;32m   2457\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2458\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2459\u001b[0m     ):\n\u001b[1;32m   2460\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1616\u001b[0m, in \u001b[0;36mRunnable._atransform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1611\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m         py_anext(iterator),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   1614\u001b[0m     )\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1616\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m cast(Output, \u001b[38;5;28;01mawait\u001b[39;00m py_anext(iterator))\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:237\u001b[0m, in \u001b[0;36mLogStreamCallbackHandler.tap_output_aiter\u001b[0;34m(self, run_id, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtap_output_aiter\u001b[39m(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: UUID, output: AsyncIterator[T]\n\u001b[1;32m    235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[T]:\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Tap an output async iterator to stream its values to the log.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# root run is handled in .astream_log()\u001b[39;00m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_id \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_id:\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;66;03m# if we can't find the run silently ignore\u001b[39;00m\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;66;03m# eg. because this run wasn't included in the log\u001b[39;00m\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_map_by_run_id\u001b[38;5;241m.\u001b[39mget(run_id):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:2424\u001b[0m, in \u001b[0;36mRunnableSequence._atransform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2417\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39matransform(\n\u001b[1;32m   2418\u001b[0m         final_pipeline,\n\u001b[1;32m   2419\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2422\u001b[0m         ),\n\u001b[1;32m   2423\u001b[0m     )\n\u001b[0;32m-> 2424\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2425\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1077\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m final: Input\n\u001b[1;32m   1075\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1079\u001b[0m         final \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:1087\u001b[0m, in \u001b[0;36mRunnable.atransform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         final \u001b[38;5;241m=\u001b[39m final \u001b[38;5;241m+\u001b[39m chunk  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1087\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mastream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1088\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:308\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    303\u001b[0m         e,\n\u001b[1;32m    304\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    305\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    306\u001b[0m         ),\n\u001b[1;32m    307\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(\n\u001b[1;32m    311\u001b[0m         LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]),\n\u001b[1;32m    312\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:292\u001b[0m, in \u001b[0;36mBaseChatModel.astream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m generation: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_astream(\n\u001b[1;32m    293\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    294\u001b[0m     ):\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:511\u001b[0m, in \u001b[0;36mChatOpenAI._astream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m    510\u001b[0m default_chunk_class \u001b[38;5;241m=\u001b[39m AIMessageChunk\n\u001b[0;32m--> 511\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    512\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    513\u001b[0m ):\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    515\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py:1330\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[0;32m-> 1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1332\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m   1333\u001b[0m             {\n\u001b[1;32m   1334\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1335\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1336\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1337\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1338\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1339\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1340\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1341\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1342\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1343\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1344\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1345\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1346\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1347\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1348\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1349\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1350\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1351\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1352\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1353\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1354\u001b[0m             },\n\u001b[1;32m   1355\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m   1356\u001b[0m         ),\n\u001b[1;32m   1357\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1358\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1359\u001b[0m         ),\n\u001b[1;32m   1360\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1362\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   1363\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/openai/_base_client.py:1725\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1713\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1721\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1722\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1723\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1724\u001b[0m     )\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/openai/_base_client.py:1428\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1421\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1427\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[0;32m-> 1428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1429\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1430\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1431\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1432\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1433\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[1;32m   1434\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/openai/_base_client.py:1519\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[1;32m   1518\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1522\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1523\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1527\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens. However, your messages resulted in 4113 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"
     ]
    }
   ],
   "source": [
    "async for chunk in gpt_cot.astream_events({\"input\": \"供应商达标的标准是什么？\"}, version=\"v1\"):\n",
    "    event = chunk['event']\n",
    "    if(event == \"on_chat_model_stream\"):\n",
    "        if('chunk' in chunk['data']):\n",
    "            print(chunk['data']['chunk'].content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbf2ae2-cfa2-4d88-9f55-e79663ab361a",
   "metadata": {},
   "source": [
    "### ✍️ GLM4 + create_cot_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d7f510b5-0436-48a0-b8d8-7b56832d0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipu_cot = create_cot_executor(ChatZhipuAI(), tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "5d277d68-89b0-45bc-be93-d9e20fb32efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关键_概念_:\n",
      "-_ _供应商_达标_标准_\n",
      "\n",
      "概念_拆_解_:\n",
      "-_ _供应商_达标_标准_ -_ 具_体_标准_\n",
      "\n",
      "反思_:\n",
      "-_ 需_要从_给_定的_工具_中_查询_到_供应商_达标_的具体_标准_。\n",
      "\n",
      "思考_:\n",
      "-_ 根_据_任务_描述_，_我_需要_使用_工具_来_查询_供应商_达标_的标准_。_首先_，_我_需要_确认_是否有_相关的_文件_或_数据_源_包含_这些_信息_。\n",
      "-_ 如果_有_，_我_需要_确定_使用_哪个_工具_来_提取_这些_信息_。\n",
      "\n",
      "计划_:\n",
      "-_ 我_将_首先_使用_ list__files_ 工_具_来_探_查_本地_文件夹_，_查找_可能_包含_供应商_达标_标准的_文件_。\n",
      "\n",
      "所_选择_执行_的动作_/_工具_/_指令_:\n",
      "```_json_\n",
      "{\"_name_\":_ \"_list__files_\",_ \"_args_\":_ {}_}\n",
      "```__当前目录为： ./data\n",
      "关键_概念_:_ _供应商_达标_标准_\n",
      "\n",
      "概念_拆_解_:\n",
      "-_ _供应商_达标_标准_ -_ 具_体_标准_\n",
      "\n",
      "反思_:\n",
      "-_ 通过_ list__files_ 工_具_查询_，_已经_发现了_可能_包含_供应商_达标_标准的_文件_：“_供应商_资格_要求_.pdf_”_。\n",
      "-_ 需_要_使用_合适的_工具_从_“_供应商_资格_要求_.pdf_”_中_提取_具体_标准_。\n",
      "\n",
      "思考_:\n",
      "-_ 下_一步_我_需要_使用_ ask__doc_ment_ 工_具_读取_“_供应商_资格_要求_.pdf_”_文件_，_并_查询_关于_供应商_达标_的具体_标准_。\n",
      "\n",
      "计划_:\n",
      "-_ 我_将_使用_ ask__doc_ment_ 工_具_，_并_传入_以下_参数_：_filename_='_供应商_资格_要求_.pdf_'_，_query_='_供应商_达标_的具体_标准_是什么_？_'_。\n",
      "\n",
      "所_选择_执行_的动作_/_工具_/_指令_:\n",
      "```_json_\n",
      "{\"_name_\":_ \"_ask__doc_ment_\",_ \"_args_\":_ {\"_filename_\":_ \"_供应商_资格_要求_.pdf_\",_ \"_query_\":_ \"_供应商_达标_的具体_标准_是什么_？\"_ }}\n",
      "```__"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File path 供应商资格要求.pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[389], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m zhipu_cot\u001b[38;5;241m.\u001b[39mastream_events({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m供应商达标的标准是什么？\u001b[39m\u001b[38;5;124m\"\u001b[39m}, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     event \u001b[38;5;241m=\u001b[39m chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_chat_model_stream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/base.py:905\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m root_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;66;03m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m _astream_log_implementation(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    908\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    909\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    910\u001b[0m     diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    911\u001b[0m     with_streamed_output_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    913\u001b[0m ):\n\u001b[1;32m    914\u001b[0m     run_log \u001b[38;5;241m=\u001b[39m run_log \u001b[38;5;241m+\u001b[39m log\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;66;03m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:612\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;66;03m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tracers/log_stream.py:566\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    563\u001b[0m prev_final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    564\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    567\u001b[0m     prev_final_output \u001b[38;5;241m=\u001b[39m final_output\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1551\u001b[0m, in \u001b[0;36mAgentExecutor.astream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1540\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m   1541\u001b[0m iterator \u001b[38;5;241m=\u001b[39m AgentExecutorIterator(\n\u001b[1;32m   1542\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1550\u001b[0m )\n\u001b[0;32m-> 1551\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m step\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent_iterator.py:240\u001b[0m, in \u001b[0;36mAgentExecutorIterator.__aiter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_should_continue(\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_elapsed\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# take the next step: this plans next action, executes it,\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# yielding action and observation as they are generated\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     next_step_seq: NextStepOutput \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_executor\u001b[38;5;241m.\u001b[39m_aiter_next_step(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_to_tool_map,\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_mapping,\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs,\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_steps,\n\u001b[1;32m    245\u001b[0m         run_manager,\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[1;32m    247\u001b[0m         next_step_seq\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;66;03m# if we're yielding actions, yield them as they come\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;66;03m# do not yield AgentFinish, which will be handled below\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1318\u001b[0m, in \u001b[0;36mAgentExecutor._aiter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;66;03m# Use asyncio.gather to run multiple tool.arun() calls concurrently\u001b[39;00m\n\u001b[0;32m-> 1318\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aperform_agent_action(\n\u001b[1;32m   1321\u001b[0m             name_to_tool_map, color_mapping, agent_action, run_manager\n\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions\n\u001b[1;32m   1324\u001b[0m     ],\n\u001b[1;32m   1325\u001b[0m )\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;66;03m# TODO This could yield each result as it becomes available\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain/agents/agent.py:1351\u001b[0m, in \u001b[0;36mAgentExecutor._aperform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tool\u001b[38;5;241m.\u001b[39marun(\n\u001b[1;32m   1352\u001b[0m         agent_action\u001b[38;5;241m.\u001b[39mtool_input,\n\u001b[1;32m   1353\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1354\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[1;32m   1355\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_run_kwargs,\n\u001b[1;32m   1357\u001b[0m     )\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tools.py:510\u001b[0m, in \u001b[0;36mBaseTool.arun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;28mstr\u001b[39m(observation), color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    514\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tools.py:467\u001b[0m, in \u001b[0;36mBaseTool.arun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    466\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arun(\u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arun(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    470\u001b[0m     )\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tools.py:725\u001b[0m, in \u001b[0;36mStructuredTool._arun\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    713\u001b[0m     new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoroutine)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    715\u001b[0m     )\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoroutine(\n\u001b[1;32m    718\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoroutine(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    724\u001b[0m     )\n\u001b[0;32m--> 725\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run,\n\u001b[1;32m    728\u001b[0m     run_manager\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_sync() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    731\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/runnables/config.py:493\u001b[0m, in \u001b[0;36mrun_in_executor\u001b[0;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run a function in an executor.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    Output: The output of the function.\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, T], partial(copy_context()\u001b[38;5;241m.\u001b[39mrun, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)),\n\u001b[1;32m    496\u001b[0m     )\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[1;32m    499\u001b[0m     executor_or_config, partial(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs\n\u001b[1;32m    500\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/concurrent/futures/thread.py:52\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_core/tools.py:701\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[1;32m    693\u001b[0m     new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\n\u001b[1;32m    696\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    697\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    698\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    699\u001b[0m         )\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_argument_supported\n\u001b[0;32m--> 701\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m     )\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[363], line 11\u001b[0m, in \u001b[0;36mask_docment\u001b[0;34m(filename, query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@tool\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask_docment\u001b[39m(\n\u001b[1;32m      3\u001b[0m         filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      4\u001b[0m         query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      5\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    如果给定一个文件，如Word或PDF文档，就可以根据该工具查询文件内容，以便回答问题。\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    考虑上下文信息，确保问题对相关概念的定义表述完整。\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     raw_docs \u001b[38;5;241m=\u001b[39m \u001b[43mload_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(raw_docs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m抱歉，文档内容为空\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[385], line 2\u001b[0m, in \u001b[0;36mload_docs\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_docs\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m----> 2\u001b[0m     file_loader \u001b[38;5;241m=\u001b[39m \u001b[43mFileLoadFactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     pages \u001b[38;5;241m=\u001b[39m file_loader\u001b[38;5;241m.\u001b[39mload_and_split()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pages\n",
      "Cell \u001b[0;32mIn[384], line 7\u001b[0m, in \u001b[0;36mFileLoadFactory.get_loader\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m ext \u001b[38;5;241m=\u001b[39m get_file_extension(filename)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m ext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Docx2txtLoader(filename)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:157\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[0;34m(self, file_path, password, headers, extract_images)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpypdf package not found, please install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install pypdf`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(password\u001b[38;5;241m=\u001b[39mpassword, extract_images\u001b[38;5;241m=\u001b[39mextract_images)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/langchain-book-u1j6yauo-py3.10/lib/python3.10/site-packages/langchain_community/document_loaders/pdf.py:100\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[0;34m(self, file_path, headers)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a valid file or url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n",
      "\u001b[0;31mValueError\u001b[0m: File path 供应商资格要求.pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "async for chunk in zhipu_cot.astream_events({\"input\": \"供应商达标的标准是什么？\"}, version=\"v1\"):\n",
    "    event = chunk['event']\n",
    "    if(event == \"on_chat_model_stream\"):\n",
    "        if('chunk' in chunk['data']):\n",
    "            print(chunk['data']['chunk'].content, end=\"_\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf21ca-cf12-4cd3-a53c-f451ccafa852",
   "metadata": {},
   "source": [
    "# 结束了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f9b10-8af0-4a42-80be-935f1fc6c853",
   "metadata": {},
   "source": [
    "## ❤️ 总结\n",
    "\n",
    "- 我们一起解构了 langchain 部份组件的源码结构\n",
    "    - Runnable\n",
    "    - BaseLanguageModel / BaseChatModel\n",
    "    - create_openai_tools_agent\n",
    "    - create_react_agent\n",
    "    - Chain\n",
    "    - AgentExecutor\n",
    "- 我们从零开始集成了达模型到 langchain\n",
    "- 我们深度解构了 OpenAI / ReAct 智能体的细节\n",
    "- 我们自定义了符合 AgentExecutor 的 AutoGPT 智能体\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a62f75-52bd-462b-a396-8fb9751fc84a",
   "metadata": {},
   "source": [
    "## ❤️ 彩蛋\n",
    "\n",
    "**Langgraph中一些较新的智能体论文实践...**\n",
    "\n",
    "- [Agent Supervisor](https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/agent_supervisor.ipynb)\n",
    "- [Hierarchical Agent Teams](https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/hierarchical_agent_teams.ipynb)\n",
    "- [Multi Agent Collaboration](https://github.com/langchain-ai/langgraph/blob/main/examples/multi_agent/multi-agent-collaboration.ipynb)\n",
    "- [Plan And Execute](https://github.com/langchain-ai/langgraph/blob/main/examples/plan-and-execute/plan-and-execute.ipynb)\n",
    "- [ReWoo](https://github.com/langchain-ai/langgraph/blob/main/examples/rewoo/rewoo.ipynb)\n",
    "- [Reflexion](https://github.com/langchain-ai/langgraph/blob/main/examples/reflexion/reflexion.ipynb)\n",
    "- [Self Discover](https://github.com/langchain-ai/langgraph/blob/main/examples/self-discover/self-discover.ipynb)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fb4c5-ce60-45f1-b44a-a1aeceba867e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
