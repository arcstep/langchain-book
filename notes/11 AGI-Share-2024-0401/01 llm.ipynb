{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5b5362-cf90-4d8a-9c70-3db56e3f8dcc",
   "metadata": {},
   "source": [
    "# ğŸ¦œğŸ”— è§£è¯»LangChainæ ¸å¿ƒæºç ï¼šå…³äºLLMå’ŒAgentï¼ˆä¸Šï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09652ad-45cf-4152-8794-2639a92a4ac2",
   "metadata": {},
   "source": [
    "# è¯¾ç¨‹å¼€å§‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac26c1-1878-43d9-984d-bebacabccefb",
   "metadata": {},
   "source": [
    "## è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb7b7a-d4a8-4e8d-b757-a55062c3fad8",
   "metadata": {},
   "source": [
    "- ğŸŒ¹ ä¸€èµ·é˜…è¯» Langchain ç›¸å…³ç»„ä»¶çš„æºç ï¼Œä»¥ä¾¿æ›´å¥½åœ°é˜…è¯»å®˜æ–¹æ–‡æ¡£\n",
    "- ğŸŒ¹ æŒæ¡ Langchain æ–‡æ¡£ä¸­æœªæ›¾æåŠã€ç¿»çœ‹æºç æ‰çŸ¥æ™“çš„å®ç”¨æŠ€å·§\n",
    "- âœï¸ ä»é›¶å¼€å§‹é›†æˆæ™ºè°±å¤§æ¨¡å‹åˆ° LangChainï¼šè§£å†³æ™ºè°±å®˜æ–¹SDKä¸å…¼å®¹çš„é—®é¢˜\n",
    "- âœï¸ æŒ‰ LangChain æ¡†æ¶è‡ªå®šä¹‰ä¸€ä¸ªæ™ºèƒ½ä½“ï¼šå†ç°ã€Šæ‰‹æ’•AutoGPTã€‹ä¸­çš„æ™ºèƒ½ä½“\n",
    "- âœï¸ æœ€ç»ˆå®è·µï¼šå†ç°ã€Šæ‰‹æ’•AutoGPTã€‹ï¼šlangchain+è‡ªå®šä¹‰å¤§æ¨¡å‹+è‡ªå®šä¹‰æ™ºèƒ½ä½“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff511b-10e1-43d4-92e0-829a1fe4d5d2",
   "metadata": {},
   "source": [
    "## æ¶‰åŠçš„èµ„æº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7f60d-7043-42e0-98c2-459355c52f19",
   "metadata": {},
   "source": [
    "### â¤ï¸ LangChain å®˜ç½‘\n",
    "\n",
    "[langchainå®˜ç½‘çš„pythonæ–‡æ¡£](https://python.langchain.com/docs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7561bf-b6bd-4b3b-aa25-cf2527c49a2e",
   "metadata": {},
   "source": [
    "### â¤ï¸ LangChain æ¨¡å—æºç æ¦‚è§ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4481a6-d92d-4df6-8cfd-65e57c2463f5",
   "metadata": {},
   "source": [
    "[ğŸ”— æŸ¥çœ‹æ ¸å¿ƒæºç èµ„æº](https://github.com/langchain-ai/langchain/tree/master/libs)\n",
    "\n",
    "| æºç ä½ç½® | åŠŸèƒ½æè¿° |\n",
    "| :--- | :--- |\n",
    "| [langchain/libs/langchain/langchain](https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain) | æ¨¡å—å…¥å£ï¼Œä¼šå¯¼å…¥coreã€communityç­‰å…¶ä»–æ¨¡å— |\n",
    "| [langchain/libs/core/langchain_core](https://github.com/langchain-ai/langchain/tree/master/libs/core/langchain_core) | æ ¸å¿ƒç»„ä»¶å’Œå…³é”®çš„åŸºç±»å®ç° |\n",
    "| [langchain/libs/partners/openai/langchain_openai](https://github.com/langchain-ai/langchain/tree/master/libs/partners/openai/langchain_openai) | åˆä½œä¼™ä¼´ï¼ˆå®˜æ–¹åˆä½œï¼‰ç»„ä»¶ |\n",
    "| [langchain/libs/community/langchain_community](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community) | ç¤¾åŒºï¼ˆéå®˜æ–¹ï¼‰ç»„ä»¶ |\n",
    "| [langchain/libs/experimental/langchain_experimental](https://github.com/langchain-ai/langchain/tree/master/libs/experimental/langchain_experimental) | è¯•éªŒæ€§åŠŸèƒ½ï¼ˆå‰æ²¿æ¢ç´¢ç»„ä»¶ï¼Œä¸å¯¹ç‰ˆæœ¬ç¨³å®šåšæ‰¿è¯ºï¼‰ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eff717-2f78-43a7-87c0-9d41f329206a",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ æ¨èé˜…è¯»ï¼šä» Langchain çš„æœ€æ ¸å¿ƒç»„ä»¶ Runnable å¼€å§‹é˜…è¯»æºç \n",
    "\n",
    "[ğŸ”— æŸ¥çœ‹ langchain_core/runnables/base.py#L104](https://github.com/langchain-ai/langchain/blob/ad77fa15eec4dae431171b7e8c13b8c1f9edec98/libs/core/langchain_core/runnables/base.py#L104)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601bed1-2ed8-4582-95d5-b25a3568ba29",
   "metadata": {},
   "source": [
    "**ï¼ˆ1ï¼‰Runnableå®ç”¨æ–¹æ³•ï¼š**\n",
    "\n",
    "- Runnable\n",
    "    - assign()\n",
    "    - bind()\n",
    "    - with_config()\n",
    "    - get_name()\n",
    "    - get_graph()\n",
    "    - get_prompts()\n",
    "    - input_schema\n",
    "    - output_schema\n",
    "    - invoke / ainvoke / batch / abatch \n",
    "    - stream /astream / astream_log / astream_events\n",
    "\n",
    "----\n",
    "**ï¼ˆ2ï¼‰RunnableSerializableå®ç”¨æ–¹æ³•ï¼š**\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - dumps()\n",
    "        - loads()\n",
    "        - first()\n",
    "        - last()\n",
    "        - middle()\n",
    "\n",
    "----\n",
    "**ï¼ˆ3ï¼‰é…ç½®èƒ½åŠ›å­ç±»ï¼š**\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - RunnableBindingBase\n",
    "            - RunnableBindingï¼ˆå‘Runnableå®ä¾‹ä¼ é€’å‚æ•°ï¼‰\n",
    "        - DynamicRunnable\n",
    "            - RunnableConfigurableFields\n",
    "            - RunnableConfigurableAlternatives\n",
    "\n",
    "----\n",
    "**ï¼ˆ4ï¼‰æµç¨‹æ§åˆ¶å­ç±»ï¼š**\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - RunnablePassthroughï¼ˆä¼ é€’é¢å¤–è¾“å…¥ï¼‰\n",
    "        - RunnableSequenceï¼ˆå®ç°é¡ºåºæ‰§è¡Œï¼Œå¯ä»¥ç”¨é‡è½½çš„`|`ç¬¦å·æˆ–`RunnableSequence`æ¥æ„é€ ï¼‰\n",
    "        - RunnableParallelï¼ˆå®ç°å¹¶è¡Œæ‰§è¡Œï¼Œå¯ä»¥ç”¨`Dict`æˆ–`RunnableParallel`ç±»æ¥æ„é€ ï¼Œåˆ«å`RunnableMap`ï¼‰\n",
    "\n",
    "----\n",
    "**ï¼ˆ5ï¼‰å¤§æ¨¡å‹å­ç±»ï¼š**\n",
    "\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseLanguageModel\n",
    "            - BaseLLMï¼ˆæ´¾ç”Ÿå…¶ä»–å¤§æ¨¡å‹ï¼‰\n",
    "                - BaseOpenAIï¼ˆæ´¾ç”Ÿå…¶ä»–å¤§æ¨¡å‹ï¼‰\n",
    "                    - OpenAI\n",
    "                - LLM\n",
    "                    - ...\n",
    "                - ...\n",
    "            - BaseChatModel\n",
    "                - ChatOpenAI\n",
    "                - ...\n",
    "\n",
    "----\n",
    "**ï¼ˆ6ï¼‰æç¤ºè¯­å­ç±»ï¼š**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BasePromptTemplate `[Dict, PromptValue]`\n",
    "            - StringPromptTemplateï¼ˆå­—ç¬¦ä¸²æ¨¡æ¿ï¼‰\n",
    "            - BaseChatPromptTemplateï¼ˆå¯¹è¯æ¨¡æ¿ï¼‰\n",
    "            - ImagePromptTemplate\n",
    "            - PipelinePromptTemplate\n",
    "\n",
    "----\n",
    "**ï¼ˆ7ï¼‰æ£€ç´¢å™¨å­ç±»ï¼š**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseRetriever `[RetrieverInput, RetrieverOutput]`ï¼ˆæ´¾ç”Ÿå„ç±»æ£€ç´¢å™¨ï¼‰\n",
    "\n",
    "----\n",
    "**ï¼ˆ8ï¼‰Toolå­ç±»ï¼š**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseTool `[Union[str, Dict], Any]`ï¼ˆæ´¾ç”Ÿå„ç±»å·¥å…·ï¼‰\n",
    "\n",
    "----\n",
    "**ï¼ˆ9ï¼‰è¾“å‡ºè§£æå­ç±»ï¼š**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - BaseGenerationOutputParser `[Union[str, BaseMessage], T]`\n",
    "        - BaseOutputParserï¼ˆæ´¾ç”Ÿå„ç±»è¾“å‡ºè§£æï¼‰\n",
    "\n",
    "----\n",
    "**ï¼ˆ10ï¼‰è¾“å…¥èµ‹å€¼å­ç±»ï¼š**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - RunnablePassthrough\n",
    "        - RunnableAssign\n",
    "        - RunnablePick\n",
    "\n",
    "----\n",
    "**ï¼ˆ11ï¼‰é—ç•™Chainå­ç±»ï¼š**\n",
    "- Runnable\n",
    "    - RunnableSerializable\n",
    "        - Chainï¼ˆç»“æ„åŒ–Runnableï¼‰\n",
    "            - AgentExecutorï¼ˆæ‰§è¡Œæ™ºèƒ½ä½“ï¼‰\n",
    "\n",
    "----\n",
    "**ï¼ˆ12ï¼‰å¿«é€Ÿè‡ªå®šä¹‰Runnableçš„å·¥å…·å­ç±»ï¼š**\n",
    "- Runnableï¼ˆï¼‰\n",
    "    - RunnableGeneratorï¼ˆå¸¸ç”¨äºå¤„ç†è¾“å‡ºå¯èƒ½æ˜¯è¿­ä»£å™¨ç»“æœçš„chainï¼‰\n",
    "    - RunnableLambdaï¼ˆå¸¸ç”¨äºåŒ…è£…æ™®é€šå‡½æ•°ï¼Œè£…é¥°å‡½æ•°@chainï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c33759-7be9-4a3a-be4b-7e42b83d3777",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ æœ¬èŠ‚ï¼ˆä¸ŠåŠéƒ¨ä»½ï¼‰æ¶‰åŠçš„ LangChain æºç \n",
    "\n",
    "- ğŸŒ¹ æŸ¥çœ‹ Runnableï¼š[langchain_core/runnables/base.py#L104](https://github.com/langchain-ai/langchain/blob/ad77fa15eec4dae431171b7e8c13b8c1f9edec98/libs/core/langchain_core/runnables/base.py#L104)\n",
    "- ğŸŒ¹ æŸ¥çœ‹ BaseLanguageModelï¼š[langchain_core/language_models/base.py](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/base.py#L74-L81)\n",
    "- ğŸŒ¹ æŸ¥çœ‹ BaseChatModelï¼š[langchain_core/language_models/chat_models.py](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/chat_models.py#L100)\n",
    "- ğŸŒ¹ æŸ¥çœ‹ OpenAI é£æ ¼çš„æ¶ˆæ¯è½¬æ¢ï¼š [langchain_community.adapters.openai](https://github.com/langchain-ai/langchain/blob/3f7da03dd89e76f290ce361c72d1676319110163/libs/community/langchain_community/adapters/openai.py#L112-L156)\n",
    "- ğŸŒ¹ æŸ¥çœ‹å¯¹è¯æ¶ˆæ¯è¯­æ³•ç³–ï¼š[langchain_core/messages/utils.py](https://github.com/langchain-ai/langchain/blob/c93d4ea91cfcf55dfe871931d42aa22562f8dae2/libs/core/langchain_core/messages/utils.py#L130-L168)\n",
    "- ğŸŒ¹ æŸ¥çœ‹æ ¸å¿ƒæºç èµ„æºï¼š[github.com/langchain-ai](https://github.com/langchain-ai/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936103d-a47c-4455-81ca-10a8cbb8449a",
   "metadata": {},
   "source": [
    "# ï¼ˆä¸€ï¼‰è§£è¯»æºç ï¼Œé›†æˆè‡ªå·±çš„å¤§æ¨¡å‹åˆ° langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2eacc5-b64f-43dd-ab95-0afe81f827a6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>å¹²è´§ä»è¿™é‡Œå¼€å§‹ï¼</b><br>\n",
    "    æ¥ä¸‹æ¥çš„ä¾‹å­ä¸­ï¼Œä¼šç©¿æ’ langchian æºç è§£è¯»ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4086972-8af4-41e8-9f1d-7d3a5e984bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a33f05-0ea9-427c-b851-6511e0b9fc29",
   "metadata": {},
   "source": [
    "## 1ã€å¤§æ¨¡å‹çš„ä¸€èˆ¬ç”¨æ³•å›é¡¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f07493-0a57-4c60-a846-e6b1b69bfa46",
   "metadata": {},
   "source": [
    "### âœï¸ ä½¿ç”¨ OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f9e2e4-782e-466b-be9d-c23b0c30242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4db118-7b74-4d8e-8d9c-e8976ff4294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke\n",
    "text = \"ä½ çŸ¥é“ã€Œå¤æ´›ç‰¹çƒ¦æ¼ã€è¿™éƒ¨ç”µå½±å—ï¼Ÿ\"\n",
    "response = llm.invoke(text)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad948cb-8584-43f4-9dce-b008fa6cbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream\n",
    "for chunk in llm.stream(text):\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d63eec-9f22-4f5b-94bf-40f721313ad1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒ</b><br>\n",
    "    langchain æ”¯æŒçš„8ä¸ªæ–¹æ³•éƒ½åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹ä½¿ç”¨ï¼Ÿ\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d2136-fe1d-4723-87d3-162309f07230",
   "metadata": {},
   "source": [
    "- invokeï¼šæœ€ç®€å•\n",
    "- batch: åå°æ‰¹é‡\n",
    "- streamï¼šè®©ç”¨æˆ·ä½“éªŒæµå¼è¾“å‡º\n",
    "- ainvoke / astream / abatch: å®ç°å¼‚æ­¥ä½“éªŒ\n",
    "- astream_log / astream_events: ä»Runableã€LCELã€æ™ºèƒ½ä½“ã€langgraphç­‰æå–ç‰¹å®šçš„æµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803877e-8f15-4a3b-88a5-fcfdc5b1dea5",
   "metadata": {},
   "source": [
    "### âœï¸ LCELï¼šLLM + Prompt + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dea0d5-8c5c-436d-b006-67b07eceae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"ä½ çŸ¥é“{name}è¿™éƒ¨ç”µå½±å—?\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "for chunk in chain.stream({\"name\": \"å¤æ´›ç‰¹çƒ¦æ¼\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73527d37-fdb8-4d76-b70c-4ce1c209a3ed",
   "metadata": {},
   "source": [
    "## 2ã€ç®€å•çš„å¼€å§‹ï¼šå®ç°ã€Œæ¥¼ä¸‹é‚»å±…è€å¤§çˆ·ã€AIå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc945190-d75b-49de-94f5-801ee3125488",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>âš ï¸ è¦æ·±åº¦ä½¿ç”¨ langchain å°±å¿…é¡»é˜…è¯»æºç ï¼š</b><br>\n",
    "    åƒé›†æˆè‡ªå·±çš„å¤§æ¨¡å‹åˆ° langchain è¿™æ ·çš„ä»»åŠ¡ï¼Œlangchain æ–‡æ¡£ä¸­åŸºæœ¬æœªæ›¾æåŠã€‚<br>\n",
    "    å› æ­¤ï¼Œå¿…é¡»ç¿»çœ‹æºç æ‰èƒ½ææ¸…æ¥šå®ç°çš„æœºç†ã€‚<br><br>\n",
    "    ä½† langchain çš„ğŸŒ¹é­…åŠ›ğŸŒ¹å°±åœ¨äºï¼šä½ å¯ä»¥å‚ä¸communityï¼Œæˆ–å»ºç«‹è‡ªå·±çš„community ï¼\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3028e-da74-4247-af83-d76f03544797",
   "metadata": {},
   "source": [
    "### ğŸ¦œ éœ€æ±‚åˆ†æï¼šå‚è€ƒç”µå½±ç‰‡æ®µï¼ŒæŠŠã€Œéå¸¸æœ‰æ™ºæ…§çš„æ¥¼ä¸‹é‚»å±…è€å¤§çˆ·ã€å˜æˆ AIå¤§æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9838b374-9a07-4f26-b3cc-7004e4ddf08f",
   "metadata": {},
   "source": [
    "è¿™ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å…ˆè®²æ¸…æ¥šlangchainçš„å¤§æ¨¡å‹æ ‡å‡†å®ç°æ¡†æ¶ï¼Œä¸‹ä¸ªä¾‹å­å†è®²å¦‚ä½•å¯¹æ¥å®é™…çš„å¤§æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6fe6d-6fdd-49ea-88ce-496eddd23e5b",
   "metadata": {},
   "source": [
    "1. ä½¿ç”¨å¤§æ¨¡å‹ï¼šæ¨¡æ‹Ÿä¸€ä¸ªå¤§æ¨¡å‹\n",
    "2. ç”Ÿæˆèƒ½åŠ›ï¼šæåŠé©¬å†¬æ¢…æ—¶ç”Ÿæˆæ‰“å²”é—²èŠï¼ˆé©¬ä»€ä¹ˆæ¢…ï¼Ÿé©¬å†¬ä»€ä¹ˆï¼Ÿä»€ä¹ˆå†¬æ¢…ï¼Ÿï¼‰ï¼Œå…¶ä½™ç”Ÿæˆâ€œå“¦...â€œ\n",
    "\n",
    "![é©¬ä»€ä¹ˆæ¢…ï¼Ÿé©¬å†¬ä»€ä¹ˆï¼Ÿä»€ä¹ˆå†¬æ¢…ï¼Ÿ](./madongmei.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0526e-50a9-481f-ae14-6433fc114d25",
   "metadata": {},
   "source": [
    "### âœï¸ åŸºæœ¬å®ç°ï¼šinvoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2c9ba-39af-488b-af00-d272b7bff551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from typing import Any, Dict, Iterator, List, Optional, Union\n",
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, HumanMessageChunk, AIMessage, AIMessageChunk, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebdb44f-afd7-4ffc-9419-56e144a6d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatWithOlderAI(BaseChatModel):\n",
    "    \"\"\"æ¨¡æ‹Ÿè·Ÿé©¬å†¬æ¢…æ¥¼ä¸‹é‚»å±…è€å¤§çˆ·çš„å¯¹è¯\"\"\"\n",
    "\n",
    "    # å¿…é¡»å®ç°\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"chat-with-neighber-older\"\n",
    "\n",
    "    # å¿…é¡»å®ç°\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        generations = [ChatGeneration(message=res) for res in self._ask_remote(messages)]\n",
    "        return ChatResult(generations=generations)\n",
    "\n",
    "    # æœ‰è€å¤§çˆ·çš„æ™ºæ…§è®¡æ—¶å‘¨æœŸ\n",
    "    i: int = 0\n",
    "\n",
    "    # è®¿é—®è¿œç¨‹å¤§æ¨¡å‹\n",
    "    # å½“ä½ éœ€è¦å®ç°è‡ªå·±çš„å¤§æ¨¡å‹æ—¶ï¼Œä¸»è¦æ˜¯æ›¿æ¢è¿™éƒ¨åˆ†\n",
    "    def _ask_remote(self, messages: List[BaseMessage]) -> List[BaseMessage]:\n",
    "        answers = [HumanMessage(m) for m in [\n",
    "            \"é©¬ä»€ä¹ˆæ¢…ï¼Ÿ\",\n",
    "            \"ä»€ä¹ˆå†¬æ¢…ï¼Ÿï¼Ÿ\",\n",
    "            \"é©¬ä¸œä»€ä¹ˆï¼Ÿï¼Ÿï¼Ÿ\",\n",
    "        ]]\n",
    "        \n",
    "        if(re.search(\"é©¬å†¬æ¢…\", messages[0].content)):\n",
    "            response = answers[self.i]\n",
    "            self.i = (self.i + 1) if self.i < (len(answers) - 1) else 0\n",
    "        else:\n",
    "            response = AIMessage(\"å“¦...\")\n",
    "            \n",
    "        return [response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb12783-b794-4ce2-8ace-4bd781be835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [[HumanMessage(m)] for m in [\n",
    "    \"å¤§çˆ·ï¼Œæ¥¼ä¸Š322ä½çš„æ˜¯é©¬å†¬æ¢…å®¶å—ï¼Ÿ\",\n",
    "    \"é©¬å†¬æ¢…å•Š\",\n",
    "    \"é©¬å†¬æ¢…ï¼\",\n",
    "    \"æˆ‘æ˜¯è¯´é©¬å†¬æ¢…ï¼\",\n",
    "    \"æ‚¨æ­‡ç€å§...\",\n",
    "]]\n",
    "\n",
    "llm = ChatWithOlderAI()\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question[0].content}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    print(llm.invoke(question).content, end=\"\")\n",
    "    # for chunk in llm.stream(question):\n",
    "    #     print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8231e5a-c8b9-4d8e-8e56-280ccc889fd7",
   "metadata": {},
   "source": [
    "### âœï¸ æ”¯æŒæµå¼è¾“å‡ºï¼šstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2633f0-9002-4684-818a-44daed91c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamChatWithOlderAI(ChatWithOlderAI):\n",
    "    \"\"\"æ¨¡æ‹Ÿè·Ÿå¤§çˆ·çš„å¯¹è¯ï¼Œæ”¯æŒæµ\"\"\"\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        *args,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        response = self._ask_remote(messages)\n",
    "        for chunk in response[0].content:\n",
    "            time.sleep(0.1)\n",
    "            yield ChatGenerationChunk(message=AIMessageChunk(content=chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c1cf8-0886-423f-9710-cd10ef7c6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_stream = StreamChatWithOlderAI()\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question[0].content}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    for chunk in llm_stream.stream(question):\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa2f9d-2177-4c7e-b935-a947b675ee9a",
   "metadata": {},
   "source": [
    "### âœï¸  LCELï¼šPrompt + LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d4000-66db-4be9-9dae-e9ab7e14cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "questions_text = [\n",
    "    \"æ¥¼ä¸Š322ä½çš„æ˜¯é©¬å†¬æ¢…å®¶å—ï¼Ÿ\",\n",
    "    \"é©¬å†¬æ¢…å•Š\",\n",
    "    \"é©¬å†¬æ¢…ï¼\",\n",
    "    \"æˆ‘æ˜¯è¯´é©¬å†¬æ¢…ï¼\",\n",
    "    \"å¤§çˆ·æ‚¨æ­‡ç€å§...\"\n",
    "]\n",
    "\n",
    "llm_stream = StreamChatWithOlderAI()\n",
    "prompt = PromptTemplate.from_template(\"å¤§çˆ·ï¼Œ{question}\")\n",
    "chain = prompt | llm_stream | StrOutputParser()\n",
    "\n",
    "for question in questions_text:\n",
    "    print(f\"\\n\\nå¤æ´›ï¼š{question}\")\n",
    "    print(\"å¤§çˆ·ï¼š\", end=\"\")\n",
    "    for chunk in chain.stream({\"question\": question}):\n",
    "        print(chunk, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae412a-cfd5-4160-80df-a6265560cd34",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ å®¡è§†é“¾ä¸Šå„èŠ‚ç‚¹çš„è¾“å…¥è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeecb41-c94c-4046-817f-8642d0ecb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c055383-7ea1-4db2-b638-82d93df772d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c05f8e-d9e2-4a26-9558-aaa2dbcc8ad9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm_stream.input_schema.schema()\n",
    "# chain.input_schema.schema()\n",
    "# prompt.output_schema.schema()\n",
    "# prompt.invoke({\"question\":\"ä½ å¥½\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bc9d3-ecbc-4327-99bd-0d1cb97389f2",
   "metadata": {},
   "source": [
    "### ğŸŒ¹ é˜…è¯»æºç ï¼šå®ç° langchain å¤§æ¨¡å‹çš„åŸç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62fc73-8277-4bea-97f6-d79a08dd64e9",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰BaseLanguageModel\n",
    "\n",
    "[ğŸ”— æŸ¥çœ‹ langchain_core/language_models/base.py](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/base.py#L74-L81)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e482c-ba97-4bb7-ad16-0398d7110039",
   "metadata": {},
   "source": [
    "```python\n",
    "class BaseLanguageModel(\n",
    "    RunnableSerializable[LanguageModelInput, LanguageModelOutputVar], ABC\n",
    "):\n",
    "    \"\"\"Abstract base class for interfacing with language models.\n",
    "\n",
    "    All language model wrappers inherit from BaseLanguageModel.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c54270-3787-4248-85d7-fce89e39bbe6",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰BaseChatModel\n",
    "\n",
    "[ğŸ”— æŸ¥çœ‹ langchain_core/language_models/chat_models.py](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/language_models/chat_models.py#L100)\n",
    "\n",
    "**æ ¸å¿ƒé€»è¾‘ï¼š**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c153a-fc04-47bb-96d1-8a57741f1de1",
   "metadata": {},
   "source": [
    "```python\n",
    "class BaseChatModel(BaseLanguageModel[BaseMessage], ABC):\n",
    "    \"\"\"Base class for Chat models.\"\"\"\n",
    "\n",
    "    ...\n",
    "\n",
    "    def invoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.generate_prompt(...)\n",
    "        # generate_prompt >> generate >> _generate\n",
    "\n",
    "    def ainvoke(...) -> BaseMessage:\n",
    "        # ...\n",
    "        self.agenerate_prompt(...)\n",
    "        # agenerate_prompt >> agenerate >> _agenerate >> _generate\n",
    "    \n",
    "    def stream(...) -> Iterator[BaseMessageChunk]:\n",
    "        # ...\n",
    "        if type(self)._stream == BaseChatModel._stream:\n",
    "            # model doesn't implement streaming, so use default implementation\n",
    "            yield cast(\n",
    "                BaseMessageChunk, self.invoke(input, config=config, stop=stop, **kwargs)\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    async def astream(...) -> AsyncIterator[BaseMessageChunk]:\n",
    "        # åœ¨#19332åˆå¹¶ä¸­ï¼Œ_astreamæ–¹æ³•å®ç°å·²ç»è¢«ç®€åŒ–\n",
    "        # https://github.com/langchain-ai/langchain/pull/19332/commits/afbe6ac659e41ab5f4a6f4dcaa33511e9e59e4d5\n",
    "        if (\n",
    "            type(self)._astream is BaseChatModel._astream\n",
    "            and type(self)._stream is BaseChatModel._stream\n",
    "        ):\n",
    "            # No async or sync stream is implemented, so fall back to ainvoke\n",
    "            yield cast(\n",
    "                BaseMessageChunk,\n",
    "                await self.ainvoke(input, config=config, stop=stop, **kwargs),\n",
    "            )\n",
    "        # ...\n",
    "\n",
    "    # bacth, abatch, astream_log, astream_events \n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df1cf1-2efe-4bf0-8f6b-4bd752084f9f",
   "metadata": {},
   "source": [
    "**å¿…é¡»å®ç°çš„éƒ¨åˆ†ï¼š**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa90a6e-8255-4e6f-9876-2f4cf16d2041",
   "metadata": {},
   "source": [
    "```python\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"chat-with-neighber-older\"\n",
    "        \n",
    "    ## ******** invoke / ainvoke / batch / abatch **********\n",
    "    @abstractmethod\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"Top Level call\"\"\"\n",
    "\n",
    "    ## ******** stream / astream / astream_log / astream_events **********\n",
    "    def _stream(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[ChatGenerationChunk]:\n",
    "        raise NotImplementedError()        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78830db-43ef-4dc4-b5cb-c0a83ac4e3ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ğŸŒ¹ æ¨èé˜…è¯»ï¼šlangchain å†…ç½®å®ç°çš„ FakeLLM æºç \n",
    "\n",
    "- [ğŸ”— æŸ¥çœ‹ FakeListLLM](https://github.com/langchain-ai/langchain/blob/8595c3ab59371d9932310eb12a2c3220afe3ba84/libs/core/langchain_core/language_models/fake.py#L14)\n",
    "- [ğŸ”— æŸ¥çœ‹ FakeStreamingListLLM](https://github.com/langchain-ai/langchain/blob/8595c3ab59371d9932310eb12a2c3220afe3ba84/libs/core/langchain_core/language_models/fake.py#L61)\n",
    "- [ğŸ”— æŸ¥çœ‹ FakeMessagesListChatModel](https://github.com/langchain-ai/langchain/blob/8595c3ab59371d9932310eb12a2c3220afe3ba84/libs/core/langchain_core/language_models/fake_chat_models.py#L16)\n",
    "- [ğŸ”— æŸ¥çœ‹ FakeChatModel](https://github.com/langchain-ai/langchain/blob/8595c3ab59371d9932310eb12a2c3220afe3ba84/libs/core/langchain_core/language_models/fake_chat_models.py#L120C7-L120C20)\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>âš ï¸ å‚è€ƒï¼š</b><br>\n",
    "    å¦‚æœä½ è§‰å¾—æˆ‘ä»¬ä¸Šé¢çš„ä¾‹å­è¿˜ä¸å¤Ÿä¸°å¯Œï¼Œå¯ä»¥å‚è€ƒè¿™å‡ ä¸ªFakeç³»åˆ—çš„å¤§æ¨¡å‹æºç ï¼Œå¯ä»¥å‚è€ƒä¸Šé¢çš„ä¾‹å­ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f664542-8ea0-4cba-ba61-735c0fea6b04",
   "metadata": {},
   "source": [
    "## 3ã€é›†æˆæ™ºè°±å¤§æ¨¡å‹åˆ° Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e4176-391c-41a4-bc21-988f7b295843",
   "metadata": {},
   "source": [
    "### ğŸ¦œ éœ€æ±‚åˆ†æï¼šç»“åˆæ™ºè°±å®˜æ–¹æ–‡æ¡£ï¼Œç¼–å†™ChatZhipuAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff16f8-4f04-4639-9cbb-5aead5c88076",
   "metadata": {},
   "source": [
    "- [æ™ºè°±AIå®˜æ–¹çš„Pythonæ¥å£æ–‡æ¡£](https://maas.aminer.cn/dev/api#sdk)\n",
    "- [Langchainä¸­å·²æœ‰çš„æ™ºè°±AIç»„ä»¶ï¼ˆæ—§ç‰ˆæœ¬ï¼‰](https://python.langchain.com/docs/integrations/chat/zhipuai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98111791-1ac5-49ab-84ba-231e697bf706",
   "metadata": {},
   "source": [
    "[å®˜æ–¹API zhpuai v2.0.1 åœ¨2024å¹´1æœˆ16æ—¥å‘å¸ƒ](https://pypi.org/project/zhipuai/#history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d217d-27e3-4802-9ea6-e5d585a2bd01",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ™ºè°±AIé‡åˆ°çš„å°´å°¬ï¼š</b><br>\n",
    "    æ™ºè°±å®˜æ–¹SDKå‡çº§åˆ°4.0ä¹‹å, Langchainç›¸åº”çš„åŒ…ä¸€ç›´æ²¡æœ‰æ›´æ–°ã€‚<br>\n",
    "    æˆªæ­¢åˆ°2024å¹´3æœˆ29æ—¥ï¼Œä»ç„¶ä¸å¯ç”¨ï¼ˆå¦‚æœçªç„¶å¯ç”¨äº†ä¹Ÿä¸è¦ç´§ï¼Œæœ¬è¯¾å†…å®¹åŸæœ¬å°±æ˜¯æŠ›è½¬å¼•ç‰ï¼‰\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7ebf3-ec67-4cbc-8c13-3cba71d7461f",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰æ™ºè°±å®˜æ–¹å¯ç”¨æ¥å£\n",
    "- ç›´æ¥è°ƒç”¨ï¼šå¯å®ç° invoke\n",
    "- å¼‚æ­¥è°ƒç”¨ï¼ˆå…ˆè°ƒç”¨ï¼Œå†æŸ¥è¯¢ç»“æœï¼‰ï¼šé€‚åˆå®ç° ainvoke / batch / abatch\n",
    "- æµå¼è°ƒç”¨ï¼ˆSSEï¼ŒServer-Send Events)ï¼šé€‚åˆå®ç° stream / astream / stream_log / stream_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf4066-d16d-4307-93d5-d54f56cdd3a2",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰æ™ºè°±å®˜æ–¹æ”¯æŒèƒ½åŠ›\n",
    "- æ”¯æŒå·¥å…·ï¼šæœ¬åœ°å·¥å…·å›è°ƒ / äº‘ä¸Šæ£€ç´¢ / äº‘ä¸Šäº’è”ç½‘æœç´¢\n",
    "- æ”¯æŒè¯†å›¾\n",
    "- æ”¯æŒç”Ÿå›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4f39d-46f4-401f-93c3-b6a59a687754",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    èƒ½å¦å®ç°ä¸€ä¸ªè‡ªå®šä¹‰å¤§æ¨¡å‹ï¼Œæ”¯æŒå¤šæ¨¡æ€èƒ½åŠ›ï¼Ÿ<br>\n",
    "    input: List[Union[æ–‡å­—, å›¾åƒ]] -> Union[æ–‡å­—, å›¾åƒ]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbbbff-1483-487a-8648-141b5f64fc99",
   "metadata": {},
   "source": [
    "#### ï¼ˆ3ï¼‰æ™ºè°±å®˜æ–¹é€Ÿç‡é™åˆ¶\n",
    "\n",
    "[ğŸ”— æ™ºè°±AIå®˜æ–¹æ–‡æ¡£ä¸­å¯¹é€Ÿç‡é™åˆ¶çš„è¯´æ˜](https://maas.aminer.cn/dev/howuse/rate-limits/why?tab=5)ï¼š\n",
    "\n",
    "> å½“å‰æˆ‘ä»¬åŸºäºç”¨æˆ·çš„æœˆåº¦ API è°ƒç”¨æ¶ˆè€—é‡‘é¢æƒ…å†µå°†é€Ÿç‡æ§åˆ¶åˆ†ä¸º6ç§ç­‰çº§ã€‚\n",
    ">\n",
    "> æ¶ˆè€—é‡‘é¢é€‰å–é€»è¾‘ï¼šæˆ‘ä»¬ä¼šé€‰å–ç”¨æˆ·å½“å‰æœˆä»½1å·ï½t-1æ—¥çš„è°ƒç”¨ API æ¨ç†æ¶ˆè€—æ€»é‡‘é¢å’Œç”¨æˆ·ä¸Šä¸ªæœˆçš„ API è°ƒç”¨æ¶ˆè€—æ€»é‡‘é¢åšæ¯”è¾ƒï¼Œå–æ›´é«˜é‡‘é¢ä½œä¸ºç”¨æˆ·å½“å‰çš„ API æ¶ˆè€—é‡‘é¢ã€‚\n",
    ">\n",
    "> ç‰¹åˆ«çš„ï¼Œè‹¥æ‚¨ä»æœªæ›¾ä»˜è´¹å……å€¼/è´­ä¹°è¿‡èµ„æºåŒ…ï¼Œåˆ™ä¼šå½’ä¸ºå…è´¹çº§åˆ«ã€‚\n",
    "\n",
    "**æ•´ç†GLM4æ¨¡å‹ä½¿ç”¨é™åˆ¶å¦‚ä¸‹ï¼š**\n",
    "|ç”¨æˆ·ç­‰çº§|ä½¿ç”¨é‡|GLM4å¹¶å‘é™åˆ¶|\n",
    "|:---|:---|:---|\n",
    "|å…è´¹|apiè°ƒç”¨æ¶ˆè€—0å…ƒ-50å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|5|\n",
    "|ä½¿ç”¨é‡1|apiè°ƒç”¨æ¶ˆè€—50å…ƒ-500å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|10|\n",
    "|ä½¿ç”¨é‡2|apiè°ƒç”¨æ¶ˆè€—500å…ƒ-5000å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|20|\n",
    "|ä½¿ç”¨é‡3|apiè°ƒç”¨æ¶ˆè€—5000å…ƒ-10000å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|30|\n",
    "|ä½¿ç”¨é‡4|apiè°ƒç”¨æ¶ˆè€—10000å…ƒ-30000å…ƒ/æ¯æœˆï¼ˆä¸å«ï¼‰|100|\n",
    "|ä½¿ç”¨é‡5|apiè°ƒç”¨æ¶ˆè€—30000å…ƒä»¥ä¸Š/æ¯æœˆ|200|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941a68e-e6de-40f9-8ecb-610556b92296",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    èƒ½å¦å®ç°ä¸€ä¸ªè‡ªå®šä¹‰å¤§æ¨¡å‹ï¼Œé€šè¿‡å¤šä¸ªä½ç”¨é‡è´¦æˆ·æ± çš„ç®¡ç†æœºåˆ¶æ¥æé«˜å¯ç”¨çš„è°ƒç”¨é€Ÿç‡ï¼Ÿ<br>\n",
    "    é€Ÿç‡é™åˆ¶å±äºæœåŠ¡ç«¯é™çº§ï¼Œè°ƒç”¨æ—¶è‡ªåŠ¨æŒ‰ç…§é€Ÿç‡é™åˆ¶æ’é˜Ÿï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e18cd-e44e-4f28-a8a2-819f719c4daf",
   "metadata": {},
   "source": [
    "### âœï¸ æµ‹è¯•å®˜æ–¹ä¾‹å­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317160f-22fe-4210-bc69-ed83abacfeca",
   "metadata": {},
   "source": [
    "çœ‹å®˜æ–¹ä¾‹å­ï¼š[ğŸ”— æŸ¥çœ‹ https://github.com/MetaGLM/zhipuai-sdk-python-v4](https://github.com/MetaGLM/zhipuai-sdk-python-v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad0716-95a2-4966-bf90-07d33be54cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681792b-ab7d-4269-b9d3-8f55a25ce0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## çœ‹çœ‹å®˜æ–¹çš„ä¾‹å­æ˜¯å¦èƒ½æ­£ç¡®è¿è¡Œ\n",
    "client = ZhipuAI()\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å«ä»€ä¹ˆåå­—\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835dc40-1269-4415-8127-70f62f8ea0a0",
   "metadata": {},
   "source": [
    "### âœï¸ åŒ…è£…ä¸ºä¸€ä¸ªå‡½æ•°è°ƒç”¨ï¼ˆå‡è£…æˆ‘ä¸æƒ³ç›´æ¥ç”¨ langchainï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c782a4d-663b-423c-8cd7-3d63a7893e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_zhipu(question: str) -> str:\n",
    "    client = ZhipuAI()\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘æœºå™¨äººï¼Œæˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"hello\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return(response.choices[0].message.content)\n",
    "\n",
    "ask_zhipu(\"ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f6f0e-3891-4a30-91a8-afcfd2cf5d08",
   "metadata": {},
   "source": [
    "### âœï¸ æ”¯æŒä¸ Prompt åä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d65800-bc21-489a-9dd9-84b50b8e1be4",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰èƒ½å¦å®ç°å¦‚ä¸‹åœºæ™¯ï¼Ÿï¼ˆä¼¼ä¹ä½¿ç”¨ langchain ä¹Ÿæ²¡é‚£ä¹ˆåï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2572d41a-b2a6-4b81-9426-f083081f86ac",
   "metadata": {},
   "source": [
    "```python\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"question\": \"ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\"})\n",
    "```\n",
    "\n",
    "åŸºæœ¬æ€è·¯ï¼š\n",
    "\n",
    "Promptè¾“å…¥ï¼ˆæŒ‰langchainæ ‡å‡†ï¼‰ <br>\n",
    "â¬‡ï¸ <br>\n",
    "Promptè¾“å‡ºï¼ˆæŒ‰langchainæ ‡å‡†ï¼‰ <br>\n",
    "â¬‡ï¸ <br>\n",
    "LLMè¾“å…¥ï¼ˆæŒ‰å¤§æ¨¡å‹æ ‡å‡†ï¼‰ <br>\n",
    "â¬‡ï¸ <br>\n",
    "LLMè¾“å‡ºï¼ˆæŒ‰langchainæ ‡å‡†ï¼‰\n",
    "â¬‡ï¸ <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5a333-e3e2-493b-8525-baf37a2f11ac",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰æ„é€  Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024270e5-a030-421f-8af7-af64c1251dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘æœºå™¨äººï¼Œæˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚\"),\n",
    "    (\"human\", \"ä½ å¥½\"),\n",
    "    (\"ai\", \"hello\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "prompt.invoke({\"question\":\"ä½ å«ä»€åå­—ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd50c3d-5a21-4d6b-96e2-76a2e5ae5566",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒ</b><br>\n",
    "    ä¸Šé¢ä»£ç ä¸­ï¼Œ ä¸ºä»€ä¹ˆ from_messages æ”¯æŒ systemã€humanã€ai è¿™äº›åå­—ï¼Ÿè¿˜æœ‰å…¶ä»–åå­—å—ï¼Ÿ\n",
    "</div>\n",
    "\n",
    "**ğŸŒ æç¤ºï¼š**\n",
    "- æ–‡æ¡£ä¸­æ²¡æœ‰ç­”æ¡ˆï¼Œéœ€è¦ç ”ç©¶æºç ï¼š[ğŸ”— æŸ¥çœ‹ langchain_core/messages/utils.py](https://github.com/langchain-ai/langchain/blob/c93d4ea91cfcf55dfe871931d42aa22562f8dae2/libs/core/langchain_core/messages/utils.py#L130-L168)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae249420-7b4a-453e-be1a-47dbbde27a05",
   "metadata": {},
   "source": [
    "#### ï¼ˆ3ï¼‰ä» Prompt è¾“å‡ºæ ¼å¼ï¼Œè½¬æ¢åˆ°å¤§æ¨¡å‹çš„è¾“å…¥æ ¼å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f685d93-a8a5-4a6e-94aa-b489656fdc96",
   "metadata": {},
   "source": [
    "**æ¢æŸ¥æ ¼å¼ï¼š**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90cc73-c09f-44c0-92bf-4bee04489894",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.invoke({\"question\":\"ä½ å«ä»€åå­—ï¼Ÿ\"}).to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc70629-f85f-4a01-a8be-146b3d1522f4",
   "metadata": {},
   "source": [
    "**è½¬æ¢æ ¼å¼ï¼š**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd10cd0-e5b6-488d-b044-3d1e36dac1cb",
   "metadata": {},
   "source": [
    "è¿™é‡Œå¯ä»¥å€ŸåŠ© openai æ ‡å‡†çš„è½¬æ¢å‡½æ•°ï¼š [langchain_community.adapters.openai](https://github.com/langchain-ai/langchain/blob/3f7da03dd89e76f290ce361c72d1676319110163/libs/community/langchain_community/adapters/openai.py#L112-L156)ï¼ŒèŠ‚çœå¾ˆå¤šä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48adc15-0507-4950-bb27-f034e5a5ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.adapters.openai import convert_message_to_dict\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c1316-3741-49a7-85da-806b5fcd2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "[convert_message_to_dict(m) for m in prompt.invoke({\"question\":\"ä½ å«ä»€åå­—ï¼Ÿ\"}).to_messages()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7648a6-6ab7-4a62-81b3-d0b02c553ea2",
   "metadata": {},
   "source": [
    "### âœï¸ ç›´æ¥ç”¨ RunnableLambda è¾¾åˆ°ç›®çš„ï¼ˆå‡è£…æˆ‘ä¸æƒ³ç”¨ langchain çš„å¤§æ¨¡å‹åŸºç±»ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5a0a3-433d-48e7-950b-fc3d8a445e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from typing import List\n",
    "from langchain_core.prompt_values import ChatPromptValue \n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "@chain\n",
    "def ask_zhipu(promptValue: ChatPromptValue) -> AIMessage:\n",
    "    client = ZhipuAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=[convert_message_to_dict(m) for m in promptValue.to_messages()],\n",
    "    )\n",
    "    return(AIMessage(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b9894-8a00-4913-b542-ed0f6e73ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | ask_zhipu | StrOutputParser()\n",
    "chain.invoke({\"question\": \"ä½ å«ä»€åå­—ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dae6d9-9301-4c56-bc78-96f1ad2f758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çœ‹çœ‹å½“å‰é“¾çš„ç»“æ„\n",
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa150d60-9630-4597-bd2f-16524238f899",
   "metadata": {},
   "source": [
    "### âœï¸ åŸºäº BaseChatModel è¾¾åˆ°ç›®çš„ï¼ˆå‡è£…æˆ‘å¼€å§‹æƒ³è·å¾— LCEL çš„è¯¸å¤šå¥½å¤„ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67137baa-a298-4530-bcbb-f88f5fa4077c",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰ä»å¤§æ¨¡å‹çš„è¾“å‡ºæ ¼å¼ï¼Œè½¬æ¢åˆ° langchain çš„æ ‡å‡†è¾“å‡ºæ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46fb809-bfbd-4035-9de4-0a1d52a6da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.adapters.openai import convert_dict_to_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6daa2ea-e6a4-4289-a9c7-8707489433ef",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰å®ç°æ”¯æŒ invoke çš„ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0374ab1-7121-4513-869e-bbc5ab56302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from typing import Any, Dict, Iterator, List, Optional, cast, Mapping\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ac9a7-62e2-45c8-a0b5-5b0d97824ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniZhipuAI(BaseChatModel):\n",
    "    \"\"\"æ”¯æŒæœ€æ–°çš„æ™ºè°±API\"\"\"\n",
    "\n",
    "    client: Optional[ZhipuAI] = None\n",
    "\n",
    "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.client = ZhipuAI()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return the type of chat model.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    def _ask_remote(self, messages, streaming=False, **kwargs):\n",
    "        # ä»langchainæ¶ˆæ¯æ ¼å¼ï¼Œè½¬æ¢åˆ°æ™ºè°±AIè¾“å…¥çš„æ ¼å¼\n",
    "        dict_zhipu = [convert_message_to_dict(m) for m in messages]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"glm-4\",\n",
    "            messages=dict_zhipu,\n",
    "            stream=streaming,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # ä»æ™ºè°±AIè¾“å‡ºçš„æ ¼å¼ï¼Œè½¬æ¢åˆ°langchainçš„æ¶ˆæ¯æ ¼å¼\n",
    "        if not isinstance(response, dict):\n",
    "            response = response.dict()\n",
    "        return [convert_dict_to_message(c[\"message\"]) for c in response[\"choices\"]]\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        \"\"\"å®ç° ZhiputAI çš„åŒæ­¥è°ƒç”¨\"\"\"\n",
    "\n",
    "        # é—®æ™ºè°±AIï¼Œå¹¶å¾—åˆ°å›å¤\n",
    "        responses = self._ask_remote(messages, streaming=False, **kwargs)\n",
    "\n",
    "        return ChatResult(\n",
    "            generations=[ChatGeneration(message=m) for m in responses]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34bc36-229e-4c44-a02f-f6537a89a67b",
   "metadata": {},
   "source": [
    "#### ï¼ˆ3ï¼‰ç”¨èµ·æ¥ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee54840-3dfb-4d6d-ae4b-6a07ba3b2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸­è‹±äº’è¯‘æœºå™¨äººï¼Œåªè´Ÿè´£ç¿»è¯‘ï¼Œä¸è¦è¯•å›¾å¯¹é—®é¢˜åšè§£ç­”ã€‚æˆ‘è¯´ä¸­æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œæˆ‘è¯´è‹±æ–‡ä½ å°±ç›´æ¥ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚ä¸è¦è¾“å‡ºå…¶ä»–ï¼Œä¸è¦å•°å—¦ã€‚\"),\n",
    "    (\"human\", \"ä½ å¥½\"),\n",
    "    (\"ai\", \"hello\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "llm_zhipu = MiniZhipuAI()\n",
    "chain = prompt | llm_zhipu\n",
    "\n",
    "chain.invoke({\"question\": \"The competition between China and the United States in the AI field is very intense. Can China catch up?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467f98a-f6c6-4443-b0ef-ef906cf26111",
   "metadata": {},
   "source": [
    "### âœï¸ å°è¯•åœ¨æ™ºèƒ½ä½“ä¸­ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853191a-48d5-4385-a79b-d1ebaf4d9c69",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰å®šä¹‰ä¸€ä¸ªç®€å•å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adeaac3-3dd6-4a5e-9591-7da1b31660c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool, convert_to_openai_function\n",
    "import re\n",
    "\n",
    "@tool\n",
    "def ask_neighber(query: str) -> str:\n",
    "    \"\"\"æˆ‘æ˜¯é©¬å†¬æ¢…çš„é‚»å±…è€å¤§çˆ·ï¼Œå…³äºå¥¹çš„äº‹æƒ…ä½ å¯ä»¥é—®æˆ‘\"\"\"\n",
    "    if(re.search(\"é©¬å†¬æ¢…\", query)):\n",
    "        return \"æ¥¼ä¸Š322\"\n",
    "    else:\n",
    "        return \"æˆ‘ä¸æ¸…æ¥š\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c272f4-0dca-4499-afce-3a91c93d413a",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰ä½œä¸º openai é£æ ¼çš„å›è°ƒå·¥å…·ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d510aa-b493-4920-968b-909cfdfd2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_zhipu = MiniZhipuAI().bind(tools=[convert_to_openai_tool(ask_neighber)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52acb9b5-9948-4de6-b364-c1da895d1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_zhipu.invoke(\"å‘Šè¯‰æˆ‘é©¬å†¬æ¢…åœ¨å“ªä¸ªæˆ¿é—´ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8a61d-573c-468d-b9df-62516c521e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_neighber.invoke({\"query\":\"é©¬å†¬æ¢…\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486f46b-8c36-49ba-aec8-5340206443fe",
   "metadata": {},
   "source": [
    "#### ï¼ˆ3ï¼‰é›†æˆåˆ°æ™ºèƒ½ä½“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c09ac0d-f981-4c50-a2c7-fc41f082618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "def create_neighber(llm):\n",
    "    tools = [ask_neighber]\n",
    "    prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    return AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc382cdb-9ffc-40fa-a16c-41b5eb371c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_neighber(MiniZhipuAI()).invoke({\"input\":\"é©¬å†¬æ¢…ä½å“ªé‡Œ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77770d1-c8fa-4967-8142-e91d012652e9",
   "metadata": {},
   "source": [
    "### âœï¸ ç°åœ¨å¯ä»¥è½»æ¾åˆ‡æ¢æ™ºèƒ½ä½“ä¸­çš„å¤§æ¨¡å‹ï¼ˆå‡è£…æˆ‘å¯¹ langchian å¾ˆæ»¡æ„ï¼ğŸ‘ğŸ‘ğŸ‘ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb52bc-0c67-40e7-9bef-d97680e21614",
   "metadata": {},
   "source": [
    "#### ï¼ˆ1ï¼‰ä½¿ç”¨ langchain_zhipu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff552d-78cd-41c0-a302-b9a695c2887d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>âš ï¸ æ€è€ƒï¼š</b><br>\n",
    "    ä¸Šé¢ä»£ç å·²ç»ç›¸å¯¹å®Œæ•´å®ç°äº†ä¸€ä¸ª langchain å¤§æ¨¡å‹ï¼›ä½†ç¼ºå°‘å¾ˆå¤šç»†èŠ‚æ§åˆ¶ï¼Œå¯ä»¥å°è¯•è‡ªå·±åŠ¨æ‰‹æ·»åŠ ï¼    \n",
    "</div>\n",
    "\n",
    "**ğŸŒ å‚è€ƒï¼š**\n",
    "- [ğŸ”— æŸ¥çœ‹ langchain_zhpu ä¸­çš„å®ç°æºç ](https://github.com/arcstep/langchain_zhipuai/blob/e55af13eed673bc409ffdb143030e6cc0b2af27c/langchain_zhipu/chat.py#L304-L354) [![PyPI version](https://img.shields.io/pypi/v/langchain_zhipu.svg)](https://pypi.org/project/langchain_zhipu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fddecd-fd0c-41f7-b262-114a36d54145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_zhipu import ChatZhipuAI\n",
    "\n",
    "create_neighber(ChatZhipuAI()).invoke({\"input\":\"é©¬å†¬æ¢…ä½å“ªé‡Œ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ea67a-56ae-4b60-a2be-6a7021c973eb",
   "metadata": {},
   "source": [
    "#### ï¼ˆ2ï¼‰ä½¿ç”¨ langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bb69b8-33a7-4f1e-9ac5-0e41972241d1",
   "metadata": {},
   "source": [
    "**è¿™ä¸ç›´æ¥ä½¿ç”¨OpenAIç±»ä¼¼ï¼š**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc557ddb-fa06-4fbf-90da-d9418123dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "create_neighber(ChatOpenAI()).invoke({\"input\":\"é©¬å†¬æ¢…ä½å“ªé‡Œ\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160eb50-4574-46fa-b9d4-aeaa0c773a6e",
   "metadata": {},
   "source": [
    "# â¤ï¸ çŸ¥è¯†ç‚¹å°ç»“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b3b01-8f7f-4ade-a669-4c6c94ac1d2a",
   "metadata": {},
   "source": [
    "1. å¦‚æœè¦é›†æˆè‡ªå·±çš„å¤§æ¨¡å‹åˆ° langchain ï¼Œä» `BaseChatModel` ç»§æ‰¿æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹\n",
    "2. BaseChatModel è‡³å°‘è¦æ±‚ä½ å®ç° `_generate` æ–¹æ³•ï¼Œå¦‚æœè¡¥å…… `_stream` æ–¹æ³•ï¼Œå°±å¯ä»¥æä¾›åˆ°å…¨é¢èƒ½åŠ›\n",
    "3. ä½¿ç”¨ `langchain_community.adapters.openai` å¯ä»¥è½¬æ¢ OpenAI é£æ ¼çš„æ¶ˆæ¯æ ¼å¼\n",
    "4. `ChatPromptTemplate.from_messages` å¯ä»¥ä½¿ç”¨è¯­æ³•ç³–ï¼š system, humanï¼ˆæˆ–userï¼‰, aiï¼ˆæˆ–assistantï¼‰ç­‰\n",
    "5. å€¼å¾—è®°ä½å‡ ä¸ªä»æºç è§‚å¯Ÿåˆ°çš„å®ç”¨æ–¹æ³•ï¼š`get_graph().print_ascii()`ï¼Œ`input_schema.schema()` ç­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada588bc-d1d3-4864-8e66-cd828a895d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
