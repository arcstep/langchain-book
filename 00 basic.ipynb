{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30caf792-2fad-48e7-9b6d-bb5bdf2c38c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# å¼€å§‹ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008bf7c-69d9-4556-9054-96426d200426",
   "metadata": {},
   "source": [
    "## ç»“åˆpoetryä½¿ç”¨Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58d7fd-8301-4178-b53f-a7df9dc02218",
   "metadata": {},
   "source": [
    "åœ¨poetryä¸­æ”¯æŒjupyterå’Œipykernelï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c195e-a73c-44d9-b2fc-3d4c2e5fb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add ipykernel jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be542642-63ed-4eb9-878e-096162e9988a",
   "metadata": {},
   "source": [
    "åˆ›å»ºä¸€ä¸ªåä¸º`langchani-book-poetry-env`çš„å¯ç”¨å†…æ ¸ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c83c3-8e23-4abc-8955-0a92941e4d10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!poetry run python -m ipykernel install --user --name=langchani-book-py3.10-ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53afd7-f910-4c8f-91ee-a9139c89d86b",
   "metadata": {},
   "source": [
    "## åŠ è½½ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eff29666-236e-4b42-ae4f-78299de4a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import sys\n",
    "import io\n",
    "original_stdout = sys.stdout \n",
    "sys.stdout = io.StringIO()\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baedfb2d-930b-45f3-8be0-4e4cb91a15a7",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd486c-3ec9-4b66-89c2-c2f8815520d7",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨langserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4614a71-4d62-43c3-b659-7f855d4917a0",
   "metadata": {},
   "source": [
    "## è®¿é—®langserveæœåŠ¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cdce9-cb73-4e0f-853d-87074ebe6059",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>æ¶æ„è§£å¶ï¼š</b>åœ¨pythonä¸­è®¿é—®è¿œç¨‹langserveçš„æœºåˆ¶ï¼Œæœ‰åŠ©äºå°†GPTæœåŠ¡å’Œåº”ç”¨æ¨¡å—åœ¨æ¶æ„ä¸Šè§£è€¦ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818871a-c020-4885-a71d-f659fd47fe2d",
   "metadata": {},
   "source": [
    "ä¾‹å¦‚ï¼Œè¦ç»“åˆAIç”Ÿæˆèƒ½åŠ›åˆ›å»ºæ–‡æ¡£ï¼Œä¸‹é¢è¿™ä¸ªå°è£…ä¼šéå¸¸æœ‰ç”¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f890631-f59c-44c9-8592-cb675aeea322",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def print_content(data):\n",
    "    for char in data:\n",
    "        print(char, end=\"\", flush=True)\n",
    "\n",
    "from langserve import RemoteRunnable\n",
    "def remote_runnable(runnable, params = [], base_url = base_url, debug = debug):\n",
    "    chain = RemoteRunnable(f\"{base_url}/{runnable}\")\n",
    "    def ask(*args):\n",
    "        kwargs = dict(zip(params, args))\n",
    "        if debug:\n",
    "            print_content(chain.stream(kwargs))\n",
    "        else:\n",
    "            return chain.invoke(kwargs)\n",
    "    return ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34aff10-f0c9-4e35-b6c8-adfb055482f8",
   "metadata": {},
   "source": [
    "æˆ–è€…æ‰“åŒ…ä¸ºä¸€ä¸ªpythonæ–‡ä»¶ï¼Œç›´æ¥å¼•ç”¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2668e6c8-2f9d-464b-b714-2752266924c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNABLE_BASE_URL:  http://localhost:8000\n"
     ]
    }
   ],
   "source": [
    "from Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f25aa-7a5a-4c4a-b566-c345eed279bb",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805890c3-5828-4e16-a19a-7e77f49f0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35 = remote_runnable(\"langserve/gpt35\", [\"question\"])\n",
    "gpt4 = remote_runnable(\"langserve/gpt4\", [\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af697c5-d0c7-4908-bc5c-2c3ec64168f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¯èƒ½æœ‰å¾ˆå¤šåŸå› å¯¼è‡´çˆ¶æ¯ç»“å©šæ—¶æ²¡æœ‰é‚€è¯·ä½ ã€‚ä¹Ÿè®¸ä»–ä»¬è®¤ä¸ºä½ è¿˜å¤ªå°ï¼Œæˆ–è€…ä»–ä»¬æƒ³è¦ä¸€ä¸ªç§äººçš„ã€å°å‹çš„å©šç¤¼ã€‚ä¹Ÿæœ‰å¯èƒ½æ˜¯å› ä¸ºä»–ä»¬çš„å©šç¤¼è®¡åˆ’æ˜¯åœ¨ä½ ä¸åœ¨åœºçš„æ—¶å€™è¿›è¡Œçš„ã€‚æ— è®ºåŸå› æ˜¯ä»€ä¹ˆï¼Œé‡è¦çš„æ˜¯ç†è§£å¹¶æ¥å—ä»–ä»¬çš„å†³å®šï¼Œå¹¶ä¸”ç¥ç¦ä»–ä»¬æœªæ¥çš„å¹¸ç¦ç”Ÿæ´»ã€‚"
     ]
    }
   ],
   "source": [
    "gpt35(\"æˆ‘çš„çˆ¶æ¯ç»“å©šæ—¶ä¸ºä»€ä¹ˆæ²¡æœ‰é‚€è¯·æˆ‘ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9ccb50-592c-4b9e-9991-d6362ea57fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¦‚æœä½ çš„çˆ¶æ¯åœ¨ç»“å©šæ—¶æ²¡æœ‰é‚€è¯·ä½ ï¼Œå¯èƒ½æœ‰å‡ ä¸ªåŸå› ï¼š\n",
      "\n",
      "1. ä½ è¿˜æ²¡æœ‰å‡ºç”Ÿï¼šè¿™æ˜¯æœ€å¸¸è§çš„åŸå› ã€‚å¦‚æœä½ çš„çˆ¶æ¯åœ¨ä½ å‡ºç”Ÿä¹‹å‰ç»“å©šï¼Œé‚£ä¹ˆä½ è‡ªç„¶ä¸å¯èƒ½è¢«é‚€è¯·ã€‚\n",
      "\n",
      "2. ç§å¯†æˆ–å°å‹å©šç¤¼ï¼šæœ‰äº›å¤«å¦‡å¯èƒ½é€‰æ‹©ä¸¾è¡Œä¸€ä¸ªéå¸¸ç§å¯†çš„å©šç¤¼ï¼Œåªé‚€è¯·éå¸¸äº²è¿‘çš„å®¶äººæˆ–æœ‹å‹ï¼Œæˆ–è€…ç”šè‡³åªæœ‰ä¸¤ä¸ªäººå•ç‹¬ä¸¾è¡Œä»ªå¼ã€‚\n",
      "\n",
      "3. åœ°ç†æˆ–ç‰©ç†éšœç¢ï¼šå¯èƒ½åœ¨ä½ çš„çˆ¶æ¯ç»“å©šæ—¶ï¼Œä½ å› ä¸ºæŸäº›åŸå› ï¼ˆå¦‚å¹´å¹¼ã€å­¦ä¸šã€å·¥ä½œæˆ–å…¶ä»–è´£ä»»ï¼‰æ— æ³•åˆ°åœºã€‚\n",
      "\n",
      "4. å®¶åº­å…³ç³»ï¼šæœ‰æ—¶ç”±äºå®¶åº­å†…éƒ¨å…³ç³»å¤æ‚ï¼Œå¯èƒ½ä¼šå¯¼è‡´æŸäº›å®¶åº­æˆå‘˜æ²¡æœ‰è¢«é‚€è¯·å‚åŠ å©šç¤¼ã€‚\n",
      "\n",
      "5. è¯¯è§£æˆ–æ²Ÿé€šé—®é¢˜ï¼šä¹Ÿæœ‰å¯èƒ½æ˜¯ç”±äºæ²Ÿé€šä¸ç•…æˆ–è¯¯è§£å¯¼è‡´ä½ æ²¡æœ‰æ”¶åˆ°é‚€è¯·ã€‚\n",
      "\n",
      "6. å…¶ä»–ä¸ªäººåŸå› ï¼šæ¯ä¸ªå®¶åº­çš„æƒ…å†µéƒ½æ˜¯ç‹¬ç‰¹çš„ï¼Œå¯èƒ½æœ‰å…¶ä»–ä½ ä¸çŸ¥é“çš„åŸå› ã€‚\n",
      "\n",
      "å¦‚æœè¿™ä¸ªé—®é¢˜è®©ä½ æ„Ÿåˆ°å›°æƒ‘æˆ–ä¸å®‰ï¼Œä¸ä½ çš„çˆ¶æ¯è¿›è¡Œå¼€æ”¾å’Œè¯šå®çš„å¯¹è¯å¯èƒ½ä¼šå¸®åŠ©ä½ äº†è§£å½“æ—¶çš„æƒ…å†µå’Œä»–ä»¬çš„å†³å®šã€‚é€šå¸¸ï¼Œè¿™ç§æƒ…å†µæ˜¯ç”±äºä½ è¿˜æœªå‡ºç”Ÿæˆ–éå¸¸å°ï¼Œæ‰€ä»¥ä¸å¯èƒ½å‚ä¸ä»–ä»¬çš„å©šç¤¼ã€‚"
     ]
    }
   ],
   "source": [
    "gpt4(\"æˆ‘çš„çˆ¶æ¯ç»“å©šæ—¶ä¸ºä»€ä¹ˆæ²¡æœ‰é‚€è¯·æˆ‘ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ecd12-4f79-43ed-b539-fc658f3b7d33",
   "metadata": {},
   "source": [
    "### é€šä¹‰åƒé—®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d343865c-49fe-4f74-a4ef-663af2488d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tongyi = remote_runnable(\"langserve/tongyi\", [\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f67d83-145b-4df3-84ed-1bf076d506e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯é˜¿é‡Œäº‘å¼€å‘çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œæˆ‘å«é€šä¹‰åƒé—®ã€‚"
     ]
    }
   ],
   "source": [
    "tongyi(\"ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca836636-1e81-4752-80ec-7f38145561c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å› ä¸ºæ‚¨åœ¨ä»–ä»¬ç»“å©šçš„æ—¶å€™è¿˜æ²¡æœ‰å‡ºç”Ÿï¼Œæ‰€ä»¥ä»–ä»¬è‡ªç„¶æ— æ³•é‚€è¯·æ‚¨å‚åŠ ä»–ä»¬çš„å©šç¤¼ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œåªæœ‰å·²ç»å‡ºç”Ÿå¹¶èƒ½å¤Ÿç†è§£äº‹ä»¶æ„ä¹‰çš„äººæ‰ä¼šè¢«é‚€è¯·å‚åŠ å©šç¤¼ã€‚"
     ]
    }
   ],
   "source": [
    "tongyi(\"æˆ‘çš„çˆ¶æ¯ç»“å©šæ—¶ä¸ºä»€ä¹ˆæ²¡æœ‰é‚€è¯·æˆ‘?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09678f-3e52-42ef-a88d-3c3db3c99319",
   "metadata": {},
   "source": [
    "### Chatglm3-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67ec88c3-750b-44c6-8940-2675baee3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatglm6b = remote_runnable(\"langserve/chatglm6b\", [\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8405e071-e584-420a-a606-1a7a800736a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " æˆ‘æ˜¯ä¸€ä¸ªåä¸º ChatGLM3-6B çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæ˜¯åŸºäºæ¸…åå¤§å­¦KEG å®éªŒå®¤å’Œæ™ºè°± AIå…¬å¸äº 2023 å¹´å…±åŒè®­ç»ƒçš„è¯­è¨€æ¨¡å‹å¼€å‘çš„ã€‚æˆ‘çš„ä»»åŠ¡æ˜¯é’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜å’Œè¦æ±‚æä¾›é€‚å½“çš„ç­”å¤å’Œæ”¯æŒã€‚"
     ]
    }
   ],
   "source": [
    "chatglm6b(\"ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c5fe24b-e207-4ba0-b1b5-28ae152bb1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ä½œä¸ºäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘æ— æ³•äº†è§£æ‚¨ä¸ªäººç”Ÿæ´»ä¸­çš„å…·ä½“æƒ…å†µã€‚ä½†æ˜¯ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œå©šç¤¼æ˜¯ä¸€ç§åº†ç¥ä¸¤ä¸ªäººæˆä¸ºå¤«å¦‡çš„ä»ªå¼ï¼Œå› æ­¤ï¼Œæ–°å©šå¤«å¦‡å¾ˆå°‘ä¼šé‚€è¯·å­©å­ä½œä¸ºå˜‰å®¾ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä»–ä»¬å¯èƒ½ä¼šé‚€è¯·å­©å­å‚åŠ å©šç¤¼ï¼Œä½†è¿™å–å†³äºå­©å­çš„å¹´é¾„å’Œå©šç¤¼çš„è§„æ¨¡ã€‚å¦‚æœæ‚¨å¸Œæœ›äº†è§£æ›´å¤šå…³äºæ‚¨çˆ¶æ¯å©šç¤¼çš„ä¿¡æ¯ï¼Œæ‚¨å¯ä»¥å°è¯•ä¸ä»–ä»¬æ²Ÿé€šï¼Œäº†è§£ä»–ä»¬å½“æ—¶çš„æƒ³æ³•å’Œå†³å®šã€‚"
     ]
    }
   ],
   "source": [
    "chatglm6b(\"æˆ‘çš„çˆ¶æ¯ç»“å©šæ—¶ä¸ºä»€ä¹ˆæ²¡æœ‰é‚€è¯·æˆ‘?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e3204-c752-42ce-9806-526f0ef979e4",
   "metadata": {},
   "source": [
    "### lambdaå‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7249bdd-eb0b-4dee-9a47-d841a752d095",
   "metadata": {},
   "source": [
    "è‡ªå®šä¹‰çš„lambdaå‡½æ•°ä¸€èˆ¬ä¸è®¿é—®å¤§æ¨¡å‹ï¼Œè€Œæ˜¯ä»¥è¾ƒå¿«é€Ÿåº¦åœ¨æœ¬åœ°è®¡ç®—ï¼Œå› æ­¤ä¸éœ€è¦æ”¯æŒæµå¼æ‰“å°ï¼Œæ‰€ä»¥æ— éœ€å°è£…ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6febd84-1f08-407b-bd91-ac81a9708839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result is: 3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RemoteRunnable(f\"{base_url}/langserve/add\")\n",
    "chain.invoke({\"x\": 1, \"y\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8e8d9a-d732-4df7-b3fe-658eaca22aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result is: 43'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RemoteRunnable(f\"{base_url}/langserve/add_one\")\n",
    "chain.invoke(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e57c8866-c7f4-4c74-bf51-0d5c286ba15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Why don't programmers like nature?\\n\\nBecause they prefer the comfort of their artificial intelligence!\", 'Why did the artist bring a ladder to the art gallery? \\n\\nBecause they wanted to reach new heights in their work!', 'Why did the cell go to therapy?\\n\\nBecause it had a lot of mitosis!']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.base import RunnableEach\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about{topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "runnable = prompt | model | output_parser\n",
    "runnable_each = RunnableEach(bound=runnable)\n",
    "output = runnable_each.invoke([{'topic':'Computer Science'},\n",
    "                            {'topic':'Art'},\n",
    "                            {'topic':'Biology'}])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc014ec-381c-4a83-9b86-428d9d24b30e",
   "metadata": {},
   "source": [
    "### RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b54b6-a047-48f0-8a5f-0a98ba5eaebc",
   "metadata": {},
   "source": [
    "RunnableLambdaåœ¨åŒ…è£…ä¸€ä¸ªæ™®é€šå‡½æ•°æ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e1816-fd8f-4221-bfc9-1c5b62a41ccd",
   "metadata": {},
   "source": [
    "#### ä½¿ç”¨invokeå’Œbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f585316-7e1a-4bbd-ac5e-c074040b3c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Alice ! Welcome To Langchain!\n",
      "hi Alice ! Welcome To Langchain!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import time\n",
    "\n",
    "# å®šä¹‰ä½ çš„å‡½æ•°\n",
    "def hello(name):\n",
    "    return f\"hi {name} ! Welcome To Langchain!\"\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªMyRunnableLambdaå®ä¾‹\n",
    "runnable = RunnableLambda(hello)\n",
    "\n",
    "# ä½¿ç”¨invokeè·å¾—ä¸€æ¬¡æ€§è¾“å‡º\n",
    "print(runnable.invoke(\"Alice\"))  # è¾“å‡º \"hi Alice !\"\n",
    "\n",
    "# æ³¨æ„ï¼šå› ä¸ºhelloå‡½æ•°æ²¡æœ‰æµå¼è¾“å‡ºï¼Œå› æ­¤streamä¹Ÿæ˜¯æ²¡æœ‰æµå¼è¾“å‡ºæ•ˆæœçš„\n",
    "for output in runnable.stream(\"Alice\"):\n",
    "    time.sleep(0.3)\n",
    "    print(output)  # è¾“å‡º \"hi Alice !\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71034b-36b5-42b3-aba4-168cb5e4e533",
   "metadata": {},
   "source": [
    "#### ä½¿ç”¨batchè·å¾—æ‰¹é‡ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac7d4dbd-f0e1-45b7-b56b-449e62ef25b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi Alice ! Welcome To Langchain!', 'hi Bob ! Welcome To Langchain!']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batchä¸­ä¼šè‡ªåŠ¨è°ƒç”¨invoke\n",
    "runnable.batch([\"Alice\", \"Bob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8e33c-39a7-4b73-b714-54557020704f",
   "metadata": {},
   "source": [
    "#### è·å¾—streamçš„æµå¼è¾“å‡ºæ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "248fbd2c-baf4-47b1-87f4-3635234b2afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Alice! Welcome to Langchain!\n",
      "hi Alice! Welcome to Langchain!"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import time\n",
    "\n",
    "# å®šä¹‰ä½ çš„å‡½æ•°\n",
    "def hello(name):\n",
    "    yield \"hi \"\n",
    "    yield name\n",
    "    yield \"! \"\n",
    "    yield \"Welcome\"\n",
    "    yield \" to\"\n",
    "    yield \" Langchain!\"\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªMyRunnableLambdaå®ä¾‹\n",
    "runnable = RunnableLambda(hello)\n",
    "\n",
    "# invokeä¼šç­‰åˆ°æ‰€æœ‰ç»“æœè·å¾—ååˆå¹¶åˆ°ä¸€èµ·è¾“å‡º\n",
    "print(runnable.invoke(\"Alice\"))  # è¾“å‡º \"hi Alice !\"\n",
    "\n",
    "# å› ä¸ºhelloå‡½æ•°å®ç°äº†yieldï¼Œstreamå°±ä¼šæœ‰æµå¼è¾“å‡ºæ•ˆæœ\n",
    "for output in runnable.stream(\"Alice\"):\n",
    "    time.sleep(0.3)\n",
    "    print(output, end = \"\")  # è¾“å‡º \"hi Alice !\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe12eeb-26e8-46be-9f83-7813febe1e05",
   "metadata": {},
   "source": [
    "#### ä½¿ç”¨ @chain è¾¾åˆ°åŒæ ·çš„æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14411965-dec6-4b0d-9b78-1317eec9db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Alice! Welcome to Langchain!\n",
      "hi Alice! Welcome to Langchain!"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "import time\n",
    "\n",
    "# å®šä¹‰ä½ çš„å‡½æ•°\n",
    "@chain\n",
    "def hello(name):\n",
    "    yield \"hi \"\n",
    "    yield name\n",
    "    yield \"! \"\n",
    "    yield \"Welcome\"\n",
    "    yield \" to\"\n",
    "    yield \" Langchain!\"\n",
    "\n",
    "print(hello.invoke(\"Alice\"))  # è¾“å‡º \"hi Alice !\"\n",
    "\n",
    "for output in hello.stream(\"Alice\"):\n",
    "    time.sleep(0.3)\n",
    "    print(output, end = \"\")  # è¾“å‡º \"hi Alice !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276662c7-4a6d-4430-aa6c-a0e1118ad265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60579866-1c20-4b99-bd0a-b058622cf8b0",
   "metadata": {},
   "source": [
    "### RunnableGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f46ce3-5fa7-46de-9820-ec6fb73b6972",
   "metadata": {},
   "source": [
    "RunnableGeneratoræ˜¯ä¸“é—¨ç”¨äºç”Ÿæˆå™¨ä¼˜åŒ–çš„å®ç°ï¼Œåœ¨å°†é“¾ä½œä¸ºè¾“å…¥æ—¶æ— éœ€ç‰¹åˆ«æŒ‡å®šå³å¯ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1bea8ce6-6273-420c-bdba-6be3914dace6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReduceğŸ‘, reuseğŸ‘, recycle!'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chant_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Give me a 3 word chant about {topic}\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def character_generator(input: Iterator[str]) -> Iterator[str]:\n",
    "    for token in input:\n",
    "        if \",\" in token or \".\" in token:\n",
    "            yield \"ğŸ‘\" + token\n",
    "        else:\n",
    "            yield token\n",
    "\n",
    "runnable = chant_chain | character_generator\n",
    "assert type(runnable.last) is RunnableGenerator\n",
    "\"\".join(runnable.stream({\"topic\": \"waste\"})) # ReduceğŸ‘, ReuseğŸ‘, RecycleğŸ‘."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33bc2f-2430-4849-8981-96918850002a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
