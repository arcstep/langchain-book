{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30caf792-2fad-48e7-9b6d-bb5bdf2c38c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 开始使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008bf7c-69d9-4556-9054-96426d200426",
   "metadata": {},
   "source": [
    "## 结合poetry使用Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58d7fd-8301-4178-b53f-a7df9dc02218",
   "metadata": {},
   "source": [
    "在poetry中支持jupyter和ipykernel："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c195e-a73c-44d9-b2fc-3d4c2e5fb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add ipykernel jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be542642-63ed-4eb9-878e-096162e9988a",
   "metadata": {},
   "source": [
    "创建一个名为`langchani-book-poetry-env`的可用内核："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c83c3-8e23-4abc-8955-0a92941e4d10",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!poetry run python -m ipykernel install --user --name=langchani-book-py3.10-ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53afd7-f910-4c8f-91ee-a9139c89d86b",
   "metadata": {},
   "source": [
    "## 加载环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eff29666-236e-4b42-ae4f-78299de4a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import sys\n",
    "import io\n",
    "original_stdout = sys.stdout \n",
    "sys.stdout = io.StringIO()\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baedfb2d-930b-45f3-8be0-4e4cb91a15a7",
   "metadata": {},
   "source": [
    "## 使用langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd486c-3ec9-4b66-89c2-c2f8815520d7",
   "metadata": {},
   "source": [
    "## 使用langserve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4614a71-4d62-43c3-b659-7f855d4917a0",
   "metadata": {},
   "source": [
    "## 访问langserve服务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cdce9-cb73-4e0f-853d-87074ebe6059",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>架构解偶：</b>在python中访问远程langserve的机制，有助于将GPT服务和应用模块在架构上解耦。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b818871a-c020-4885-a71d-f659fd47fe2d",
   "metadata": {},
   "source": [
    "例如，要结合AI生成能力创建文档，下面这个封装会非常有用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f890631-f59c-44c9-8592-cb675aeea322",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def print_content(data):\n",
    "    for char in data:\n",
    "        print(char, end=\"\", flush=True)\n",
    "\n",
    "from langserve import RemoteRunnable\n",
    "def remote_runnable(runnable, params = [], base_url = base_url, debug = debug):\n",
    "    chain = RemoteRunnable(f\"{base_url}/{runnable}\")\n",
    "    def ask(*args):\n",
    "        kwargs = dict(zip(params, args))\n",
    "        if debug:\n",
    "            print_content(chain.stream(kwargs))\n",
    "        else:\n",
    "            return chain.invoke(kwargs)\n",
    "    return ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34aff10-f0c9-4e35-b6c8-adfb055482f8",
   "metadata": {},
   "source": [
    "或者打包为一个python文件，直接引用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2668e6c8-2f9d-464b-b714-2752266924c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNABLE_BASE_URL:  http://localhost:8000\n"
     ]
    }
   ],
   "source": [
    "from Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f25aa-7a5a-4c4a-b566-c345eed279bb",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805890c3-5828-4e16-a19a-7e77f49f0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35 = remote_runnable(\"langserve/gpt35\", [\"question\"])\n",
    "gpt4 = remote_runnable(\"langserve/gpt4\", [\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af697c5-d0c7-4908-bc5c-2c3ec64168f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可能有很多原因导致父母结婚时没有邀请你。也许他们认为你还太小，或者他们想要一个私人的、小型的婚礼。也有可能是因为他们的婚礼计划是在你不在场的时候进行的。无论原因是什么，重要的是理解并接受他们的决定，并且祝福他们未来的幸福生活。"
     ]
    }
   ],
   "source": [
    "gpt35(\"我的父母结婚时为什么没有邀请我？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9ccb50-592c-4b9e-9991-d6362ea57fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果你的父母在结婚时没有邀请你，可能有几个原因：\n",
      "\n",
      "1. 你还没有出生：这是最常见的原因。如果你的父母在你出生之前结婚，那么你自然不可能被邀请。\n",
      "\n",
      "2. 私密或小型婚礼：有些夫妇可能选择举行一个非常私密的婚礼，只邀请非常亲近的家人或朋友，或者甚至只有两个人单独举行仪式。\n",
      "\n",
      "3. 地理或物理障碍：可能在你的父母结婚时，你因为某些原因（如年幼、学业、工作或其他责任）无法到场。\n",
      "\n",
      "4. 家庭关系：有时由于家庭内部关系复杂，可能会导致某些家庭成员没有被邀请参加婚礼。\n",
      "\n",
      "5. 误解或沟通问题：也有可能是由于沟通不畅或误解导致你没有收到邀请。\n",
      "\n",
      "6. 其他个人原因：每个家庭的情况都是独特的，可能有其他你不知道的原因。\n",
      "\n",
      "如果这个问题让你感到困惑或不安，与你的父母进行开放和诚实的对话可能会帮助你了解当时的情况和他们的决定。通常，这种情况是由于你还未出生或非常小，所以不可能参与他们的婚礼。"
     ]
    }
   ],
   "source": [
    "gpt4(\"我的父母结婚时为什么没有邀请我？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ecd12-4f79-43ed-b539-fc658f3b7d33",
   "metadata": {},
   "source": [
    "### 通义千问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d343865c-49fe-4f74-a4ef-663af2488d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tongyi = remote_runnable(\"langserve/tongyi\", [\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f67d83-145b-4df3-84ed-1bf076d506e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是阿里云开发的大规模语言模型，我叫通义千问。"
     ]
    }
   ],
   "source": [
    "tongyi(\"你是什么模型?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ca836636-1e81-4752-80ec-7f38145561c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因为您在他们结婚的时候还没有出生，所以他们自然无法邀请您参加他们的婚礼。通常情况下，只有已经出生并能够理解事件意义的人才会被邀请参加婚礼。"
     ]
    }
   ],
   "source": [
    "tongyi(\"我的父母结婚时为什么没有邀请我?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09678f-3e52-42ef-a88d-3c3db3c99319",
   "metadata": {},
   "source": [
    "### Chatglm3-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67ec88c3-750b-44c6-8940-2675baee3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatglm6b = remote_runnable(\"langserve/chatglm6b\", [\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8405e071-e584-420a-a606-1a7a800736a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 我是一个名为 ChatGLM3-6B 的人工智能助手，是基于清华大学KEG 实验室和智谱 AI公司于 2023 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。"
     ]
    }
   ],
   "source": [
    "chatglm6b(\"你是什么模型?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c5fe24b-e207-4ba0-b1b5-28ae152bb1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 作为人工智能助手，我无法了解您个人生活中的具体情况。但是，通常情况下，婚礼是一种庆祝两个人成为夫妇的仪式，因此，新婚夫妇很少会邀请孩子作为嘉宾。在某些情况下，他们可能会邀请孩子参加婚礼，但这取决于孩子的年龄和婚礼的规模。如果您希望了解更多关于您父母婚礼的信息，您可以尝试与他们沟通，了解他们当时的想法和决定。"
     ]
    }
   ],
   "source": [
    "chatglm6b(\"我的父母结婚时为什么没有邀请我?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e3204-c752-42ce-9806-526f0ef979e4",
   "metadata": {},
   "source": [
    "### lambda函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7249bdd-eb0b-4dee-9a47-d841a752d095",
   "metadata": {},
   "source": [
    "自定义的lambda函数一般不访问大模型，而是以较快速度在本地计算，因此不需要支持流式打印，所以无需封装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6febd84-1f08-407b-bd91-ac81a9708839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result is: 3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RemoteRunnable(f\"{base_url}/langserve/add\")\n",
    "chain.invoke({\"x\": 1, \"y\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8e8d9a-d732-4df7-b3fe-658eaca22aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result is: 43'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RemoteRunnable(f\"{base_url}/langserve/add_one\")\n",
    "chain.invoke(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e57c8866-c7f4-4c74-bf51-0d5c286ba15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Why don't programmers like nature?\\n\\nBecause they prefer the comfort of their artificial intelligence!\", 'Why did the artist bring a ladder to the art gallery? \\n\\nBecause they wanted to reach new heights in their work!', 'Why did the cell go to therapy?\\n\\nBecause it had a lot of mitosis!']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.base import RunnableEach\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about{topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "runnable = prompt | model | output_parser\n",
    "runnable_each = RunnableEach(bound=runnable)\n",
    "output = runnable_each.invoke([{'topic':'Computer Science'},\n",
    "                            {'topic':'Art'},\n",
    "                            {'topic':'Biology'}])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc014ec-381c-4a83-9b86-428d9d24b30e",
   "metadata": {},
   "source": [
    "### RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b54b6-a047-48f0-8a5f-0a98ba5eaebc",
   "metadata": {},
   "source": [
    "RunnableLambda在包装一个普通函数时特别有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e1816-fd8f-4221-bfc9-1c5b62a41ccd",
   "metadata": {},
   "source": [
    "#### 使用invoke和batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f585316-7e1a-4bbd-ac5e-c074040b3c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Alice ! Welcome To Langchain!\n",
      "hi Alice ! Welcome To Langchain!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import time\n",
    "\n",
    "# 定义你的函数\n",
    "def hello(name):\n",
    "    return f\"hi {name} ! Welcome To Langchain!\"\n",
    "\n",
    "# 创建一个MyRunnableLambda实例\n",
    "runnable = RunnableLambda(hello)\n",
    "\n",
    "# 使用invoke获得一次性输出\n",
    "print(runnable.invoke(\"Alice\"))  # 输出 \"hi Alice !\"\n",
    "\n",
    "# 注意：因为hello函数没有流式输出，因此stream也是没有流式输出效果的\n",
    "for output in runnable.stream(\"Alice\"):\n",
    "    time.sleep(0.3)\n",
    "    print(output)  # 输出 \"hi Alice !\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71034b-36b5-42b3-aba4-168cb5e4e533",
   "metadata": {},
   "source": [
    "#### 使用batch获得批量结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac7d4dbd-f0e1-45b7-b56b-449e62ef25b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi Alice ! Welcome To Langchain!', 'hi Bob ! Welcome To Langchain!']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch中会自动调用invoke\n",
    "runnable.batch([\"Alice\", \"Bob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8e33c-39a7-4b73-b714-54557020704f",
   "metadata": {},
   "source": [
    "#### 获得stream的流式输出效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "248fbd2c-baf4-47b1-87f4-3635234b2afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Alice! Welcome to Langchain!\n",
      "hi Alice! Welcome to Langchain!"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "import time\n",
    "\n",
    "# 定义你的函数\n",
    "def hello(name):\n",
    "    yield \"hi \"\n",
    "    yield name\n",
    "    yield \"! \"\n",
    "    yield \"Welcome\"\n",
    "    yield \" to\"\n",
    "    yield \" Langchain!\"\n",
    "\n",
    "# 创建一个MyRunnableLambda实例\n",
    "runnable = RunnableLambda(hello)\n",
    "\n",
    "# invoke会等到所有结果获得后合并到一起输出\n",
    "print(runnable.invoke(\"Alice\"))  # 输出 \"hi Alice !\"\n",
    "\n",
    "# 因为hello函数实现了yield，stream就会有流式输出效果\n",
    "for output in runnable.stream(\"Alice\"):\n",
    "    time.sleep(0.3)\n",
    "    print(output, end = \"\")  # 输出 \"hi Alice !\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe12eeb-26e8-46be-9f83-7813febe1e05",
   "metadata": {},
   "source": [
    "#### 使用 @chain 达到同样的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14411965-dec6-4b0d-9b78-1317eec9db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi Alice! Welcome to Langchain!\n",
      "hi Alice! Welcome to Langchain!"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "import time\n",
    "\n",
    "# 定义你的函数\n",
    "@chain\n",
    "def hello(name):\n",
    "    yield \"hi \"\n",
    "    yield name\n",
    "    yield \"! \"\n",
    "    yield \"Welcome\"\n",
    "    yield \" to\"\n",
    "    yield \" Langchain!\"\n",
    "\n",
    "print(hello.invoke(\"Alice\"))  # 输出 \"hi Alice !\"\n",
    "\n",
    "for output in hello.stream(\"Alice\"):\n",
    "    time.sleep(0.3)\n",
    "    print(output, end = \"\")  # 输出 \"hi Alice !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276662c7-4a6d-4430-aa6c-a0e1118ad265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60579866-1c20-4b99-bd0a-b058622cf8b0",
   "metadata": {},
   "source": [
    "### RunnableGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f46ce3-5fa7-46de-9820-ec6fb73b6972",
   "metadata": {},
   "source": [
    "RunnableGenerator是专门用于生成器优化的实现，在将链作为输入时无需特别指定即可使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1bea8ce6-6273-420c-bdba-6be3914dace6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reduce👏, reuse👏, recycle!'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableGenerator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from typing import Iterator\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chant = (\n",
    "    ChatPromptTemplate.from_template(\"Give me a 3 word chant about {topic}\")\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def character_generator(input: Iterator[str]) -> Iterator[str]:\n",
    "    for token in input:\n",
    "        if \",\" in token or \".\" in token:\n",
    "            yield \"👏\" + token\n",
    "        else:\n",
    "            yield token\n",
    "\n",
    "runnable = chant | character_generator\n",
    "assert type(runnable.last) is RunnableGenerator\n",
    "\"\".join(runnable.stream({\"topic\": \"waste\"})) # Reduce👏, Reuse👏, Recycle👏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33bc2f-2430-4849-8981-96918850002a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchani-book-py3.10-ipykernel",
   "language": "python",
   "name": "langchani-book-py3.10-ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
